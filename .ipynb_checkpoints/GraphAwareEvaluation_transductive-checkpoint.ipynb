{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52ad701-071b-4c9f-9bc8-a0da062c9c8e",
   "metadata": {},
   "source": [
    "# Graph Aware evaluation on Core, CiteSeer and PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afa977-54bf-45de-be73-5b1f5fffc97c",
   "metadata": {},
   "source": [
    "## Load font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6361a3a5-c7cd-478d-ba66-9acacb684235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "from math import sin\n",
    "rc('text', usetex = False)\n",
    "la = matplotlib.font_manager.FontManager()\n",
    "lu = matplotlib.font_manager.FontProperties(family = 'Arial')\n",
    "print(la.findfont(lu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9426710-16b8-4651-a531-33eb87bcc074",
   "metadata": {},
   "source": [
    "## Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f39ca8-9364-4636-b9be-5b25e76d0d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'X': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  'y': tensor([3, 4, 4,  ..., 3, 3, 3]),\n",
       "  'test': tensor([False, False, False,  ...,  True,  True,  True]),\n",
       "  'train': tensor([ True,  True,  True,  ..., False, False, False]),\n",
       "  'val': tensor([False, False, False,  ..., False, False, False]),\n",
       "  'edge_index': tensor([[   0,    0,    0,  ..., 2705, 2706, 2707],\n",
       "          [ 633, 1862, 2582,  ..., 2705, 2706, 2707]])},\n",
       " 'PubMed': {'X': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0554, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0114, 0.0047,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0531, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0145, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       "  'y': tensor([1, 1, 0,  ..., 2, 0, 2]),\n",
       "  'test': tensor([False, False, False,  ...,  True,  True,  True]),\n",
       "  'train': tensor([ True,  True,  True,  ..., False, False, False]),\n",
       "  'val': tensor([False, False, False,  ..., False, False, False]),\n",
       "  'edge_index': tensor([[    0,     0,     0,  ..., 19714, 19715, 19716],\n",
       "          [ 1378,  1544,  6092,  ..., 19714, 19715, 19716]])},\n",
       " 'Citeseer': {'X': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  'y': tensor([3, 1, 5,  ..., 3, 1, 5]),\n",
       "  'test': tensor([False, False, False,  ...,  True,  True,  True]),\n",
       "  'train': tensor([ True,  True,  True,  ..., False, False, False]),\n",
       "  'val': tensor([False, False, False,  ..., False, False, False]),\n",
       "  'edge_index': tensor([[   0,    1,    1,  ..., 3324, 3325, 3326],\n",
       "          [ 628,  158,  486,  ..., 3324, 3325, 3326]])}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "citeseer_dataset = Planetoid(root = \"./data\", name = \"CiteSeer\")\n",
    "cora_dataset = Planetoid(root = \"./data\", name = \"Cora\")\n",
    "pubmed_dataset = Planetoid(root = \"./data\", name = \"PubMed\")\n",
    "\n",
    "def pre_process(dataset):\n",
    "    dataset.transform = T.NormalizeFeatures()\n",
    "    return dataset\n",
    "\n",
    "def add_set(set_name):\n",
    "    global name_to_sets, name_to_dataset\n",
    "    name_to_sets[set_name] = dict({})\n",
    "    \n",
    "    dataset = name_to_dataset[set_name]\n",
    "    X =  dataset[0].x \n",
    "    y =  dataset[0].y \n",
    "    \n",
    "    test =  dataset[0].test_mask\n",
    "    train = dataset[0].train_mask \n",
    "    val =  dataset[0].val_mask\n",
    "    \n",
    "    edge_index = add_self_loops(dataset[0].edge_index)[0]\n",
    "\n",
    "    name_to_sets[set_name][\"X\"] = X\n",
    "    name_to_sets[set_name][\"y\"] = y\n",
    "    name_to_sets[set_name][\"test\"] = test\n",
    "    name_to_sets[set_name][\"train\"] = train\n",
    "    name_to_sets[set_name][\"val\"] = val\n",
    "    name_to_sets[set_name][\"edge_index\"] = edge_index\n",
    "\n",
    "def create_sets():\n",
    "    for set_name in name_to_dataset.keys():\n",
    "        add_set(set_name)\n",
    "\n",
    "\n",
    "CORA = \"Cora\"\n",
    "PUBMED = \"PubMed\"\n",
    "CITESEER = \"Citeseer\"\n",
    "\n",
    "name_to_dataset = dict({})\n",
    "name_to_dataset[CORA] = pre_process(cora_dataset)\n",
    "name_to_dataset[PUBMED] = pre_process(pubmed_dataset)\n",
    "name_to_dataset[CITESEER] = pre_process(citeseer_dataset)\n",
    "name_to_sets = dict({})\n",
    "create_sets()\n",
    "name_to_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617389a-d7e9-4344-a953-7effac79197b",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c99a99fd-af4f-4f72-ab9d-9719ef84db11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3727a0b80abd4d4ca3f3d84bb44d7c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cac8e82fed46eab983d3461717c117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0492d3445cb4bfa9a37c8c0d6be9ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/21 07:57:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m user_functions \u001b[38;5;241m=\u001b[39m [norm_user_function, user_function]\n\u001b[1;32m     43\u001b[0m searcher \u001b[38;5;241m=\u001b[39m AutoSearch(name_to_sets[CORA], max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, pred_metric \u001b[38;5;241m=\u001b[39m accuracy_score, parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_configs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:201\u001b[0m, in \u001b[0;36mAutoSearch.search\u001b[0;34m(self, clfs, clfs_space, hops, user_functions, attention_configs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attention_config \u001b[38;5;129;01min\u001b[39;00m tqdm(attention_configs):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user_function \u001b[38;5;129;01min\u001b[39;00m user_functions:\n\u001b[0;32m--> 201\u001b[0m         search_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_hop_clf_attention_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m search_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m best_val:\n\u001b[1;32m    203\u001b[0m             best_val \u001b[38;5;241m=\u001b[39m search_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:145\u001b[0m, in \u001b[0;36mAutoSearch.search_hop_clf_attention_config\u001b[0;34m(self, hop, clf, user_function, attention_config, space)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_data()\n\u001b[1;32m    144\u001b[0m sparkTune \u001b[38;5;241m=\u001b[39m SparkTune(clf,user_function,hop,attention_config, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43msparkTune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m params \u001b[38;5;241m=\u001b[39m space_eval(space, params) \u001b[38;5;66;03m## index choices to original choices\u001b[39;00m\n\u001b[1;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m clf(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:108\u001b[0m, in \u001b[0;36mSparkTune.search\u001b[0;34m(self, space)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, space):\n\u001b[0;32m--> 108\u001b[0m     spark_trials \u001b[38;5;241m=\u001b[39m \u001b[43mSparkTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallelism\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallelism\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m fmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective, space, algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_search\u001b[38;5;241m.\u001b[39mmax_evals, trials\u001b[38;5;241m=\u001b[39mspark_trials, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/spark.py:86\u001b[0m, in \u001b[0;36mSparkTrials.__init__\u001b[0;34m(self, parallelism, timeout, loss_threshold, spark_session)\u001b[0m\n\u001b[1;32m     83\u001b[0m validate_timeout(timeout)\n\u001b[1;32m     84\u001b[0m validate_loss_threshold(loss_threshold)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spark_session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m spark_session\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39msparkContext\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark_pinned_threads_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark_context\u001b[38;5;241m.\u001b[39m_gateway, ClientServer\n\u001b[1;32m     93\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:203\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:296\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:421\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1586\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1578\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1579\u001b[0m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[1;32m   1581\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1583\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1584\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1586\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1588\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from hyperopt import hp\n",
    "from AutoTune2 import AutoSearch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "lr_choices = {\n",
    "    'penalty': [\"l2\"],\n",
    "    'max_iter': [2**i for i in range(6, 15)],\n",
    "    \n",
    "}\n",
    "\n",
    "space_lr = {\n",
    "    **{key: hp.choice(key, value) for key, value in lr_choices.items()},\n",
    "    'tol': hp.loguniform('tol', -11, -3),\n",
    "    'C': hp.uniform('C', 0.0, 10)\n",
    "}\n",
    "\n",
    "def norm_user_function(kwargs):\n",
    "    return  normalize(kwargs[\"original_features\"] + kwargs[\"summed_neighbors\"], p=2.0, dim = 1)\n",
    "    \n",
    "def user_function(kwargs):\n",
    "    return  kwargs[\"original_features\"] + kwargs[\"summed_neighbors\"]\n",
    "    \n",
    "\n",
    "hops = [0,3,8]\n",
    "clfs = [LogisticRegression]\n",
    "clfs_space = dict({})\n",
    "clfs_space[\"LogisticRegression\"] = space_lr\n",
    "attention_configs = [None,{'inter_layer_normalize': False,\n",
    "                     'use_pseudo_attention':True,\n",
    "                     'cosine_eps':.01,\n",
    "                     'dropout_attn': None}, \n",
    "                     {'inter_layer_normalize': True,\n",
    "                     'use_pseudo_attention':True,\n",
    "                     'cosine_eps':.01,\n",
    "                     'dropout_attn': None},\n",
    "                     {'inter_layer_normalize': True,\n",
    "                     'use_pseudo_attention':True,\n",
    "                     'cosine_eps':.001,\n",
    "                     'dropout_attn': None}]\n",
    "user_functions = [norm_user_function, user_function]\n",
    "searcher = AutoSearch(name_to_sets[CORA], max_evals=500, pred_metric = accuracy_score, parallelism=50)\n",
    "store = searcher.search(clfs, clfs_space, hops=hops, user_functions= user_functions,\n",
    "                        attention_configs = attention_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fc36b-6f00-47b0-866f-9d8a0771e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152bacf-9124-4f31-921c-e6cfc65844a5",
   "metadata": {},
   "source": [
    "## Generic fit function for GraphAware training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d81b55b-cf71-4a91-adcb-f6fad70dffd5",
   "metadata": {},
   "source": [
    "## Dictionary for storing trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b02d09-8a18-47d2-bc37-7afb0e47ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_model = dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3dba0e8-64b4-47fc-a013-a079934d4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleFramework import Framework\n",
    "import time\n",
    "\n",
    "def fit_dataset(set_name,user_functions=[], hops_list= [3], clfs = [], attention_configs= []):\n",
    "    dataset = name_to_sets[set_name]\n",
    "    y = dataset[\"y\"]\n",
    "    \n",
    "    start = time.time()\n",
    "    framework = Framework(user_functions, \n",
    "                     hops_list=hops_list, ## to obtain best for local neighborhood\n",
    "                     clfs=clfs,\n",
    "                     gpu_idx=0,\n",
    "                     handle_nan=0.0,\n",
    "                    attention_configs=attention_configs)\n",
    "    vals = framework.get_features(dataset[\"X\"], dataset[\"edge_index\"], dataset[\"val\"])\n",
    "    vals = [val.cpu() for val in vals]\n",
    "    kwargs_list=[{\"eval_set\":[(vals[i], y[dataset[\"val\"]])], \"early_stopping_rounds\":5} if clf.__class__.__name__ == 'XGBClassifier' else {} for i, clf in enumerate(clfs)]\n",
    "    framework.fit(dataset[\"X\"], dataset[\"edge_index\"], y, dataset[\"train\"], kwargs_list)\n",
    "    end = time.time()-start\n",
    "    name_to_model[set_name] = framework\n",
    "    return framework, end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d54b4-487c-4bf8-9be2-accaa57bd46f",
   "metadata": {},
   "source": [
    "## Generic predict function for GraphAware evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a265c4-b42c-4f6c-87a3-048377575ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def predict_dataset(set_name,framework):\n",
    "    dataset = name_to_sets[set_name]\n",
    "    \n",
    "    y = dataset[\"y\"]\n",
    "    framework = name_to_model[set_name]\n",
    "    pred = framework.predict(dataset[\"X\"], dataset[\"edge_index\"], dataset[\"test\"]) \n",
    "    pred_val = framework.predict(dataset[\"X\"], dataset[\"edge_index\"], dataset[\"val\"]) \n",
    "    y_test = y[dataset[\"test\"]]\n",
    "    y_val = y[dataset[\"val\"]]\n",
    "    return {\n",
    "        \"test_acc\": accuracy_score(y_test, pred),\n",
    "        \"val_acc\": accuracy_score(y_val, pred_val)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec54227-0829-4d25-9b2b-543ff1630b06",
   "metadata": {},
   "source": [
    "## Citeseer Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb7163-63e7-4589-9de6-2c56962ea1e2",
   "metadata": {},
   "source": [
    "### CiteSeer Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d5308e-9368-47c9-8a18-f75990e6fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from AutoTune2 import upd_user_function, norm_user_function, user_function\n",
    "citeseer_store = {'LogisticRegression': {0: {'train_acc': 1.0,\n",
    "   'val_acc': 0.594,\n",
    "   'test_acc': 0.615,\n",
    "   'model': LogisticRegression(C=3.9057765563512103,\n",
    "                      max_iter=512, tol=0.00037394547447174774),\n",
    "   'user_function': user_function,\n",
    "   'attention_config': {'inter_layer_normalize': True,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.01,\n",
    "    'dropout_attn': None}},\n",
    "  3: {'train_acc': 0.95,\n",
    "   'val_acc': 0.716,\n",
    "   'test_acc': 0.721,\n",
    "   'model': LogisticRegression(C=3.161729301367482, \n",
    "                      max_iter=128, tol=0.0022154364103027916),\n",
    "   'user_function': user_function,\n",
    "   'attention_config': {'inter_layer_normalize': False,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.01,\n",
    "    'dropout_attn': None}},\n",
    "  8: {'train_acc': 0.9583333333333334,\n",
    "   'val_acc': 0.738,\n",
    "   'test_acc': 0.721,\n",
    "   'model': LogisticRegression(C=4.484384767955908,\n",
    "                      max_iter=16384, tol=0.000418404361811845),\n",
    "   'user_function': user_function,\n",
    "   'attention_config': {'inter_layer_normalize': False,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.01,\n",
    "    'dropout_attn': None}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634e6281-3911-4352-9ed8-4f5cfc76db4f",
   "metadata": {},
   "source": [
    "### GraphAware on CiteSeer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4a69c9-43d5-4129-83b6-cb9631fa37e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store = citeseer_store\n",
    "user_functions = [store[\"LogisticRegression\"][0][\"user_function\"], store[\"LogisticRegression\"][3][\"user_function\"], store[\"LogisticRegression\"][8][\"user_function\"]]\n",
    "clfs = [store[\"LogisticRegression\"][0][\"model\"], store[\"LogisticRegression\"][3][\"model\"], store[\"LogisticRegression\"][8][\"model\"]]\n",
    "attention_configs = [store[\"LogisticRegression\"][0][\"attention_config\"], store[\"LogisticRegression\"][3][\"attention_config\"], store[\"LogisticRegression\"][8][\"attention_config\"]]\n",
    "times = []\n",
    "accs = []\n",
    "for i in range(100):\n",
    "    framework, end_time = fit_dataset(CITESEER,user_functions=user_functions, hops_list= [0,3,8], clfs = clfs, attention_configs= attention_configs)\n",
    "    acc_dict = predict_dataset(CITESEER, framework)\n",
    "    times.append(end_time)\n",
    "    accs.append(acc_dict[\"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfd4c0-2eb5-4237-90a0-95c87149dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"Accuracy of CiteSeer {np.array(accs).mean()} +- {np.array(accs).std()}; Required training time: {np.array(times).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c48d4-e7e9-4127-ab3c-c9c007402599",
   "metadata": {},
   "source": [
    "## PubMed Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55ce4d-9202-4216-b16b-ee85a0d9f1bd",
   "metadata": {},
   "source": [
    "### PubMed Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cca25-9d2c-4a90-bc25-5c0723c5bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoTune2 import upd_user_function, norm_user_function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pubmed_store = {'LogisticRegression': {0: {'train_acc': 0.9833333333333333,\n",
    "   'val_acc': 0.742,\n",
    "   'test_acc': 0.737,\n",
    "   'model': LogisticRegression(C=19.012946053218332, max_iter=4096,\n",
    "                      tol=0.011693958862167635),\n",
    "   'user_function': upd_user_function,\n",
    "   'attention_config': {'inter_layer_normalize': True,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.001,\n",
    "    'dropout_attn': None}},\n",
    "  3: {'train_acc': 0.9833333333333333,\n",
    "   'val_acc': 0.812,\n",
    "   'test_acc': 0.802,\n",
    "   'model': LogisticRegression(C=2.3417904147486635, max_iter=4096,\n",
    "                      tol=1.877242326314165e-05),\n",
    "   'user_function': norm_user_function,\n",
    "   'attention_config': {'inter_layer_normalize': False,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.01,\n",
    "    'dropout_attn': None}},\n",
    "  8: {'train_acc': 0.9666666666666667,\n",
    "   'val_acc': 0.826,\n",
    "   'test_acc': 0.793,\n",
    "   'model': LogisticRegression(C=8.816857543671555, max_iter=256, tol=0.0003864950814262107),\n",
    "   'user_function': norm_user_function,\n",
    "   'attention_config': None}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa5914-5307-4900-accc-2d334a741fd8",
   "metadata": {},
   "source": [
    "### GraphAware on PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318ac98-4b11-4f83-b72c-26424523021c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "store = pubmed_store\n",
    "user_functions = [store[\"LogisticRegression\"][0][\"user_function\"], store[\"LogisticRegression\"][3][\"user_function\"], store[\"LogisticRegression\"][8][\"user_function\"]]\n",
    "clfs = [store[\"LogisticRegression\"][0][\"model\"], store[\"LogisticRegression\"][3][\"model\"], store[\"LogisticRegression\"][8][\"model\"]]\n",
    "attention_configs = [store[\"LogisticRegression\"][0][\"attention_config\"], store[\"LogisticRegression\"][3][\"attention_config\"], store[\"LogisticRegression\"][8][\"attention_config\"]]\n",
    "times = []\n",
    "accs = []\n",
    "for i in tqdm(range(100)):\n",
    "    framework, end_time = fit_dataset(PUBMED,user_functions=user_functions, hops_list= [0,3,8], clfs = clfs, attention_configs= attention_configs)\n",
    "    acc_dict = predict_dataset(PUBMED, framework)\n",
    "    times.append(end_time)\n",
    "    accs.append(acc_dict[\"test_acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86b1f1-b7c7-4481-a516-9af2a7319f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"Accuracy of PuBMed {np.array(accs).mean()} +- {np.array(accs).std()}; Required training time: {np.array(times).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7b1a4-ba15-4da0-9188-a39b19b24d8a",
   "metadata": {},
   "source": [
    "## Cora Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d685f74-4f0c-47ff-b700-f6307cb316a0",
   "metadata": {},
   "source": [
    "### Cora Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ceacc-852c-4bd7-91df-71e63ac0dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from AutoTune import user_function, norm_user_function\n",
    "cora_store = {'LogisticRegression': {0: {'train_acc': 0.9928571428571429,\n",
    "   'val_acc': 0.586,\n",
    "   'test_acc': 0.598,\n",
    "   'model': LogisticRegression(C=9.89464848441749, l1_ratio=0.1083794378326286,\n",
    "                      max_iter=8192, tol=3.9088643651368724e-05),\n",
    "   'user_function': user_function,\n",
    "   'attention_config': {'inter_layer_normalize': True,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.001,\n",
    "    'dropout_attn': None}},\n",
    "  3: {'train_acc': 0.9928571428571429,\n",
    "   'val_acc': 0.808,\n",
    "   'test_acc': 0.82,\n",
    "   'model': LogisticRegression(C=4.9289832447362025, l1_ratio=0.1761472021705791,\n",
    "                      max_iter=8192, tol=0.017104071425396022),\n",
    "   'user_function': norm_user_function,\n",
    "   'attention_config': None},\n",
    "  8: {'train_acc': 0.9928571428571429,\n",
    "   'val_acc': 0.808,\n",
    "   'test_acc': 0.817,\n",
    "   'model': LogisticRegression(C=3.726771337407598, l1_ratio=0.032154684509317244,\n",
    "                      max_iter=128, tol=7.557643967339885e-05),\n",
    "   'user_function': norm_user_function,\n",
    "   'attention_config': {'inter_layer_normalize': True,\n",
    "    'use_pseudo_attention': True,\n",
    "    'cosine_eps': 0.001,\n",
    "    'dropout_attn': None}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea531a8-444a-4134-b172-b1d0fc1fd4f9",
   "metadata": {},
   "source": [
    "### GraphAware on Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244557af-8d5c-4abe-bc40-ce3bd3a461ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "store = cora_store\n",
    "user_functions = [store[\"LogisticRegression\"][0][\"user_function\"], store[\"LogisticRegression\"][3][\"user_function\"], store[\"LogisticRegression\"][8][\"user_function\"]]\n",
    "clfs = [store[\"LogisticRegression\"][0][\"model\"], store[\"LogisticRegression\"][3][\"model\"], store[\"LogisticRegression\"][8][\"model\"]]\n",
    "attention_configs = [store[\"LogisticRegression\"][0][\"attention_config\"], store[\"LogisticRegression\"][3][\"attention_config\"], store[\"LogisticRegression\"][8][\"attention_config\"]]\n",
    "\n",
    "times = []\n",
    "accs = []\n",
    "for i in range(10):\n",
    "    framework, end_time = fit_dataset(CORA,user_functions=user_functions, hops_list= [0,3,8], clfs = clfs, attention_configs= attention_configs)\n",
    "    acc_dict = predict_dataset(CORA, framework)\n",
    "    print(acc_dict)\n",
    "    times.append(end_time)\n",
    "    accs.append(acc_dict[\"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d2c11-8082-42f6-a013-8eb2cad42c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"Accuracy of Cora {np.array(accs).mean()} +- {np.array(accs).std()}; Required training time: {np.array(times).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7653e6f-4a72-4ef0-9b0d-3e6fca8ef221",
   "metadata": {},
   "source": [
    "## Feature importance for CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295879d0-b9b9-45f3-ba13-74e1c2d38530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "font = {'family' : 'Arial',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.ylim(0, 0.006)\n",
    "plt.xlim(0, 1434)\n",
    "framework.plot_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd397a7e-644a-4986-ae3f-81ae5fc06896",
   "metadata": {},
   "source": [
    "## T-SNE Plot for Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aadd99-dabd-4a8a-874f-8239e18cbf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = name_to_sets[CORA]\n",
    "y = dataset[\"y\"]\n",
    "X = dataset[\"X\"]\n",
    "edge_index = dataset[\"edge_index\"]\n",
    "framework.plot_tsne(X, edge_index, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
