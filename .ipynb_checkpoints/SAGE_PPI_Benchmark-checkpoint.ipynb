{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1c65ba-0223-44e0-9b52-c86a995eba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = PPI(root='/tmp/PPI', split=\"train\")\n",
    "val_dataset = PPI(root='/tmp/PPI', split=\"val\")\n",
    "test_dataset = PPI(root='/tmp/PPI', split=\"test\")\n",
    "# train_dataset.transform = T.NormalizeFeatures()\n",
    "# val_dataset.transform = T.NormalizeFeatures()\n",
    "# test_dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "train_loader = iter(DataLoader(train_dataset, batch_size=len(train_dataset)))\n",
    "val_loader = iter(DataLoader(val_dataset, batch_size=len(val_dataset)))\n",
    "test_loader = iter(DataLoader(test_dataset, batch_size=len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2eb039-8918-4891-988e-7581d3eca40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PPI(20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40fa312-4eaa-4cb5-9d45-40842f463296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = next(train_loader)\n",
    "test_set = next(test_loader)\n",
    "val_set = next(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2ff990-90bb-4d98-81b6-5590617bdd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93afa03f-a35a-44df-82e0-212cf82859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout = .2, aggr=\"mean\", normalize = False, project = True):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim, aggr=aggr, normalize = normalize, project = project)\n",
    "        self.lin1 = Linear(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim, aggr = aggr, normalize = normalize, project = project)\n",
    "        self.lin2 = Linear(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, out_dim, aggr = aggr, normalize = normalize, project = project)\n",
    "        self.lin3 = Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index)# + self.lin1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index) #+ self.lin2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)# + self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4893f406-0786-4823-84d3-9d119b635338",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "train_set = train_set.to(device)\n",
    "val_set = val_set.to(device)\n",
    "test_set = test_set.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049c0fa3-d7c6-4573-b8e9-12f6e81c5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"train\"\n",
    "VAL = \"val\"\n",
    "TEST = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf3b418-5b9f-4ad0-9f15-024e30634508",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_names = [TRAIN, TEST, VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "956502ac-3c9c-4ac3-992d-86d4d098ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = dict()\n",
    "sets[TRAIN] = train_dataset\n",
    "sets[TEST] = test_dataset\n",
    "sets[VAL] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e8bf61d-0c5c-427f-910f-68f8ce721735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9381e7a65c4262903ec2f0bd8a4896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60226862d0d1440ab37d9ffa5043dbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m PATIENCE_COUNT \u001b[38;5;241m==\u001b[39m PATIENCE:\u001b[38;5;66;03m#epoch > EPOCHS // 2 and losses[VAL][-1] > torch.mean(torch.tensor(losses[VAL][-(PATIENCE+1):])).item():\u001b[39;00m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_val_loss \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m best_val_overall:\n\u001b[1;32m    100\u001b[0m     best_val_overall \u001b[38;5;241m=\u001b[39m best_val_loss\n",
      "Cell \u001b[0;32mIn[82], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_name \u001b[38;5;241m!=\u001b[39m VAL:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PATIENCE_COUNT \u001b[38;5;241m==\u001b[39m PATIENCE:\u001b[38;5;66;03m#epoch > EPOCHS // 2 and losses[VAL][-1] > torch.mean(torch.tensor(losses[VAL][-(PATIENCE+1):])).item():\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[82], line 66\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(set_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         acc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     64\u001b[0m         batch_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 66\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m scores[set_name]\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_name \u001b[38;5;241m==\u001b[39m VAL \u001b[38;5;129;01mand\u001b[39;00m best_val_loss \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m acc_loss:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     {\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m ):\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \n\u001b[1;32m   1282\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1725\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1725\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1732\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1733\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:587\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    584\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred[:, labels[:n_labels]]\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# calculate weighted counts\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m true_and_pred \u001b[38;5;241m=\u001b[39m \u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m count_nonzero(\n\u001b[1;32m    589\u001b[0m     true_and_pred, axis\u001b[38;5;241m=\u001b[39msum_axis, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m count_nonzero(y_pred, axis\u001b[38;5;241m=\u001b[39msum_axis, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_compressed.py:376\u001b[0m, in \u001b[0;36m_cs_matrix.multiply\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    375\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(other)\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binopt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_elmul_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Single element.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_compressed.py:1258\u001b[0m, in \u001b[0;36m_cs_matrix._binopt\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(maxnnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, other\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m-> 1258\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m   \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1268\u001b[0m A\u001b[38;5;241m.\u001b[39mprune()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import  matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import copy\n",
    "\n",
    "space = {\n",
    "    \"WEIGHT_DECAYS\": [0],#[0, 1e-3]\n",
    "\"AGGR\": [ \"max\"],#\"mean\", \n",
    "\"DROPOUT\": [0.0],\n",
    "\"HIDDEN_DIMS\": [256, 512],#[16, 32, 64, 128],\n",
    "\"LEARNING_RATES\": [1e-4, 5e-3, 1e-3, 5e-4],\n",
    "    \"PROJECT\": [True],#[True, False]\n",
    "    \"NORMALIZE\": [False],#[True, False],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(space)\n",
    "best_params_overall = None\n",
    "best_val_overall = float(\"inf\")\n",
    "\n",
    "for params in tqdm(param_grid.__iter__()):\n",
    "    EPOCHS = 320\n",
    "    HIDDEN_DIM = params[\"HIDDEN_DIMS\"]\n",
    "    DROPOUT = params[\"DROPOUT\"]\n",
    "    LEARNING_RATE = params[\"LEARNING_RATES\"]\n",
    "    WEIGHT_DECAY = params[\"WEIGHT_DECAYS\"]\n",
    "    PROJECT = params[\"PROJECT\"]\n",
    "    NORMALIZE = params[\"NORMALIZE\"]\n",
    "    AGGR = params[\"AGGR\"]\n",
    "    PATIENCE = 100\n",
    "    PATIENCE_COUNT = 0\n",
    "    \n",
    "    model = GNN(in_dim=train_set.x.shape[-1], hidden_dim=HIDDEN_DIM, out_dim=train_set.y.shape[-1], dropout = DROPOUT,\n",
    "               aggr = AGGR, normalize = NORMALIZE, project=PROJECT).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    # models = []\n",
    "    \n",
    "    losses = dict()\n",
    "    for set_name in set_names: losses[set_name] = []\n",
    "    scores = dict()\n",
    "    for set_name in set_names: scores[set_name] = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    test_acc = 0\n",
    "    \n",
    "    def validate(set_name):\n",
    "        global best_val_loss,  test_acc, PATIENCE_COUNT\n",
    "        acc_loss = 0\n",
    "        batch_size = 0\n",
    "        ground_truth = []\n",
    "        preds = []\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            set = sets[set_name]\n",
    "    \n",
    "            for loader in set:\n",
    "                loader = loader.to(device)\n",
    "                out = model(loader.x, loader.edge_index)\n",
    "                loss = loss_fn(out, loader.y)\n",
    "                ground_truth.append(loader.y)\n",
    "                preds.append((out > 0).float())\n",
    "                acc_loss += loss.item()\n",
    "                batch_size+=1\n",
    "                \n",
    "        score = f1_score(torch.cat(ground_truth).cpu(), torch.cat(preds).detach().cpu(), average =\"micro\")\n",
    "        scores[set_name].append(score)\n",
    "        \n",
    "        if set_name == VAL and best_val_loss >= acc_loss:\n",
    "            best_val_loss = acc_loss\n",
    "            # test_acc = scores[TEST][-1]\n",
    "            PATIENCE_COUNT = 0\n",
    "        else:\n",
    "            PATIENCE_COUNT += 1\n",
    "        # models.append(copy.deepcopy(model))\n",
    "        losses[set_name].append(acc_loss / batch_size)\n",
    "    \n",
    "    def train():\n",
    "        global PATIENCE_COUNT\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            acc_loss = 0\n",
    "            for loader in train_dataset:\n",
    "                loader = loader.to(device)\n",
    "                optim.zero_grad()\n",
    "                model.train()\n",
    "                out = model(loader.x, loader.edge_index)\n",
    "                loss = loss_fn(out, loader.y)\n",
    "                acc_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "            for set_name in set_names:\n",
    "                if set_name != VAL:\n",
    "                    continue\n",
    "                validate(set_name)\n",
    "            if PATIENCE_COUNT == PATIENCE:#epoch > EPOCHS // 2 and losses[VAL][-1] > torch.mean(torch.tensor(losses[VAL][-(PATIENCE+1):])).item():\n",
    "                break\n",
    "    train()\n",
    "    if best_val_loss <= best_val_overall:\n",
    "        best_val_overall = best_val_loss\n",
    "        best_params_overall = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1be6a9d-4e4e-4b72-95c5-974c443a0d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12518548592925072"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49cf37c2-ec99-49dc-9a5c-39a3efe6ab3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGGR': 'max',\n",
       " 'DROPOUT': 0.0,\n",
       " 'HIDDEN_DIMS': 512,\n",
       " 'LEARNING_RATES': 0.001,\n",
       " 'NORMALIZE': False,\n",
       " 'PROJECT': True,\n",
       " 'WEIGHT_DECAYS': 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8bd129f-0eb5-4df4-9c8e-4d8476850500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2028813cc22452481c99aa883c6a75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best_model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         best_model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[0;32m---> 89\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PATIENCE_COUNT \u001b[38;5;241m==\u001b[39m PATIENCE:\u001b[38;5;66;03m#epoch > EPOCHS // 2 and losses[VAL][-1] > torch.mean(torch.tensor(losses[VAL][-(PATIENCE+1):])).item():\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbest_model\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'best_model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import copy\n",
    "##TODO Write hyperparam tune loop \n",
    "\n",
    "\n",
    "EPOCHS = 10_000 #200\n",
    "HIDDEN_DIM = 256 #64\n",
    "PROJECT = True\n",
    "NORMALIZE = False\n",
    "AGGR = \"max\"\n",
    "DROPOUT = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0\n",
    "PATIENCE = 100\n",
    "PATIENCE_COUNT = 0\n",
    "\n",
    "\n",
    "model = GNN(in_dim=train_set.x.shape[-1], hidden_dim=HIDDEN_DIM, out_dim=train_set.y.shape[-1], dropout = DROPOUT,\n",
    "               aggr = AGGR, normalize = NORMALIZE, project=PROJECT).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "best_model = None\n",
    "\n",
    "losses = dict()\n",
    "for set_name in set_names: losses[set_name] = []\n",
    "scores = dict()\n",
    "for set_name in set_names: scores[set_name] = []\n",
    "best_val_loss = float(\"inf\")\n",
    "test_acc = 0\n",
    "\n",
    "def validate(set_name):\n",
    "    global best_val_loss,  test_acc, PATIENCE_COUNT\n",
    "    acc_loss = 0\n",
    "    batch_size = 0\n",
    "    ground_truth = []\n",
    "    preds = []\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        set = sets[set_name]\n",
    "\n",
    "        for loader in set:\n",
    "            loader = loader.to(device)\n",
    "            out = model(loader.x, loader.edge_index)\n",
    "            loss = loss_fn(out, loader.y)\n",
    "            ground_truth.append(loader.y)\n",
    "            preds.append((out > 0).float())\n",
    "            acc_loss += loss.item()\n",
    "            batch_size+=1\n",
    "            \n",
    "    score = f1_score(torch.cat(ground_truth).cpu(), torch.cat(preds).detach().cpu(), average =\"micro\")\n",
    "    scores[set_name].append(score)\n",
    "    \n",
    "    if set_name == VAL and best_val_loss >= acc_loss:\n",
    "        best_val_loss = acc_loss\n",
    "        # test_acc = scores[TEST][-1]\n",
    "        PATIENCE_COUNT = 0\n",
    "    else:\n",
    "        if PATIENCE_COUNT == 0:\n",
    "            best_model = copy.deepcopy(model)\n",
    "        PATIENCE_COUNT += 1\n",
    "    \n",
    "    losses[set_name].append(acc_loss / batch_size)\n",
    "\n",
    "def train():\n",
    "    global PATIENCE_COUNT, best_model\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        acc_loss = 0\n",
    "        for loader in train_dataset:\n",
    "            loader = loader.to(device)\n",
    "            optim.zero_grad()\n",
    "            model.train()\n",
    "            out = model(loader.x, loader.edge_index)\n",
    "            loss = loss_fn(out, loader.y)\n",
    "            acc_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        for set_name in set_names:\n",
    "            # if set_name != VAL:\n",
    "            #     continue\n",
    "            validate(set_name)\n",
    "        if PATIENCE_COUNT == PATIENCE:#epoch > EPOCHS // 2 and losses[VAL][-1] > torch.mean(torch.tensor(losses[VAL][-(PATIENCE+1):])).item():\n",
    "            break\n",
    "    if best_model is None:\n",
    "        best_model = copy.deepcopy(model)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dac940-5288-4258-9467-3c3e65729740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for parameter in model.parameters():\n",
    "    # print(20*\"*\")\n",
    "    # print(parameter.shape)\n",
    "    # print(torch.prod(torch.tensor(parameter.shape), 0))\n",
    "    num_params += torch.prod(torch.tensor(parameter.shape), 0).item()\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798f54f-77b3-4e3b-b481-474bf9c5e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name in set_names: plt.plot(losses[set_name])\n",
    "plt.legend(set_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4eefb-2ce2-43a5-8dd1-a4b8a03c0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "preds = []\n",
    "for loader in sets[TEST]:\n",
    "    loader = loader.to(device)\n",
    "    out = models[-(PATIENCE+1)](loader.x, loader.edge_index)\n",
    "    preds.append(out)\n",
    "    ground_truth.append(loader.y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99873f4-6b2e-45b8-87ca-d45d99e455ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(torch.cat(ground_truth).cpu(), (torch.cat(preds).cpu().detach() > 0).float(), average = \"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5997a-337a-486a-9001-92389bf90078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
