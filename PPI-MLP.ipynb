{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fedec7e-b40b-4639-baec-2040f1a07fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleFramework import Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff17fc77-ad91-4c3f-ad39-88e7ea7a122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = PPI(root='/tmp/PPI', split=\"train\")\n",
    "val_dataset = PPI(root='/tmp/PPI', split=\"val\")\n",
    "test_dataset = PPI(root='/tmp/PPI', split=\"test\")\n",
    "train_dataset.transform = T.NormalizeFeatures()\n",
    "val_dataset.transform = T.NormalizeFeatures()\n",
    "test_dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "train_loader = iter(DataLoader(train_dataset, batch_size=len(train_dataset)))\n",
    "val_loader = iter(DataLoader(val_dataset, batch_size=len(val_dataset)))\n",
    "test_loader = iter(DataLoader(test_dataset, batch_size=len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b1c73b-8677-4797-ae3d-c116adcbd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = next(train_loader)\n",
    "test_set = next(test_loader)\n",
    "val_set = next(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459875d7-b103-4699-9230-0ef6581388a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/graph_aware_ml/EnsembleFramework.py:145: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:230.)\n",
      "  summed_exp_score = torch.zeros_like(exp_score).scatter(0, target,exp_score, reduce=\"add\")\n"
     ]
    }
   ],
   "source": [
    "from EnsembleFramework import Framework\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def user_function(kwargs):\n",
    "    return  nn.functional.normalize(kwargs[\"updated_features\"] + kwargs[\"summed_neighbors\"], p = 2.0, dim = -1)\n",
    "    \n",
    "framework = Framework(hops_list= [5], clfs=[], attention_configs=[{'inter_layer_normalize': False,\n",
    "   'use_pseudo_attention': True,\n",
    "   'cosine_eps': 0.01,\n",
    "   'dropout_attn': None}], handle_nan=0.0, gpu_idx=0, user_functions=[user_function])\n",
    "new_train_features = framework.get_features(X=train_set.x, edge_index=train_set.edge_index, mask=torch.ones(train_set.x.shape[0]).type(torch.bool))\n",
    "new_test_features = framework.get_features(X=test_set.x, edge_index=test_set.edge_index, mask=torch.ones(test_set.x.shape[0]).type(torch.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb7c73-6c59-4380-82e7-d78ac4916494",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://stackoverflow.com/questions/67887291/multi-label-classification-with-sklearn-how-do-you-use-a-validation-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8563e0-8b06-491c-ad6a-3d23abc33b2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.06440329551697"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "start = time.time()\n",
    "model = MultiOutputClassifier(XGBClassifier(**{'alpha': 0.9468666283941924, 'booster': 'gbtree', 'eta': 0.34790291453070427, 'max_delta_step': 3, 'max_depth': None, 'min_child_weight': 1, 'n_estimators': 1200, 'reg_lambda': 0.037655682459731096, 'subsample': 0.9776289728774308}), n_jobs=-1).fit(new_train_features[0].cpu(), train_set.y)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbba0d6-dbe4-43e7-a0f4-750bff128852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725534120079772"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_set.y, model.predict(new_test_features[0].cpu()), average =\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa48193-f51e-4feb-8e5a-8faf4861053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9838)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.equal(model.predict(new_test_features[0].cpu()), test_set.y).sum()/ test_set.y.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d56c4e3-b8d9-4be4-89f7-91e6e0d439f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from hyperopt import fmin, tpe, hp,STATUS_OK, SparkTrials\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# booster_self = [\"gbtree\"]\n",
    "# n_estimators_self = [5, 50, 100,150, 200, 400, 500, 800, 1_000, 1_200]\n",
    "# max_depth_self = [None, 1, 2, 3, 4]\n",
    "# max_delta_step_self = [None, 1, 2, 3, 4]\n",
    "# min_child_weight_self = [None, 1, 2, 3, 4]\n",
    "booster_self = [\"gbtree\"]\n",
    "n_estimators_self = [1_200, 1_400, 1_600]\n",
    "max_depth_self = [None, 4]\n",
    "max_delta_step_self = [2,3,5]\n",
    "min_child_weight_self = [None, 1, 2]\n",
    "\n",
    "xb_choices = {\n",
    "    'booster': booster_self,\n",
    "    'n_estimators': n_estimators_self,\n",
    "    'max_depth': max_depth_self,\n",
    "    'max_delta_step': max_delta_step_self,\n",
    "    'min_child_weight': min_child_weight_self,\n",
    "}\n",
    "space_xb = {\n",
    "    **{key: hp.choice(key, value) for key, value in xb_choices.items()},\n",
    "    'eta': hp.loguniform('eta', -3, -.3),\n",
    "    # 'subsample': hp.uniform('subsample', 0.6, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'alpha': hp.uniform('alpha', 0.8, 1),#0.0,1\n",
    "}\n",
    "svc_choices = {\n",
    "    'kernel': [\"linear\",\"rbf\", \"sigmoid\"]\n",
    "}\n",
    "space_svc = {\n",
    "   **{key: hp.choice(key, value) for key, value in svc_choices.items()},\n",
    "     \"C\":hp.uniform(\"C\",0.0, 1.0)\n",
    "}\n",
    "\n",
    "space_lr = {\n",
    "    \"C\":hp.uniform(\"C\",0.0, 1.0)\n",
    "}\n",
    "\n",
    "def search_hyperparams():    \n",
    "    stores=[]\n",
    "    hops_lists = [[5]] #[[0,0, 0], [3,3, 3], [5,5, 5]]\n",
    "    for hops_list in tqdm(hops_lists):\n",
    "        store=dict({})\n",
    "        clfs = [XGBClassifier]\n",
    "        spaces= [space_xb, space_svc, space_lr]\n",
    "        space_choices= [xb_choices, svc_choices, {}]\n",
    "        hops_list = hops_list\n",
    "        attention_configs = [\n",
    "                            {'inter_layer_normalize': True,\n",
    "                             'use_pseudo_attention':True,\n",
    "                             'cosine_eps':.01,\n",
    "                             'dropout_attn': None}]\n",
    "        max_acc = 0\n",
    "        best_hops = None\n",
    "        best_user_function = None\n",
    "        best_attention_config = None\n",
    "        best_clf_params = None\n",
    "        best_clf = None\n",
    "        user_functions = [user_function for _ in hops_list]\n",
    "        for clf_idx, clf in tqdm(enumerate(clfs)):\n",
    "            space = spaces[clf_idx]\n",
    "            framework = Framework(user_functions, \n",
    "                         hops_list=hops_list, ## to obtain best for local neighborhood\n",
    "                         clfs=[],\n",
    "                         gpu_idx=0,\n",
    "                         handle_nan=0.0,\n",
    "                        attention_configs=attention_configs)\n",
    "    \n",
    "    \n",
    "            val_aggregated_feature_list = framework.get_features(val_set.x, val_set.edge_index, torch.ones(val_set.x.shape[0]).type(torch.bool))\n",
    "            train_aggregated_feature_list = framework.get_features(train_set.x, train_set.edge_index, torch.ones(train_set.x.shape[0]).type(torch.bool))## this shoould be indepent of the length of the classifiers list\n",
    "    \n",
    "            for i in range(len(val_aggregated_feature_list)):\n",
    "                print(clf)\n",
    "                print(hops_list[i])\n",
    "                X_val = val_aggregated_feature_list[i].cpu()\n",
    "                X_train = train_aggregated_feature_list[i].cpu()\n",
    "                def objective(params):\n",
    "                    model = MultiOutputClassifier(clf(**params, random_state = 42,tree_method='hist',\n",
    "                      device=\"cuda\"), n_jobs=1).fit(X_train, train_set.y)\n",
    "                    y_pred = model.predict(X_val)\n",
    "                    score = f1_score(val_set.y, y_pred, average =\"micro\")\n",
    "                    return {'loss': -score, 'status': STATUS_OK}\n",
    "                spark_trials = SparkTrials()\n",
    "                best_params = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=spark_trials)\n",
    "    \n",
    "                for key,value in space_choices[clf_idx].items():\n",
    "                    best_params[key] = value[best_params[key]]\n",
    "    \n",
    "                best_model = MultiOutputClassifier(clf(**best_params, random_state = 42,tree_method='hist',\n",
    "                      device=\"cuda\"), n_jobs=1).fit(X_train, train_set.y)\n",
    "                best_model.fit(X_train, train_set.y)\n",
    "                y_pred = best_model.predict(X_val)\n",
    "                score = f1_score(val_set.y, y_pred, average =\"micro\")\n",
    "                print(best_params)\n",
    "                if score >= max_acc:\n",
    "                    max_acc = score\n",
    "                    best_hops = hops_list[i]\n",
    "                    best_user_function = user_functions[i]\n",
    "                    best_attention_config = attention_configs[i]\n",
    "                    best_clf_params = best_params\n",
    "                    best_clf = clf\n",
    "        store[\"hops_list\"] = hops_list\n",
    "        store[\"max_acc\"] = max_acc\n",
    "        store[\"best_hops\"] = best_hops\n",
    "        store[\"best_user_function\"] = best_user_function\n",
    "        store[\"best_attention_config\"] = best_attention_config\n",
    "        store[\"best_clf_params\"] = best_clf_params\n",
    "        store[\"best_clf\"] = best_clf\n",
    "        stores.append(store)\n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f06ab-ae6b-4eee-a08a-1c64554d0e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc319c240ef4b73b494b5dbf54c0d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee39f6a070874728a095f6ea0f7a8b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/11 11:47:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Because the requested parallelism was None or a non-positive value, parallelism will be set to (64), which is Spark's default parallelism (64), or 1, whichever is greater. We recommend setting parallelism explicitly to a positive value because the total of Spark task slots is subject to cluster sizing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                           | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>    (0 + 1) / 1][Stage 1:>    (0 + 1) / 1][Stage 2:>    (0 + 1) / 1]1]\r"
     ]
    }
   ],
   "source": [
    "ppi_stores = search_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043bc84-f5f7-4203-9df9-6c04bebf211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "463ff3ad-40ec-40a7-bcfe-fb5a62a13a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7473)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(model.predict(test_set.x), test_set.y).sum()/ test_set.y.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2588b959-5113-4240-bd94-1803e7449f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1767, 50])\n"
     ]
    }
   ],
   "source": [
    "from EnsembleFramework import Framework\n",
    "\n",
    "def user_function(kwargs):\n",
    "    return  nn.functional.normalize(kwargs[\"updated_features\"] + kwargs[\"summed_neighbors\"], p = 2.0, dim = -1)\n",
    "    \n",
    "for train_batch in train_dataset:\n",
    "    framework = Framework(hops_list= [3], clfs=[], attention_configs=[{}], handle_nan=0.0, gpu_idx=0, user_functions=[user_function])\n",
    "    new_features = framework.get_features(X=train_batch.x, edge_index=train_batch.edge_index, mask=torch.ones(train_batch.x.shape[0]).type(torch.bool))\n",
    "    print(new_features[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4220e904-2c92-4fb7-aff4-ebcdfc522cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44906"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_shape = 0\n",
    "for batch in train_dataset:\n",
    "    sum_shape += batch.y.shape[0]\n",
    "sum_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cc85f6c9-a360-46b3-8858-0c8eb7080d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0f3cd842-bb1c-4041-a82a-1aedf4bf9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim,heads):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.ModuleList([nn.Linear(input_dim, hidden_dim) for _ in range(heads[0])])\n",
    "        self.layer_2 = nn.ModuleList([nn.Linear(hidden_dim*heads[0], hidden_dim) for _ in range(heads[1])])\n",
    "        self.layer_3 = nn.ModuleList([nn.Linear(hidden_dim*heads[0], output_dim) for _ in range(heads[2])])\n",
    "        self.layer_4 = nn.Linear(output_dim*heads[2], output_dim)\n",
    "        # self.layer_1 = GATConv(input_dim, hidden_dim, heads= 4, dropout=0.0, concat=True)\n",
    "        # self.layer_2 = GATConv(hidden_dim*4, hidden_dim, heads= 4, dropout=0.0, concat=True)\n",
    "        # self.layer_3 = GATConv(hidden_dim*4, output_dim, heads= 6, dropout=0.0, concat=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        hidden_dims = []\n",
    "        for lin in self.layer_1:\n",
    "            hidden = lin(x)\n",
    "            hidden = nn.functional.elu(hidden)\n",
    "            hidden_dims.append(hidden)\n",
    "        x = torch.cat(hidden_dims, dim = -1)\n",
    "        hidden_dims = []\n",
    "        for lin in self.layer_2:\n",
    "            hidden = lin(x)\n",
    "            hidden = nn.functional.elu(hidden)\n",
    "            hidden_dims.append(hidden)\n",
    "        x = torch.cat(hidden_dims, dim = -1)\n",
    "        hidden_dims = []\n",
    "        for lin in self.layer_3:\n",
    "            hidden = lin(x)\n",
    "            hidden = nn.functional.elu(hidden)\n",
    "            hidden_dims.append(hidden)\n",
    "        x = torch.cat(hidden_dims, dim = -1)\n",
    "        x = self.layer_4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c71f8462-aaf7-4fe9-8b14-c14bb31a50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train.shape[1], 64, y_train.shape[1], heads = [4,4,6]).to(device)#256\n",
    "learning_rate = 5e-3\n",
    "epochs = 200\n",
    "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f782cbd9-5465-45cc-b3ac-1b2b0095d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = Framework(hops_list= [8], clfs=[], attention_configs=[{}], handle_nan=0.0, gpu_idx=0, user_functions=[user_function])\n",
    "def train(model):\n",
    "    global epochs, loss_fn, opt\n",
    "    for epoch in range(epochs):\n",
    "        acc_loss = 0\n",
    "        batch_size = 0\n",
    "        for train_batch in train_dataset:\n",
    "            new_features = framework.get_features(X=train_batch.x, edge_index=train_batch.edge_index, mask=torch.ones(train_batch.x.shape[0]).type(torch.bool))\n",
    "            X = new_features[0].to(device)\n",
    "            y = train_batch.y.to(device)\n",
    "            edge_index = train_batch.edge_index.to(device)\n",
    "            model.train()\n",
    "            out = model(X, edge_index)\n",
    "            loss = loss_fn(out, y)\n",
    "            # train_losses.append(loss.sum().item())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            batch_size+= 1\n",
    "            acc_loss+=loss.item()\n",
    "        # print(f\"Train {acc_loss/batch_size}\")\n",
    "        evaluate_val(model)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4ec12dd1-e437-4b82-aa3b-a9ef7b037576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5430594682693481\n",
      "0.5424825549125671\n",
      "0.5424716174602509\n",
      "0.5424311757087708\n",
      "0.5424549281597137\n",
      "0.5426161289215088\n",
      "0.5421475470066071\n",
      "0.5422431528568268\n",
      "0.5421760082244873\n",
      "0.5418714284896851\n",
      "0.5427609086036682\n",
      "0.5419675409793854\n",
      "0.5447702407836914\n",
      "0.7008543312549591\n",
      "0.7002492547035217\n",
      "0.552751362323761\n",
      "0.5418860018253326\n",
      "0.542603075504303\n",
      "0.5415277481079102\n",
      "0.5415927767753601\n",
      "0.5415101051330566\n",
      "0.5412891805171967\n",
      "0.5411690175533295\n",
      "0.5411224365234375\n",
      "0.5410727560520172\n",
      "0.5410295724868774\n",
      "0.5410719513893127\n",
      "0.5411356985569\n",
      "0.541136622428894\n",
      "0.5416967570781708\n",
      "0.5413985550403595\n",
      "0.5422426760196686\n",
      "0.5407573580741882\n",
      "0.5422178208827972\n",
      "0.5409322381019592\n",
      "0.5415723025798798\n",
      "0.5414955317974091\n",
      "0.541932076215744\n",
      "0.541016012430191\n",
      "0.5405883193016052\n",
      "0.5419783592224121\n",
      "0.54085573554039\n",
      "0.5403166115283966\n",
      "0.5411010980606079\n",
      "0.5416159331798553\n",
      "0.5409170389175415\n",
      "0.5404464900493622\n",
      "0.5416751801967621\n",
      "0.5405725538730621\n",
      "0.5404481589794159\n",
      "0.5397991836071014\n",
      "0.5400949418544769\n",
      "0.5402602255344391\n",
      "0.5407506227493286\n",
      "0.5406529903411865\n",
      "0.5407743752002716\n",
      "0.5404545664787292\n",
      "0.5403009355068207\n",
      "0.5432721376419067\n",
      "0.5407310128211975\n",
      "0.5405688583850861\n",
      "0.5411551892757416\n",
      "0.5401890277862549\n",
      "0.5439452826976776\n",
      "0.5411987900733948\n",
      "0.5402423739433289\n",
      "0.5401494204998016\n",
      "0.5418431758880615\n",
      "0.5402052700519562\n",
      "0.5402687788009644\n",
      "0.5401714742183685\n",
      "0.5425098538398743\n",
      "0.5415471196174622\n",
      "0.5405732691287994\n",
      "0.5395976603031158\n",
      "0.5403328835964203\n",
      "0.5408201515674591\n",
      "0.541543573141098\n",
      "0.5406450629234314\n",
      "0.541612297296524\n",
      "0.5398477017879486\n",
      "0.5398662686347961\n",
      "0.540754646062851\n",
      "0.5406367480754852\n",
      "0.5399531126022339\n",
      "0.539938360452652\n",
      "0.5401082336902618\n",
      "0.5406744182109833\n",
      "0.5408711433410645\n",
      "0.5402820110321045\n",
      "0.5405839383602142\n",
      "0.5396251082420349\n",
      "0.5400102138519287\n",
      "0.540400356054306\n",
      "0.542256236076355\n",
      "0.5406036674976349\n",
      "0.540735512971878\n",
      "0.5404709875583649\n",
      "0.5396067500114441\n",
      "0.5432884097099304\n",
      "0.540065348148346\n",
      "0.5431266725063324\n",
      "0.5405062437057495\n",
      "0.5402617156505585\n",
      "0.5399751961231232\n",
      "0.5410932302474976\n",
      "0.5411550998687744\n",
      "0.5402598083019257\n",
      "0.5398730337619781\n",
      "0.5409702360630035\n",
      "0.540362685918808\n",
      "0.541619062423706\n",
      "0.5395153760910034\n",
      "0.5405743420124054\n",
      "0.5401121079921722\n",
      "0.540397047996521\n",
      "0.5415379703044891\n",
      "0.5389735996723175\n",
      "0.5425865948200226\n",
      "0.5406317114830017\n",
      "0.5406939089298248\n",
      "0.5395860970020294\n",
      "0.541892945766449\n",
      "0.5399045646190643\n",
      "0.5406710505485535\n",
      "0.5403002798557281\n",
      "0.5429930686950684\n",
      "0.5399688184261322\n",
      "0.5397162139415741\n",
      "0.5406554639339447\n",
      "0.5400038957595825\n",
      "0.5394739508628845\n",
      "0.5401372611522675\n",
      "0.5393098592758179\n",
      "0.5407753884792328\n",
      "0.5394270718097687\n",
      "0.5401206910610199\n",
      "0.5389834642410278\n",
      "0.5395367443561554\n",
      "0.5431360304355621\n",
      "0.5411170423030853\n",
      "0.5395903289318085\n",
      "0.5417455434799194\n",
      "0.5398286879062653\n",
      "0.5403164625167847\n",
      "0.5405929386615753\n",
      "0.5389373302459717\n",
      "0.5406466424465179\n",
      "0.540213942527771\n",
      "0.5424695312976837\n",
      "0.5394443273544312\n",
      "0.5405447781085968\n",
      "0.5405982434749603\n",
      "0.5409162640571594\n",
      "0.5394570827484131\n",
      "0.5406701564788818\n",
      "0.5388704240322113\n",
      "0.541398674249649\n",
      "0.5395902693271637\n",
      "0.5388098359107971\n",
      "0.5412142276763916\n",
      "0.5399730205535889\n",
      "0.5391678512096405\n",
      "0.5399994850158691\n",
      "0.5403358340263367\n",
      "0.5394323170185089\n",
      "0.5394059419631958\n",
      "0.5395500659942627\n",
      "0.5388049483299255\n",
      "0.5425923466682434\n",
      "0.53970867395401\n",
      "0.5445460379123688\n",
      "0.539800614118576\n",
      "0.539835125207901\n",
      "0.5391486287117004\n",
      "0.5383752286434174\n",
      "0.5401254296302795\n",
      "0.5411768555641174\n",
      "0.5395174026489258\n",
      "0.5398948192596436\n",
      "0.5408088862895966\n",
      "0.5386823415756226\n",
      "0.5450491011142731\n",
      "0.5414654314517975\n",
      "0.5478432774543762\n",
      "0.5395271182060242\n",
      "0.540590226650238\n",
      "0.5395987629890442\n",
      "0.5737351179122925\n",
      "1.4454161524772644\n",
      "0.8823598027229309\n",
      "0.6131361722946167\n",
      "0.5525300800800323\n",
      "0.5457629561424255\n",
      "0.5441403985023499\n",
      "0.5440093576908112\n",
      "0.5439939200878143\n",
      "0.543985515832901\n",
      "0.543948233127594\n",
      "0.5439224243164062\n"
     ]
    }
   ],
   "source": [
    "model = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "244e4e31-236b-4843-bcd8-da353224fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37240967304317524\n",
      "0.3811123891251061\n"
     ]
    }
   ],
   "source": [
    "evaluate_f1(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd273031-6dce-496b-9055-e0dfd0fa56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_f1(model):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        for test_batch in test_dataset:\n",
    "            new_features = framework.get_features(X=test_batch.x, edge_index=test_batch.edge_index, mask=torch.ones(test_batch.x.shape[0]).type(torch.bool))\n",
    "            X = new_features[0].to(device)\n",
    "            y = test_batch.y.to(device)\n",
    "            edge_index = test_batch.edge_index.to(device)\n",
    "            logits = model(X, edge_index)\n",
    "            loss = loss_fn(logits, y)\n",
    "            proba = torch.sigmoid(logits)\n",
    "            pred = torch.round(proba)\n",
    "            micro_f1 = f1_score(y.cpu(), pred.cpu(), average='micro')\n",
    "            print(micro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3f2c6d42-bf42-44f3-ab77-d1a36a8ed8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_val(model):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        acc_loss = 0\n",
    "        batch_size = 0\n",
    "        for test_batch in val_dataset:\n",
    "            new_features = framework.get_features(X=test_batch.x, edge_index=test_batch.edge_index, mask=torch.ones(test_batch.x.shape[0]).type(torch.bool))\n",
    "            X = new_features[0].to(device)\n",
    "            y = test_batch.y.to(device)\n",
    "            edge_index = test_batch.edge_index.to(device)\n",
    "            logits = model(X, edge_index)\n",
    "            loss = loss_fn(logits, y)\n",
    "            acc_loss+= loss.item()\n",
    "            batch_size += 1\n",
    "        print(acc_loss / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d4995382-7c46-4efd-8578-fcc9147a34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        for test_batch in test_loader:\n",
    "            X = test_batch.x.to(device)\n",
    "            y = test_batch.y.to(device)\n",
    "            edge_index = test_batch.edge_index.to(device)\n",
    "            logits = model(X, edge_index)\n",
    "            loss = loss_fn(logits, y)\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c4132ce-7f27-45d1-abc8-6884b323a393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f39725396c0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f110294-f9a3-499f-bd93-d1fd280043f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "def print_eval(y_pred):\n",
    "    micro_f1 = f1_score(test_data.y, y_pred, average='micro')\n",
    "    ratio_corr_labels = np.equal(test_data.y, y_pred).sum() / test_data.y.numel()\n",
    "    print(f\"F1-micro {str(micro_f1)} - Overall-Acc: {str(ratio_corr_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe065a8-b8f7-4959-ad5d-ac94f9a5cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5436, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "585f6560-6e56-41d4-b923-ab4d549f7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro 0.4263748920241866 - Overall-Acc: tensor(0.7467)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    y_pred = torch.round(torch.sigmoid(model(X_test))).detach().cpu()\n",
    "    print_eval(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8fe19-5205-4754-a0a4-65ddd965bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
