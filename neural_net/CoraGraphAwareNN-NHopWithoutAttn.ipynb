{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7873d1c-92e3-48d0-a654-a6068e83070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/dwalke/.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (2.1.0+cu118)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/dwalke/.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
      "Requirement already satisfied: typing-extensions in /home/dwalke/.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: filelock in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.8.1->torchmetrics) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2023.9.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: comet_ml in /home/dwalke/.local/lib/python3.10/site-packages (3.34.1)\n",
      "Requirement already satisfied: torch in /home/dwalke/.local/lib/python3.10/site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /home/dwalke/.local/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (4.19.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.4)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.31.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.32.0)\n",
      "Requirement already satisfied: simplejson in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (3.19.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet_ml) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.0.7)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.15.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (3.0.3)\n",
      "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /home/dwalke/.local/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1; python_version > \"3.5\"->comet_ml) (3.1.0)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (0.21.6)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (13.6.0)\n",
      "Requirement already satisfied: filelock in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/dwalke/.local/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: configobj in /usr/lib/python3/dist-packages (from everett[ini]<3.2.0,>=1.0.1; python_version > \"3.5\"->comet_ml) (5.0.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dwalke/.local/lib/python3.10/site-packages (from requests>=2.18.4->comet_ml) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet_ml) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet_ml) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dwalke/.local/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dwalke/.local/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dwalke/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install comet_ml torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abbf72e-5798-4787-96a7-61398ef9c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from EnsembleFramework import Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8cf0473-839d-4123-a8c2-c19d634575e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout=.0):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(input_dim , hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight) \n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight) \n",
    "        self.lin1.bias.data.fill_(0.0)\n",
    "        self.lin2.bias.data.fill_(0.0)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        torch.manual_seed(1)\n",
    "        torch.cuda.manual_seed(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        x = nn.functional.elu(x)\n",
    "        torch.manual_seed(1)\n",
    "        torch.cuda.manual_seed(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.functional.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f0ec9f-e258-48b5-afba-e8856cae978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torchmetrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Classifier():\n",
    "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    metrics = dict({})\n",
    "    metrics[\"train\"] = []\n",
    "    metrics[\"val\"] = []\n",
    "    metrics[\"test\"] = []\n",
    "    \n",
    "    losses = dict({})\n",
    "    losses[\"train\"] = []\n",
    "    losses[\"val\"] = []\n",
    "    losses[\"test\"] = []\n",
    "    \n",
    "    models = []\n",
    "    state_dicts = []\n",
    "    \n",
    "    best_state_dict = None\n",
    "    best_metric = dict({})\n",
    "    best_loss = dict({})\n",
    "    best_model = None\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, num_classes,lr=3e-2,weight_decay=1e-4, epochs=100_000, patience = 100, dropout=.6):\n",
    "        assert num_classes == 7\n",
    "        self.model = NeuralNet(input_dim, 16, num_classes, dropout).to(Classifier.device)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.dropout = dropout\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay= weight_decay)\n",
    "        self.metric_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(Classifier.device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.enough_training_for_today = False\n",
    "        self.empty()\n",
    "\n",
    "    def empty(self):\n",
    "        for key in self.metrics:\n",
    "            Classifier.metrics[key] = []\n",
    "        for key in self.losses:\n",
    "            Classifier.losses[key] = []\n",
    "        Classifier.models = []\n",
    "        Classifier.state_dicts = []\n",
    "        \n",
    "        Classifier.best_state_dict = None\n",
    "        Classifier.best_metric = dict({})\n",
    "        Classifier.best_loss = dict({})\n",
    "        Classifier.best_model = None\n",
    "\n",
    "    def fit(self, X_train, y_train, X=None, y=None):\n",
    "        X = Classifier.dict_to_device(X)\n",
    "        y = Classifier.dict_to_device(y)\n",
    "        if not torch.is_tensor(X_train):\n",
    "            X_train = torch.from_numpy(X_train)\n",
    "        if not torch.is_tensor(y_train):\n",
    "            y_train = torch.from_numpy(y_train)\n",
    "        X_train = X_train.to(self.device)\n",
    "        y_train = y_train.to(self.device)\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            logits = self.model(X_train)\n",
    "            self.optim.zero_grad()\n",
    "            loss = self.loss_fn(logits, y_train)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            self.eval_all(X, y)\n",
    "    \n",
    "            if self.enough_training_for_today:\n",
    "                self.store_best(self.patience)\n",
    "                break\n",
    "        self.store_best(0)\n",
    "\n",
    "    def eval_all(self, X, y):\n",
    "        self.evaluate(X[\"train\"], y[\"train\"], \"train\")\n",
    "        self.evaluate(X[\"val\"], y[\"val\"], \"val\")\n",
    "        self.evaluate(X[\"test\"], y[\"test\"], \"test\")\n",
    "\n",
    "    def evaluate(self, x, y, set_name):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            logits = self.model(x)\n",
    "            loss = self.loss_fn(logits, y)\n",
    "            metric = self.metric_fn(y, logits.argmax(1))\n",
    "            if set_name == \"val\" and len(Classifier.losses[set_name]) >= self.patience:\n",
    "                last_metrics = Classifier.metrics[set_name][-self.patience:]\n",
    "                last_losses = Classifier.losses[set_name][-self.patience:]\n",
    "                \n",
    "                if all([(m >= metric.item()) for m in last_metrics]) or all([(l <= loss.item()) for l in last_losses]):\n",
    "                    self.enough_training_for_today = True\n",
    "    \n",
    "            Classifier.metrics[set_name].append(metric.item())\n",
    "            Classifier.losses[set_name].append(loss.item())\n",
    "            Classifier.state_dicts.append(self.model.state_dict().copy())\n",
    "            Classifier.models.append(copy.deepcopy(self.model))\n",
    "\n",
    "    def store_best(self, offset):\n",
    "        for key, value in Classifier.metrics.items():\n",
    "                    Classifier.best_metric[key] = value[-1-offset]\n",
    "        for key, value in Classifier.losses.items():\n",
    "            Classifier.best_loss[key] = value[-1-offset]\n",
    "        Classifier.best_state_dict = Classifier.state_dicts[-1-offset]\n",
    "        Classifier.best_model = Classifier.models[-1-offset]\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_device(store_dict):\n",
    "        for key in store_dict:\n",
    "            store_dict[key] = store_dict[key].to(Classifier.device)\n",
    "        return store_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def plot(store_dict, title):\n",
    "        for key, value in store_dict.items():\n",
    "            plt.plot(value)\n",
    "        plt.legend(store_dict.keys())\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def get_params(self, **kwargs):\n",
    "        return {'lr': self.lr, 'weight_decay': self.weight_decay, 'patience': self.patience, 'dropout': self.dropout, 'input_dim': self.input_dim, 'num_classes':self.num_classes}\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        self.lr = kwargs[\"lr\"]\n",
    "        self.weight_decay = kwargs[\"weight_decay\"]\n",
    "        self.patience = kwargs[\"patience\"]\n",
    "        self.dropout = kwargs[\"dropout\"]\n",
    "        # self.input_dim = kwargs[\"input_dim\"]\n",
    "        # self.num_classes = kwargs[\"num_classes\"]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not torch.is_tensor(X):\n",
    "            X = torch.from_numpy(X)\n",
    "        X = X.to(self.device)\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            logits = self.model(X)\n",
    "            return logits.cpu().numpy()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726e2b71-0422-4ae4-83ec-94aa962cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "dataset_name = 'Cora'\n",
    "split = \"public\"\n",
    "dataset = Planetoid(root='/tmp/Cora', name=dataset_name, split=split)\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "features =  dataset[0].x\n",
    "labels =  dataset[0].y\n",
    "\n",
    "test =  dataset[0].test_mask\n",
    "train = dataset[0].train_mask\n",
    "val =  dataset[0].val_mask\n",
    "\n",
    "edge_index = dataset[0].edge_index \n",
    "edge_index = add_self_loops(edge_index)[0]\n",
    "\n",
    "X = dict({})\n",
    "X[\"train\"] = features[train]\n",
    "X[\"val\"] = features[val]\n",
    "X[\"test\"] = features[test]\n",
    "\n",
    "y = dict({})\n",
    "y[\"train\"] = labels[train]\n",
    "y[\"val\"] = labels[val]\n",
    "y[\"test\"] = labels[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18a09f6-33e7-48f8-b247-b02600462e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "def user_function(kwargs):\n",
    "    return  normalize(kwargs[\"original_features\"] + kwargs[\"summed_neighbors\"], p=2.0, dim = 1)\n",
    "hops_list = [9, 10,20,30,40,50] #0,1,2,3,4,5,6,7,8,9,10,\n",
    "framework = Framework([user_function for i in hops_list], \n",
    "                     hops_list=hops_list, ## to obtain best for local neighborhood\n",
    "                     clfs=[],\n",
    "                     gpu_idx=0,\n",
    "                     handle_nan=0.0,\n",
    "                    attention_configs=[None for i in hops_list])\n",
    "new_features_list = framework.get_features(features, edge_index, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bec939-ab87-4075-8506-b39174be3592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15: {'dropout': 0.1,\n",
       "  'lr': 0.005177241379310344,\n",
       "  'patience': 100,\n",
       "  'weight_decay': 0.001043448275862069}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "hops_to_best_params_df = pd.read_csv(\"normalized_origin_features_plus_summed_neighbors_wo_attn.csv\")\n",
    "evaluated_hops = hops_to_best_params_df.iloc[:,0].values\n",
    "best_params = hops_to_best_params_df.iloc[:,1].values\n",
    "hops_to_params = dict({hop: ast.literal_eval(best_params[i]) for i, hop in enumerate(evaluated_hops)})\n",
    "hops_to_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbecf83-3413-4a3d-9c96-b2144f2caa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b331671b024f5fa4d9e46c2114c089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14399999380111694\n",
      "0.4819999933242798\n",
      "0.6539999842643738\n",
      "0.7039999961853027\n",
      "0.8059999942779541\n",
      "0.8080000281333923\n",
      "0.8100000023841858\n",
      "0.8180000185966492\n",
      "0.8199999928474426\n",
      "0.8220000267028809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm.notebook import tqdm\n",
    "import time \n",
    "import pandas as pd\n",
    "\n",
    "space = {\n",
    "    'lr': np.linspace(1e-5, 1e-2, 30, endpoint=True),\n",
    "    'weight_decay': np.linspace(1e-5, 1e-2, 30, endpoint=True),\n",
    "    'patience': [20, 100],#100\n",
    "    'dropout':[0, 0.1, 0.2,.3,.4,.5,.6]#\n",
    "}\n",
    "\n",
    "def write_best_params(hops_to_params):\n",
    "    df = pd.DataFrame(columns=[\"best_params\"], index=hops_to_params.keys())\n",
    "    df[\"best_params\"] = hops_to_params.values()\n",
    "    df.to_csv(\"normalized_origin_features_plus_summed_neighbors_wo_attn.csv\")\n",
    "\n",
    "def transform_kwargs_fit(framework, kwargs, i):\n",
    "    new_kwargs = dict({})\n",
    "    new_kwargs[\"X\"]= dict({})\n",
    "    new_kwargs[\"y\"]= dict({})\n",
    "    \n",
    "    new_kwargs[\"X\"][\"train\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"train\"])[i]\n",
    "    new_kwargs[\"X\"][\"test\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"test\"])[i]\n",
    "    new_kwargs[\"X\"][\"val\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"val\"])[i]\n",
    "    new_kwargs[\"y\"][\"train\"] = kwargs[\"y\"][kwargs[\"train\"]]\n",
    "    new_kwargs[\"y\"][\"test\"] = kwargs[\"y\"][kwargs[\"test\"]]\n",
    "    new_kwargs[\"y\"][\"val\"] = kwargs[\"y\"][kwargs[\"val\"]]\n",
    "    return new_kwargs\n",
    "\n",
    "hops_to_score=dict({})\n",
    "\n",
    "for i, hops in enumerate(hops_list):\n",
    "    new_features = new_features_list[i]\n",
    "    num_classes = torch.unique(labels).shape[0]\n",
    "\n",
    "    param_grid = ParameterGrid(space)\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for params in tqdm(param_grid.__iter__()):\n",
    "        framework = Framework([user_function], \n",
    "                         hops_list=[hops], ## to obtain best for local neighborhood\n",
    "                         clfs=[Classifier(features.shape[1], num_classes,epochs=100_000, **params)],\n",
    "                         gpu_idx=0,\n",
    "                         handle_nan=0.0,\n",
    "                        attention_configs=[None])\n",
    "        models = framework.fit(X_train = features,\n",
    "                edge_index = edge_index,\n",
    "                y_train = labels,\n",
    "                train_mask = train,\n",
    "                kwargs_fit_list = [dict({\n",
    "                    \"X\": features,\n",
    "                    \"edge_index\": edge_index,\n",
    "                    \"y\": labels,\n",
    "                    \"train\": train,\n",
    "                    \"test\": test,\n",
    "                    \"val\": val,\n",
    "                })],\n",
    "                transform_kwargs_fit = transform_kwargs_fit)  \n",
    "        score = models[0].best_metric[\"val\"]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            print(best_score)\n",
    "            \n",
    "    hops_to_score[hops] = best_score\n",
    "    hops_to_params[hops] = best_params\n",
    "    write_best_params(hops_to_params)\n",
    "    start = time.time()\n",
    "   \n",
    "    X = dict({})\n",
    "    X[\"train\"] = new_features[train]\n",
    "    X[\"val\"] = new_features[val]\n",
    "    X[\"test\"] = new_features[test]\n",
    "    \n",
    "    y = dict({})\n",
    "    y[\"train\"] = labels[train]\n",
    "    y[\"val\"] = labels[val]\n",
    "    y[\"test\"] = labels[test]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf879104-8a0b-4047-b564-b8f02f9d25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops_to_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cb786-6e25-4024-becb-0cf27fa4dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb57fb9-a6e4-4865-b5f9-2507c5239faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424dbb8-7d66-457e-be36-77242a4dfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops_to_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6de05-a702-48fe-8fcf-9cbba048cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0ca8f-ab9d-44fa-9a54-bddc5e5a604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops_to_params = {\n",
    "    0:{'dropout': 0,\n",
    " 'lr': 0.021631578947368422,\n",
    " 'patience': 100,\n",
    " 'weight_decay': 7.631578947368422e-05},\n",
    "    1: {'dropout': 0.1,\n",
    "  'lr': 0.0006989655172413794,\n",
    "  'patience': 100,\n",
    "  'weight_decay': 0.001043448275862069},\n",
    " 2: {'dropout': 0,\n",
    "  'lr': 0.004488275862068966,\n",
    "  'patience': 100,\n",
    "  'weight_decay': 0.004143793103448276},\n",
    " 3: {'dropout': 0,\n",
    "  'lr': 0.0006989655172413794,\n",
    "  'patience': 100,\n",
    "  'weight_decay': 0.002076896551724138},\n",
    " 5: {'dropout': 0,\n",
    "  'lr': 0.001043448275862069,\n",
    "  'patience': 100,\n",
    "  'weight_decay': 0.003110344827586207},\n",
    " 10: {'dropout': 0,\n",
    "  'lr': 0.003110344827586207,\n",
    "  'patience': 100,\n",
    "  'weight_decay': 0.0013879310344827587}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e36f81-cf66-4d21-aa00-7305f507c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "def transform_kwargs_fit(framework, kwargs, i):\n",
    "    new_kwargs = dict({})\n",
    "    new_kwargs[\"X\"]= dict({})\n",
    "    new_kwargs[\"y\"]= dict({})\n",
    "    \n",
    "    new_kwargs[\"X\"][\"train\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"train\"])[i]\n",
    "    new_kwargs[\"X\"][\"test\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"test\"])[i]\n",
    "    new_kwargs[\"X\"][\"val\"] = framework.get_features(kwargs[\"X\"], kwargs[\"edge_index\"], kwargs[\"val\"])[i]\n",
    "    new_kwargs[\"y\"][\"train\"] = kwargs[\"y\"][kwargs[\"train\"]]\n",
    "    new_kwargs[\"y\"][\"test\"] = kwargs[\"y\"][kwargs[\"test\"]]\n",
    "    new_kwargs[\"y\"][\"val\"] = kwargs[\"y\"][kwargs[\"val\"]]\n",
    "    return new_kwargs\n",
    "\n",
    "hops_lists =[[0,0], [0,1], [0,2], [0,3], [0,5], [0,10], [0,2,10]]\n",
    "for hops_list in hops_lists:\n",
    "    num_classes = torch.unique(labels).shape[0]\n",
    "    \n",
    "    framework = Framework([user_function for i in hops_list], \n",
    "                         hops_list=hops_list, ## to obtain best for local neighborhood\n",
    "                         clfs=[Classifier(features.shape[1], num_classes,epochs=100_000, **hops_to_params[hops]) for hops in hops_list],\n",
    "                         gpu_idx=0,\n",
    "                         handle_nan=0.0,\n",
    "                        attention_configs=[None for i in hops_list])\n",
    "    start = time.time()\n",
    "    models = framework.fit(X_train = features,\n",
    "                edge_index = edge_index,\n",
    "                y_train = labels,\n",
    "                train_mask = train,\n",
    "                kwargs_fit_list = [dict({\n",
    "                    \"X\": features,\n",
    "                    \"edge_index\": edge_index,\n",
    "                    \"y\": labels,\n",
    "                    \"train\": train,\n",
    "                    \"test\": test,\n",
    "                    \"val\": val,\n",
    "                }) for i in hops_list],\n",
    "                transform_kwargs_fit = transform_kwargs_fit)    \n",
    "    print(f\"Required training time: {str(time.time() - start)}\")\n",
    "    y_pred = framework.predict(features, edge_index, test)\n",
    "    y_pred_val = framework.predict(features, edge_index, val)\n",
    "    print(f\"Hops-list {str(hops_list)}; Test-acc {str(accuracy_score(labels[test], y_pred))}; Val acc {str(accuracy_score(labels[val], y_pred_val))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a7e1f-7fd2-44d4-9cd3-d9d20b89fd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
