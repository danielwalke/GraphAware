{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7873d1c-92e3-48d0-a654-a6068e83070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/dwalke/.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (1.26.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/dwalke/.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
      "Requirement already satisfied: typing-extensions in /home/dwalke/.local/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: filelock in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.8.1->torchmetrics) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dwalke/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->torchmetrics) (12.3.52)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: comet_ml in /home/dwalke/.local/lib/python3.10/site-packages (3.34.1)\n",
      "Requirement already satisfied: torch in /home/dwalke/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/dwalke/.local/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (4.19.1)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.4)\n",
      "Requirement already satisfied: python-box<7.0.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.31.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.32.0)\n",
      "Requirement already satisfied: simplejson in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (3.19.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet_ml) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (2.0.7)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (1.15.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (3.0.3)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (3.1.0)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (0.21.6)\n",
      "Requirement already satisfied: rich>=13.3.2 in /home/dwalke/.local/lib/python3.10/site-packages (from comet_ml) (13.6.0)\n",
      "Requirement already satisfied: filelock in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dwalke/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: numpy in /home/dwalke/.local/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/dwalke/.local/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: configobj in /usr/lib/python3/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/dwalke/.local/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dwalke/.local/lib/python3.10/site-packages (from requests>=2.18.4->comet_ml) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet_ml) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet_ml) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dwalke/.local/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dwalke/.local/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dwalke/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install comet_ml torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8cf0473-839d-4123-a8c2-c19d634575e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout=.0):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(input_dim , hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight) \n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight) \n",
    "        self.lin1.bias.data.fill_(0.0)\n",
    "        self.lin2.bias.data.fill_(0.0)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        torch.manual_seed(1)\n",
    "        torch.cuda.manual_seed(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin1(x)\n",
    "        x = nn.functional.elu(x)\n",
    "        torch.manual_seed(1)\n",
    "        torch.cuda.manual_seed(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.functional.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5f0ec9f-e258-48b5-afba-e8856cae978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torchmetrics import Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Classifier():\n",
    "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    metrics = dict({})\n",
    "    metrics[\"train\"] = []\n",
    "    metrics[\"val\"] = []\n",
    "    metrics[\"test\"] = []\n",
    "    \n",
    "    losses = dict({})\n",
    "    losses[\"train\"] = []\n",
    "    losses[\"val\"] = []\n",
    "    losses[\"test\"] = []\n",
    "    \n",
    "    models = []\n",
    "    state_dicts = []\n",
    "    \n",
    "    best_state_dict = None\n",
    "    best_metric = dict({})\n",
    "    best_loss = dict({})\n",
    "    best_model = None\n",
    "    \n",
    "    \n",
    "    def __init__(self, X, y,lr=3e-2,weight_decay=1e-4, epochs=100_000, patience = 100, dropout=.6):\n",
    "        num_classes = torch.unique(y[\"train\"]).shape[0]\n",
    "        assert num_classes == 7\n",
    "        self.model = NeuralNet(X[\"train\"].shape[1], 16, num_classes, dropout).to(Classifier.device)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.dropout = dropout\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay= weight_decay)\n",
    "        self.metric_fn = Accuracy(task=\"multiclass\", num_classes=num_classes).to(Classifier.device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.enough_training_for_today = False\n",
    "        self.empty()\n",
    "\n",
    "    def empty(self):\n",
    "        for key in self.metrics:\n",
    "            Classifier.metrics[key] = []\n",
    "        for key in self.losses:\n",
    "            Classifier.losses[key] = []\n",
    "        Classifier.models = []\n",
    "        Classifier.state_dicts = []\n",
    "        \n",
    "        Classifier.best_state_dict = None\n",
    "        Classifier.best_metric = dict({})\n",
    "        Classifier.best_loss = dict({})\n",
    "        Classifier.best_model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = Classifier.dict_to_device(X)\n",
    "        y = Classifier.dict_to_device(y)\n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            logits = self.model(X[\"train\"])\n",
    "            self.optim.zero_grad()\n",
    "            loss = self.loss_fn(logits, y[\"train\"])\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            \n",
    "            self.eval_all(X, y)\n",
    "    \n",
    "            if self.enough_training_for_today:\n",
    "                self.store_best(self.patience)\n",
    "                break\n",
    "        self.store_best(0)\n",
    "\n",
    "    def eval_all(self, X, y):\n",
    "        self.evaluate(X[\"train\"], y[\"train\"], \"train\")\n",
    "        self.evaluate(X[\"val\"], y[\"val\"], \"val\")\n",
    "        self.evaluate(X[\"test\"], y[\"test\"], \"test\")\n",
    "\n",
    "    def evaluate(self, x, y, set_name):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            logits = self.model(x)\n",
    "            loss = self.loss_fn(logits, y)\n",
    "            metric = self.metric_fn(y, logits.argmax(1))\n",
    "            if set_name == \"val\" and len(Classifier.losses[set_name]) >= self.patience:\n",
    "                last_metrics = Classifier.metrics[set_name][-self.patience:]\n",
    "                last_losses = Classifier.losses[set_name][-self.patience:]\n",
    "                \n",
    "                if all([(m >= metric.item()) for m in last_metrics]) or all([(l <= loss.item()) for l in last_losses]):\n",
    "                    self.enough_training_for_today = True\n",
    "    \n",
    "            Classifier.metrics[set_name].append(metric.item())\n",
    "            Classifier.losses[set_name].append(loss.item())\n",
    "            Classifier.state_dicts.append(self.model.state_dict().copy())\n",
    "            Classifier.models.append(copy.deepcopy(self.model))\n",
    "\n",
    "    def store_best(self, offset):\n",
    "        for key, value in Classifier.metrics.items():\n",
    "                    Classifier.best_metric[key] = value[-1-offset]\n",
    "        for key, value in Classifier.losses.items():\n",
    "            Classifier.best_loss[key] = value[-1-offset]\n",
    "        Classifier.best_state_dict = Classifier.state_dicts[-1-offset]\n",
    "        Classifier.best_model = Classifier.models[-1-offset]\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_device(store_dict):\n",
    "        for key in store_dict:\n",
    "            store_dict[key] = store_dict[key].to(Classifier.device)\n",
    "        return store_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def plot(store_dict, title):\n",
    "        for key, value in store_dict.items():\n",
    "            plt.plot(value)\n",
    "        plt.legend(store_dict.keys())\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def get_params(self, **kwargs):\n",
    "        return {'lr': self.lr, 'weight_decay': self.weight_decay, 'patience': self.patience, 'dropout': self.dropout, 'X': self.X, 'y':self.y}\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        self.lr = kwargs[\"lr\"]\n",
    "        self.weight_decay = kwargs[\"weight_decay\"]\n",
    "        self.patience = kwargs[\"patience\"]\n",
    "        self.dropout = kwargs[\"dropout\"]\n",
    "        # self.X = kwargs[\"X\"]\n",
    "        # self.y = kwargs[\"y\"]\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.inference_mode():\n",
    "            self.model.eval()\n",
    "            logits = self.model(x)\n",
    "            return logits.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "726e2b71-0422-4ae4-83ec-94aa962cca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "dataset_name = 'Cora'\n",
    "split = \"public\"\n",
    "dataset = Planetoid(root='/tmp/Cora', name=dataset_name, split=split)\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "features =  dataset[0].x\n",
    "labels =  dataset[0].y\n",
    "\n",
    "test =  dataset[0].test_mask\n",
    "train = dataset[0].train_mask\n",
    "val =  dataset[0].val_mask\n",
    "\n",
    "edge_index = dataset[0].edge_index \n",
    "edge_index = add_self_loops(edge_index)[0]\n",
    "\n",
    "X = dict({})\n",
    "X[\"train\"] = features[train]\n",
    "X[\"val\"] = features[val]\n",
    "X[\"test\"] = features[test]\n",
    "\n",
    "y = dict({})\n",
    "y[\"train\"] = labels[train]\n",
    "y[\"val\"] = labels[val]\n",
    "y[\"test\"] = labels[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dbecf83-3413-4a3d-9c96-b2144f2caa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfa0240cee2417da9309ad5f13ce150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180000066757202\n",
      "0.5199999809265137\n",
      "0.5220000147819519\n",
      "0.5260000228881836\n",
      "0.527999997138977\n",
      "0.5299999713897705\n",
      "0.5519999861717224\n",
      "0.5559999942779541\n",
      "0.5600000023841858\n",
      "0.5740000009536743\n",
      "0.5759999752044678\n",
      "0.578000009059906\n",
      "0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "space = {\n",
    "    'lr': np.linspace(1e-3, 5e-2, 20, endpoint=True),\n",
    "    'weight_decay': np.linspace(1e-5, 1e-4, 20, endpoint=True),\n",
    "    'patience': [100],\n",
    "    'dropout':[0, 0.1]\n",
    "}\n",
    "param_grid = ParameterGrid(space)\n",
    "best_score = 0\n",
    "best_params = None\n",
    "for params in tqdm(param_grid.__iter__()):\n",
    "    model = Classifier(X, y,epochs=100_000, **params)\n",
    "    model.fit(X, y)\n",
    "    score = model.best_metric[\"val\"]\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "        print(best_score)\n",
    "        # model.plot(model.losses, \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9424dbb8-7d66-457e-be36-77242a4dfe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0,\n",
       " 'lr': 0.021631578947368422,\n",
       " 'patience': 100,\n",
       " 'weight_decay': 7.631578947368422e-05}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7825d09-779f-427a-b97a-3bd37daa81ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799999833106995"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(X, y,epochs=100_000, **best_params)\n",
    "model.fit(X, y)\n",
    "model.best_metric[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09bbdb53-dd5d-4372-856d-d276a2899c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.6194049499922445, 'lr': 0.7336817054089763, 'patience': 200, 'weight_decay': 0.009702600907689131}        \n",
      "1.9492374658584595                                                                                                      \n",
      "{'dropout': 0.05957535494563837, 'lr': 0.21209557428918735, 'patience': 10, 'weight_decay': 0.03408253177377467}        \n",
      "1.9469952583312988                                                                                                      \n",
      "{'dropout': 0.6620934038962162, 'lr': 0.01198363617096886, 'patience': 20, 'weight_decay': 0.048745160353659424}        \n",
      "1.946196436882019                                                                                                       \n",
      "{'dropout': 0.33414637507289574, 'lr': 0.04764940480239453, 'patience': 10, 'weight_decay': 0.005732789853636135}       \n",
      "1.9461889266967773                                                                                                      \n",
      "  4%|█▉                                               | 4/100 [00:02<01:09,  1.37trial/s, best loss: 1.9461889266967773]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mlosses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mlosses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n\u001b[0;32m---> 17\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[108], line 12\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier(X, y,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100_000\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mempty()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# score = model.best_metric[\"val\"]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n",
      "Cell \u001b[0;32mIn[106], line 66\u001b[0m, in \u001b[0;36mClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     63\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menough_training_for_today:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_best(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience)\n",
      "Cell \u001b[0;32mIn[106], line 74\u001b[0m, in \u001b[0;36mClassifier.eval_all\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m], y[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], y[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[106], line 93\u001b[0m, in \u001b[0;36mClassifier.evaluate\u001b[0;34m(self, x, y, set_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m Classifier\u001b[38;5;241m.\u001b[39mmetrics[set_name]\u001b[38;5;241m.\u001b[39mappend(metric\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     92\u001b[0m Classifier\u001b[38;5;241m.\u001b[39mlosses[set_name]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 93\u001b[0m Classifier\u001b[38;5;241m.\u001b[39mstate_dicts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m     94\u001b[0m Classifier\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1897\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1897\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1899\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1894\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[0;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   1893\u001b[0m     hook(\u001b[38;5;28mself\u001b[39m, prefix, keep_vars)\n\u001b[0;32m-> 1894\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_to_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._save_to_state_dict\u001b[0;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m         destination[prefix \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m param \u001b[38;5;28;01mif\u001b[39;00m keep_vars \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from hyperopt import fmin, tpe, hp,STATUS_OK\n",
    "# patience = [10, 20, 50, 100, 200]\n",
    "# space = {\n",
    "#     'lr': hp.loguniform('lr', -5, -.3),\n",
    "#     'weight_decay': hp.loguniform('weight_decay', -6, -3),\n",
    "#     'patience': hp.choice('patience', patience),\n",
    "#     'dropout':hp.uniform('dropout', 0.0, 0.8),\n",
    "# }\n",
    "# def objective(params):\n",
    "#     model = Classifier(X, y,epochs=100_000, **params)\n",
    "#     model.empty()\n",
    "#     model.fit(X, y)\n",
    "#     # score = model.best_metric[\"val\"]\n",
    "#     print(params)\n",
    "#     print(model.losses[\"val\"][-1])\n",
    "#     return {'loss': model.losses[\"val\"][-1], 'status': STATUS_OK}\n",
    "# best_params = fmin(objective, space, algo=tpe.suggest, max_evals=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
