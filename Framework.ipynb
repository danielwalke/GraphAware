{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9325db63",
   "metadata": {},
   "source": [
    "## SBC Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2938ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc84a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/git/graph_aware_ml/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n",
      "/home/dwalke/git/graph_aware_ml/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n",
      "/home/dwalke/git/graph_aware_ml/dataAnalysis/data/Filter.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['Label'] = self.data['Diagnosis']\n"
     ]
    }
   ],
   "source": [
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"./sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data, mimic_data = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d882efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "max_Id = data[\"Id\"].unique().max()\n",
    "gw_data = data_analysis.get_gw_testing_data().copy(deep=True)\n",
    "gw_data = gw_data.assign(Id=lambda x: x.Id + max_Id)\n",
    "data = pd.concat((data, gw_data))\n",
    "data = data.sort_values([\"Id\", \"Time\"])\n",
    "data = data.reset_index(drop=True)\n",
    "popped_index = data.pop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfa5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\"\n",
    "\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a1e4e",
   "metadata": {},
   "source": [
    "## Edge index construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52567628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "def get_edge_index(dataset):\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    source_edge_index = []\n",
    "    target_edge_index = []\n",
    "\n",
    "    for Id, group in dataset.groupby(\"Id\"):\n",
    "        indices = group.index\n",
    "        offset = indices[0]\n",
    "        num_nodes = len(indices)\n",
    "        edge_index = torch.zeros((2, sum(range(num_nodes + 1))), dtype=torch.long)+offset\n",
    "\n",
    "        ## Self edges\n",
    "        edge_index[:, 0:num_nodes] = (torch.arange(num_nodes) + offset).view(1, -1)\n",
    "        idx = num_nodes\n",
    "        for i in range(1, num_nodes):\n",
    "            edge_index[1, idx:idx + i] = i+offset\n",
    "            edge_index[0, idx:idx + i] = torch.arange(i)+offset\n",
    "            idx += i\n",
    "\n",
    "        source_edge_index.extend(edge_index[0, :].numpy().tolist())\n",
    "        target_edge_index.extend(edge_index[1, :].numpy().tolist())\n",
    "\n",
    "    edge_index = np.asarray([np.asarray(source_edge_index), np.asarray(target_edge_index)])\n",
    "    edge_index = torch.tensor(edge_index)\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31e237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edge_index = get_edge_index(data[(data[\"Set\"] == \"Validation\") & (data[\"Center\"] == \"Leipzig\")])\n",
    "test_gw_edge_index = get_edge_index(data[(data[\"Set\"] == \"Validation\") & (data[\"Center\"] == \"Greifswald\")])\n",
    "train_edge_index = get_edge_index(data[data[\"Set\"] == \"Training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beddbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import FEATURES, LABEL_COLUMN_NAME\n",
    "\n",
    "train_mask = data[\"Set\"] == \"Training\"\n",
    "X_train = data.loc[train_mask, FEATURES].values\n",
    "y_train = data.loc[train_mask, LABEL_COLUMN_NAME].values\n",
    "\n",
    "test_mask = (data[\"Set\"] == \"Validation\") & (data[\"Center\"] == \"Leipzig\")\n",
    "X_test = data.loc[test_mask, FEATURES].values\n",
    "y_test = data.loc[test_mask, LABEL_COLUMN_NAME].values\n",
    "\n",
    "test_gw_mask = (data[\"Set\"] == \"Validation\") & (data[\"Center\"] == \"Greifswald\")\n",
    "X_test_gw = data.loc[test_gw_mask, FEATURES].values\n",
    "y_test_gw = data.loc[test_gw_mask, LABEL_COLUMN_NAME].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d516c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_edge_index(edge_index):\n",
    "    rev_edge_index = torch.zeros_like(edge_index)\n",
    "    index = torch.LongTensor([1,0])\n",
    "    rev_edge_index[index] = edge_index\n",
    "    return rev_edge_index\n",
    "\n",
    "rev_train_edge_index = reverse_edge_index(train_edge_index)\n",
    "rev_test_edge_index = reverse_edge_index(test_edge_index)\n",
    "rev_test_gw_edge_index = reverse_edge_index(test_gw_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e45058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "undir_train_edge_index = to_undirected(train_edge_index)\n",
    "undir_test_edge_index = to_undirected(test_edge_index)\n",
    "undir_test_gw_edge_index = to_undirected(test_gw_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2717fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def user_function(origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors):\n",
    "    return updated_features - sum_neighbors / num_neighbors\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = random_forest = RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
    "                                             min_samples_leaf=0.0001,\n",
    "                                             min_samples_split=0.0055,\n",
    "                                             n_estimators=700, random_state=42, n_jobs=-1)\n",
    "# XGBClassifier(tree_method='gpu_hist', \n",
    "#                            scale_pos_weight = 70,\n",
    "#                            n_estimators=1000,\n",
    "#                            max_depth=2,\n",
    "#                            eta=0.1,\n",
    "#                            min_child_weight = 7,\n",
    "#                            max_delta_step= 7,\n",
    "#                            sampling_method= \"uniform\")\n",
    "\n",
    "clf_nh = random_forest = RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
    "                                                min_samples_leaf=0.0001,\n",
    "                                                min_samples_split=0.0055,\n",
    "                                                n_estimators=500, random_state=42, n_jobs=-1)\n",
    "\n",
    "bst = XGBClassifier( tree_method='gpu_hist', \n",
    "                    n_estimators=1000,\n",
    "                    max_depth=2,\n",
    "                    eta=0.1,\n",
    "                    min_child_weight = 7,\n",
    "                    max_delta_step= 7,\n",
    "                    sampling_method= \"uniform\")\n",
    "\n",
    "bst_nh = XGBClassifier( tree_method='gpu_hist', \n",
    "                       n_estimators=1000,\n",
    "                       max_depth=2,\n",
    "                       eta=0.1,\n",
    "                       min_child_weight = 7,\n",
    "                       max_delta_step= 7,\n",
    "                       sampling_method= \"uniform\")\n",
    "feature_based_aggregation:Feature_based_aggregation = {\n",
    "    \"concat\": True,\n",
    "    \"combined_clf\": bst,\n",
    "    'n_estimators':1\n",
    "}\n",
    "\n",
    "classifier_based_aggregation:Classifier_based_aggregation = {\n",
    "    \"clf_list\": [clf, clf_nh],\n",
    "    'n_estimators':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bcd9402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
       "                        min_samples_leaf=0.0001, min_samples_split=0.0055,\n",
       "                        n_estimators=700, n_jobs=-1, random_state=42),\n",
       " RandomForestClassifier(class_weight={0: 0.0025, 1: 1}, max_leaf_nodes=79,\n",
       "                        min_samples_leaf=0.0001, min_samples_split=0.0055,\n",
       "                        n_estimators=500, n_jobs=-1, random_state=42))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework = Framework(\"diff_of_updated_mean\", hops=2, use_feature_based_aggregation = False,\n",
    "          feature_based_aggregation = feature_based_aggregation,\n",
    "            classifier_based_aggregation = classifier_based_aggregation, gpu_idx = 1, handle_nan = 0, normalize=False, use_pseudo_attention=False, cosine_eps = None)\n",
    "\n",
    "framework.fit(X_train, rev_train_edge_index, y_train, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b3d27cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.945359</td>\n",
       "      <td>0.051880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GW</th>\n",
       "      <td>0.943195</td>\n",
       "      <td>0.030419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUROC     AUPRC\n",
       "L   0.945359  0.051880\n",
       "GW  0.943195  0.030419"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "y_score = framework.predict_proba(X_test, rev_test_edge_index, None)[:,1]\n",
    "y_score_gw = framework.predict_proba(X_test_gw, rev_test_gw_edge_index, None)[:,1]\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_score)\n",
    "auroc_gw = roc_auc_score(y_test_gw, y_score_gw)\n",
    "\n",
    "auc_precision_recall = average_precision_score(y_test, y_score)\n",
    "auc_precision_recall_gw = average_precision_score(y_test_gw, y_score_gw)\n",
    "\n",
    "pd.DataFrame([[auroc, auc_precision_recall], [auroc_gw, auc_precision_recall_gw]], columns=[\"AUROC\", \"AUPRC\"], index=[\"L\", \"GW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9ce88b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You need to provide two grid parameter, one for each classifier!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     16\u001b[0m param_grid\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m800\u001b[39m, \u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 19\u001b[0m \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev_train_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 363\u001b[0m, in \u001b[0;36mFramework.grid_search\u001b[0;34m(self, X_train, edge_index, y_train, train_mask, grid_params, **grid_kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m y_train \u001b[38;5;241m=\u001b[39m Framework\u001b[38;5;241m.\u001b[39mget_label_tensor(y_train)\n\u001b[1;32m    361\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train[train_mask]\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_grid_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m X_train, neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_features(X_train, edge_index, train_mask)        \n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_feature_based_aggregation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_based_aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 347\u001b[0m, in \u001b[0;36mFramework.validate_grid_input\u001b[0;34m(self, grid_params)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to provide grid parameter for the classifier!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(grid_params) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_feature_based_aggregation:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to provide two grid parameter, one for each classifier!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: You need to provide two grid parameter, one for each classifier!"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def get_best_estimator(model, param_grid):\n",
    "    grid = GridSearchCV(\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    estimator=model,\n",
    "    scoring=['accuracy'],\n",
    "    refit=\"accuracy\",\n",
    "    return_train_score=True,\n",
    "    param_grid=param_grid,\n",
    "    verbose= 10\n",
    "    )\n",
    "    grid.fit(X_train, rev_train_edge_index, y_train, None)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "param_grid={\n",
    "        'n_estimators': range(200, 800, 100),\n",
    "}\n",
    "framework.grid_search(X_train, rev_train_edge_index, y_train, None, [param_grid], n_jobs=-1,\n",
    "    cv=3,\n",
    "    scoring=['accuracy'],\n",
    "    refit=\"accuracy\",\n",
    "    return_train_score=True,\n",
    "    verbose= 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9a164",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e6c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import TypedDict\n",
    "import numpy \n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class Feature_based_aggregation(TypedDict):\n",
    "    \"\"\"\n",
    "    A class for giving type hints for the dict feature_based_aggregation.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    concat:bool\n",
    "        A boolean whether to concat or add target node features and neighborhood features\n",
    "    combined_clf: BaseEstimator\n",
    "        A classifier (combined_clf) from sklearn applied to the aggregated features \n",
    "        (target node features and neighborhood features)\n",
    "    \"\"\"\n",
    "    combined_clf: BaseEstimator\n",
    "    concat: bool\n",
    "    n_estimators: int ## rather list of classifiers??\n",
    "        \n",
    "class Classifier_based_aggregation(TypedDict):\n",
    "    \"\"\"\n",
    "    A class for giving type hints for the dict classifier_based_aggregation.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    clf_list: tuple[BaseEstimator, BaseEstimator]\n",
    "        A tuple classifiers from sklearn - one applied to the target node features \n",
    "        and the other one to the neighborhood features\n",
    "    \"\"\"\n",
    "    clf_list: tuple[BaseEstimator, BaseEstimator]\n",
    "    n_estimators: int ## other data structure?,\n",
    "    weights: tuple[float, float]\n",
    "    #weight: float weights influence of self-awareness to neighborhood-awareness\n",
    "\n",
    "USER_FUNCTIONS = {\n",
    "    'sum': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: sum_neighbors,\n",
    "    'mean': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: sum_neighbors / num_neighbors,\n",
    "    'diff_of_origin_mean': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: origin_features - sum_neighbors / num_neighbors,\n",
    "    'diff_of_updated_mean': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: updated_features - sum_neighbors / num_neighbors,\n",
    "    'sum_of_origin_mean': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: origin_features + sum_neighbors / num_neighbors,\n",
    "    'sum_of_updated_mean': lambda origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop: updated_features + sum_neighbors / num_neighbors,\n",
    "}\n",
    "\n",
    "## VerbesserungsvorschlÃ¤ge? -> besonders um Acc zu verbessern\n",
    "## heterogene Graphen?\n",
    "##TODO More input_validation, grid search method whoch accepts the same params\n",
    "class Framework:\n",
    "    \"\"\"\n",
    "    A class for giving Machine learning algorithms additional graph-awareness.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_function:def|str\n",
    "        a user-defined function applied to the aggregation of neighboring nodes or a string from USER_FUNCTIONS\n",
    "    hops:int\n",
    "        number of hops to aggregate\n",
    "    use_feature_based_aggregation:bool\n",
    "        Boolean whether to use feature-based aggregation or classifier-based aggregation\n",
    "    feature_based_aggregation:Feature_based_aggregation\n",
    "        dictionary containing a classifier (combined_clf) applied to the aggregated features\n",
    "        and a boolean (concat) indicating whether to concat or add up features from ttarget-nodes and it's neighbors\n",
    "    classifier_based_aggregation:Classifier_based_aggregation\n",
    "        dictionary containing a tuple of classifiers (clf_list), one applied to the features of the target node\n",
    "        and the other one to the features of the aggregated features of the neighbors\n",
    "    gpu_idx:int|None=None\n",
    "        Optional index parameter for using GPU device (None or an integer like 0 depending the GPU index)\n",
    "    handle_nan:float|None|int=None\n",
    "        Optional parameter whether to handle nan values after applying the user-defined function (e.g., dividing by 0)\n",
    "        Replaces all nan values with the given value\n",
    "    normalize:bool=True (BETA)\n",
    "        Optional boolean whether or not to normalize features? \n",
    "    use_pseudo_attention = True (BETA)\n",
    "        Optional boolean whether or not to apply a pseudo attention mechanism \n",
    "        (weighted aggregation based on cosine-similarity)\n",
    "    device:torch.DeviceObjType\n",
    "        Torch device for computation (cpu) or gpu if available and requested\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    make_tensors()\n",
    "        Checks correct type and format of input features and edge_index\n",
    "        And transfers possible numby arrays to torch tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    ## min max aggregation might also work as future idea (https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_reduce_.html) -> in Beta\n",
    "\n",
    "    def __init__(self, user_function, \n",
    "                 hops:int,\n",
    "                 use_feature_based_aggregation:bool,\n",
    "                 feature_based_aggregation:Feature_based_aggregation,\n",
    "                 classifier_based_aggregation:Classifier_based_aggregation,\n",
    "                 gpu_idx:int|None=None,\n",
    "                 handle_nan:float|None=None,\n",
    "                 normalize:bool=False,\n",
    "                 use_pseudo_attention = False,\n",
    "                 cosine_eps:float|None=None,\n",
    "                dropout_attn:float|None = None) -> None:\n",
    "        self.user_function = user_function\n",
    "        self.hops:int = hops\n",
    "        self.use_feature_based_aggregation:bool = use_feature_based_aggregation\n",
    "        self.feature_based_aggregation:Feature_based_aggregation = feature_based_aggregation\n",
    "        self.classifier_based_aggregation:Classifier_based_aggregation = classifier_based_aggregation\n",
    "        self.gpu_idx:int|None = gpu_idx\n",
    "        self.handle_nan:float|int|None = handle_nan\n",
    "        self.normalize:bool = normalize\n",
    "        self.use_pseudo_attention:bool = use_pseudo_attention\n",
    "        self.cosine_eps:float|None = cosine_eps\n",
    "        self.dropout_attn:float|None = dropout_attn\n",
    "        self.device:torch.DeviceObjType = torch.device(f\"cuda:{str(self.gpu_idx)}\") if self.gpu_idx is not None and torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    def update_user_function(self):\n",
    "        if self.user_function in USER_FUNCTIONS:\n",
    "            self.user_function = USER_FUNCTIONS[self.user_function]\n",
    "        else:\n",
    "            raise Exception(f\"Only the following string values are valid inputs for the user function: {[key for key in USER_FUNCTIONS]}. You can also specify your own function for aggregatioon.\")\n",
    "    def get_features(self,\n",
    "                     X:torch.FloatTensor|numpy._typing.NDArray,\n",
    "                     edge_index:torch.LongTensor|numpy._typing.NDArray,\n",
    "                     mask:torch.BoolTensor|numpy._typing.NDArray,\n",
    "                    is_training:bool = False) -> tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        if mask is None:\n",
    "            mask = torch.ones(X.shape[0]).type(torch.bool)\n",
    "        if isinstance(self.user_function, str):\n",
    "            self.update_user_function()\n",
    "        ## To tensor\n",
    "        X = Framework.get_feature_tensor(X)\n",
    "        edge_index = Framework.get_edge_index_tensor(edge_index)\n",
    "        mask = Framework.get_mask_tensor(mask)\n",
    "        \n",
    "        ## To device\n",
    "        X = self.shift_tensor_to_device(X)\n",
    "        edge_index = self.shift_tensor_to_device(edge_index)\n",
    "        mask = self.shift_tensor_to_device(mask)\n",
    "        \n",
    "        if self.hops <= 0:\n",
    "            return (X[mask], None)\n",
    "        \n",
    "        ## Aggregate\n",
    "        neighbor_features = self.aggregate(X, edge_index, is_training)\n",
    "        \n",
    "        return (X[mask], neighbor_features[mask])\n",
    "    \n",
    "    def fit(self,\n",
    "            X_train:torch.FloatTensor|numpy._typing.NDArray,\n",
    "            edge_index:torch.LongTensor|numpy._typing.NDArray,\n",
    "            y_train:torch.LongTensor|numpy._typing.NDArray,\n",
    "            train_mask:torch.BoolTensor|numpy._typing.NDArray|None,\n",
    "            kwargs_list = None\n",
    "            ) -> BaseEstimator:   \n",
    "        if train_mask is None:\n",
    "            train_mask = torch.ones(X_train.shape[0]).type(torch.bool)\n",
    "        y_train = Framework.get_label_tensor(y_train)\n",
    "        y_train = y_train[train_mask]\n",
    "        \n",
    "        self.validate_input()\n",
    "        \n",
    "        X_train, neighbors = self.get_features(X_train, edge_index, train_mask, True)        \n",
    "        \n",
    "        if self.use_feature_based_aggregation and self.feature_based_aggregation is not None:\n",
    "            concat:bool = self.feature_based_aggregation[\"concat\"]\n",
    "            clf:BaseEstimator = self.feature_based_aggregation[\"combined_clf\"]\n",
    "            out_clfs:list[BaseEstimator] = []\n",
    "            if neighbors is not None:\n",
    "                X_train:torch.FloatTensor = torch.concat((X_train, neighbors), dim = 1) if concat else torch.add(X_train, neighbors)\n",
    "            for i in range(self.feature_based_aggregation[\"n_estimators\"]):\n",
    "                clf_clone = clone(clf)\n",
    "                if kwargs_list and len(kwargs_list) == 1:\n",
    "                    clf_clone.fit(X_train.cpu().numpy(), y_train,**kwargs_list[0])\n",
    "                else:\n",
    "                    clf_clone.fit(X_train.cpu().numpy(), y_train)\n",
    "                out_clfs.append(clf_clone)\n",
    "            self.feature_based_aggregation[\"trained_clfs\"] = out_clfs\n",
    "            return self.feature_based_aggregation[\"trained_clfs\"][0] if len(self.feature_based_aggregation[\"trained_clfs\"]) == 1 else self.feature_based_aggregation[\"trained_clf\"]\n",
    "        \n",
    "        if not self.use_feature_based_aggregation and self.classifier_based_aggregation is not None:\n",
    "            clf_list:list[BaseEstimator] = self.classifier_based_aggregation[\"clf_list\"]\n",
    "            out_clfs:list[tuple[BaseEstimator]] = []\n",
    "            for i in range(self.classifier_based_aggregation[\"n_estimators\"]):\n",
    "                clf_0_clone = clone(clf_list[0])\n",
    "                clf_1_clone = clone(clf_list[1])          \n",
    "                if kwargs_list and len(kwargs_list) >= 1:\n",
    "                    clf_0_clone.fit(X_train.cpu().numpy(), y_train,**kwargs_list[0])\n",
    "                else:\n",
    "                    clf_0_clone.fit(X_train.cpu().numpy(), y_train)\n",
    "                if neighbors is not None:\n",
    "                    if kwargs_list and len(kwargs_list) >= 1:\n",
    "                        clf_1_clone.fit(neighbors.cpu().numpy(), y_train,**kwargs_list[1])\n",
    "                    else:\n",
    "                        clf_1_clone.fit(neighbors.cpu().numpy(), y_train)\n",
    "                out_clfs.append((clf_0_clone, clf_1_clone))\n",
    "            self.classifier_based_aggregation[\"trained_clfs\"] = out_clfs\n",
    "            return self.classifier_based_aggregation[\"trained_clfs\"][0] if len(self.classifier_based_aggregation[\"trained_clfs\"]) == 1 else self.classifier_based_aggregation[\"trained_clfs\"]\n",
    "    \n",
    "    def predict_proba(self, X_test:torch.FloatTensor|numpy._typing.NDArray,\n",
    "                      edge_index:torch.LongTensor|numpy._typing.NDArray,\n",
    "                      test_mask:torch.BoolTensor|numpy._typing.NDArray|None,\n",
    "                     **kwargs):  \n",
    "        if test_mask is None:\n",
    "            test_mask = torch.ones(X_test.shape[0]).type(torch.bool)\n",
    "        X_test, neighbors = self.get_features(X_test, edge_index, test_mask)\n",
    "        \n",
    "        if self.use_feature_based_aggregation and self.feature_based_aggregation is not None:\n",
    "            concat:bool = self.feature_based_aggregation[\"concat\"]\n",
    "#             clf:BaseEstimator = self.feature_based_aggregation[\"combined_clf\"]\n",
    "            if neighbors is not None:\n",
    "                X_test:torch.FloatTensor = torch.concat((X_test, neighbors), dim = 1) if concat else torch.add(X_test, neighbors)\n",
    "            pred_proba = []\n",
    "            for clf in self.feature_based_aggregation[\"trained_clfs\"]:\n",
    "                pred_proba.append(clf.predict_proba(X_test.cpu().numpy(),**kwargs))\n",
    "            return np.mean(np.array(pred_proba), axis=0)\n",
    "        \n",
    "        if not self.use_feature_based_aggregation and self.classifier_based_aggregation is not None:\n",
    "#             clf_list:list[BaseEstimator] = self.classifier_based_aggregation[\"clf_list\"]\n",
    "            pred_proba = []\n",
    "            for clf_list in self.classifier_based_aggregation[\"trained_clfs\"]:\n",
    "                pred_proba_0 = clf_list[0].predict_proba(X_test.cpu().numpy(),**kwargs) \n",
    "                if \"weights\" not in classifier_based_aggregation or len(classifier_based_aggregation[\"weights\"]) != 2:\n",
    "                    classifier_based_aggregation[\"weights\"] = (.5, .5)\n",
    "                pred_proba.append(classifier_based_aggregation[\"weights\"][0] * pred_proba_0)\n",
    "                if neighbors is not None:\n",
    "                    pred_proba_1 = clf_list[1].predict_proba(neighbors.cpu().numpy(), **kwargs)\n",
    "                    pred_proba.append(classifier_based_aggregation[\"weights\"][1] * pred_proba_1)     \n",
    "            return np.mean(np.array(pred_proba), axis=0)\n",
    "        \n",
    "    \n",
    "    def predict(self,\n",
    "                X_test:torch.FloatTensor|numpy._typing.NDArray,\n",
    "                edge_index:torch.LongTensor|numpy._typing.NDArray,\n",
    "                test_mask:torch.BoolTensor|numpy._typing.NDArray|None, **kwargs):\n",
    "        return self.predict_proba(X_test, edge_index, test_mask, **kwargs).argmax(1)\n",
    "        \n",
    "\n",
    "    def validate_input(self):\n",
    "        pass\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_feature_tensor(X:torch.FloatTensor|numpy._typing.NDArray) -> torch.FloatTensor|None:\n",
    "        if not torch.is_tensor(X):\n",
    "            try:\n",
    "                return torch.from_numpy(X).type(torch.float)\n",
    "            except:\n",
    "                raise Exception(\"Features input X must be numpy array or torch tensor!\")\n",
    "                return None \n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_label_tensor(y:torch.LongTensor|numpy._typing.NDArray) -> torch.LongTensor|None:\n",
    "        if not torch.is_tensor(y):\n",
    "            try:\n",
    "                return torch.from_numpy(y).type(torch.long)\n",
    "            except:\n",
    "                raise Exception(\"Label input y must be numpy array or torch tensor!\")\n",
    "                return None\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mask_tensor(mask:torch.BoolTensor|numpy._typing.NDArray) -> torch.BoolTensor|None:\n",
    "        if not torch.is_tensor(mask):\n",
    "            try:\n",
    "                return torch.from_numpy(mask).type(torch.bool)\n",
    "            except:\n",
    "                raise Exception(\"Input mask must be numpy array or torch tensor!\")\n",
    "                return None\n",
    "        return mask\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_edge_index_tensor(edge_index:torch.LongTensor|numpy._typing.NDArray) -> torch.LongTensor|None:\n",
    "        if not torch.is_tensor(edge_index):\n",
    "            try:\n",
    "                edge_index =  torch.from_numpy(edge_index).type(torch.long)\n",
    "                Framework.validate_edge_index(edge_index)\n",
    "                return edge_index\n",
    "            except:\n",
    "                raise Exception(\"Edge index must be numpy array or torch tensor\")\n",
    "                return None\n",
    "        return edge_index\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_edge_index(edge_index:torch.LongTensor) -> None:\n",
    "        if edge_index.shape[0] != 2:\n",
    "            raise Exception(\"Edge index must have the shape 2 x NumberOfEdges\")\n",
    "            # TODO: check max edge index and shape of features\n",
    "            \n",
    "    def apply_attention_mechanism(self, source_lift:torch.FloatTensor,\n",
    "                                  features_for_aggregation:torch.FloatTensor,\n",
    "                                  target:torch.LongTensor,\n",
    "                                 is_training:bool = False) -> torch.FloatTensor:\n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        score = cos(source_lift, features_for_aggregation.index_select(0, target))\n",
    "        dropout_tens = None\n",
    "        \n",
    "        origin_scores = torch.clone(score)\n",
    "        if self.cosine_eps:\n",
    "            score[score < self.cosine_eps] = -torch.inf\n",
    "        if self.dropout_attn is not None and is_training:\n",
    "            dropout_tens = torch.FloatTensor(score.shape[0]).uniform_(0, 1)\n",
    "            score[dropout_tens < self.dropout_attn] = -torch.inf\n",
    "            print(origin_scores[dropout_tens < self.dropout_attn])\n",
    "        exp_score = torch.exp(score)\n",
    "        summed_exp_score = torch.zeros_like(exp_score).scatter(0, target,exp_score, reduce=\"add\")\n",
    "        target_lifted_summed_exp_score = summed_exp_score.index_select(0, target)\n",
    "        normalized_scores = exp_score / target_lifted_summed_exp_score\n",
    "        source_lift = normalized_scores.unsqueeze(1) * source_lift\n",
    "        return source_lift\n",
    "    \n",
    "    def shift_tensor_to_device(self,\n",
    "                               t:torch.FloatTensor) -> torch.FloatTensor:\n",
    "        if self.gpu_idx is not None:\n",
    "            return t.to(self.device) \n",
    "        return t\n",
    "    \n",
    "    \n",
    "    def aggregate(self, X:torch.FloatTensor, edge_index:torch.LongTensor, is_training:bool=False) -> torch.FloatTensor: \n",
    "        features_for_aggregation:torch.FloatTensor = torch.clone(X)\n",
    "        for i in range(self.hops):\n",
    "            if self.normalize:\n",
    "                features_for_aggregation = torch.nn.functional.normalize(features_for_aggregation, dim = 0)\n",
    "            source_lift = features_for_aggregation.index_select(0, edge_index[0])\n",
    "            target = edge_index[1]\n",
    "            \n",
    "            if self.use_pseudo_attention:\n",
    "                source_lift = self.apply_attention_mechanism(source_lift, features_for_aggregation, target, is_training)\n",
    "            \n",
    "            summed_neighbors = torch.zeros_like(features_for_aggregation, device=self.device).scatter_(0, target.unsqueeze(0).repeat(features_for_aggregation.shape[1], 1).t(), source_lift, reduce=\"add\")\n",
    "            multiplied_neighbors = torch.ones_like(features_for_aggregation, device=self.device).scatter_(0, target.unsqueeze(0).repeat(features_for_aggregation.shape[1], 1).t(), source_lift, reduce=\"multiply\")\n",
    "\n",
    "            num_source_neighbors = torch.zeros(features_for_aggregation.shape[0], dtype=torch.float, device=self.device)\n",
    "            num_source_neighbors.scatter_(0, target, torch.ones_like(target, dtype=torch.float, device=self.device), reduce=\"add\")\n",
    "            num_source_neighbors = num_source_neighbors.unsqueeze(-1)\n",
    "\n",
    "            out = self.user_function(X,features_for_aggregation,\n",
    "                                     summed_neighbors, multiplied_neighbors, num_source_neighbors, i)\n",
    "            \n",
    "            if self.handle_nan is not None:\n",
    "                out = torch.nan_to_num(out, nan=self.handle_nan)\n",
    "            features_for_aggregation = out\n",
    "        return features_for_aggregation\n",
    "    \n",
    "    def validate_grid_input(self, grid_params):\n",
    "        if len(grid_params) != 1 and self.use_feature_based_aggregation:\n",
    "            raise Exception(\"You need to provide grid parameter for the classifier!\")\n",
    "        if len(grid_params) != 2 and not self.use_feature_based_aggregation:\n",
    "            raise Exception(\"You need to provide two grid parameter, one for each classifier!\")\n",
    "        return\n",
    "    \n",
    "    def grid_search(self,\n",
    "            X_train:torch.FloatTensor|numpy._typing.NDArray,\n",
    "            edge_index:torch.LongTensor|numpy._typing.NDArray,\n",
    "            y_train:torch.LongTensor|numpy._typing.NDArray,\n",
    "            train_mask:torch.BoolTensor|numpy._typing.NDArray|None,\n",
    "            grid_params:list,\n",
    "            **grid_kwargs\n",
    "            ) -> BaseEstimator:        \n",
    "        if train_mask is None:\n",
    "            train_mask = torch.ones(X_train.shape[0]).type(torch.bool)\n",
    "        y_train = Framework.get_label_tensor(y_train)\n",
    "        y_train = y_train[train_mask]\n",
    "        \n",
    "        self.validate_grid_input(grid_params)\n",
    "        \n",
    "        X_train, neighbors = self.get_features(X_train, edge_index, train_mask)        \n",
    "        \n",
    "        if self.use_feature_based_aggregation and self.feature_based_aggregation is not None:\n",
    "            concat:bool = self.feature_based_aggregation[\"concat\"]\n",
    "            clf:BaseEstimator = self.feature_based_aggregation[\"combined_clf\"]\n",
    "            if neighbors is not None:\n",
    "                X_train:torch.FloatTensor = torch.concat((X_train, neighbors), dim = 1) if concat else torch.add(X_train, neighbors)\n",
    "            grid = GridSearchCV(\n",
    "                estimator=clf,\n",
    "                param_grid=grid_params[0],\n",
    "                **grid_kwargs\n",
    "            )\n",
    "            grid.fit(X_train.cpu().numpy(), y_train)\n",
    "            self.feature_based_aggregation[\"combined_clf\"] = grid.best_estimator_\n",
    "            return self.feature_based_aggregation[\"combined_clf\"]\n",
    "        \n",
    "        if not self.use_feature_based_aggregation and self.classifier_based_aggregation is not None:\n",
    "            clf_list:list[BaseEstimator] = self.classifier_based_aggregation[\"clf_list\"]\n",
    "            optimzed_clfs = []\n",
    "            grid_self = GridSearchCV(\n",
    "                estimator=clf_list[0],\n",
    "                param_grid=grid_params[0],\n",
    "                **grid_kwargs\n",
    "            )\n",
    "            grid_self.fit(X_train.cpu().numpy(), y_train)\n",
    "            optimzed_clfs.append(grid_self.best_estimator_)\n",
    "            if neighbors is not None:\n",
    "                grid_neighbors = GridSearchCV(\n",
    "                    estimator=clf_list[1],\n",
    "                    param_grid=grid_params[1],\n",
    "                    **grid_kwargs\n",
    "                )\n",
    "                grid_neighbors.fit(neighbors.cpu().numpy(), y_train)\n",
    "                optimzed_clfs.append(grid_neighbors.best_estimator_)\n",
    "            self.classifier_based_aggregation[\"clf_list\"] = optimzed_clfs\n",
    "            return self.classifier_based_aggregation[\"clf_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8cca695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora', split=\"public\") ## public\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "PSEUDO_EPOCHS = 1\n",
    "\n",
    "X =  dataset[0].x #node_features #dataset[0].x.repeat(PSEUDO_EPOCHS, 1) #node_features #dataset[0].x.repeat(PSEUDO_EPOCHS, 1)\n",
    "y =  dataset[0].y #node_labels #dataset[0].y.repeat(PSEUDO_EPOCHS) #node_labels #dataset[0].y.repeat(PSEUDO_EPOCHS)\n",
    "\n",
    "test =  dataset[0].test_mask #test_indices #dataset[0].test_mask #test_indices #dataset[0].test_mask.repeat(PSEUDO_EPOCHS)\n",
    "# test[dataset[0].y.shape[0]:] = False\n",
    "# print(test.sum())\n",
    "train = dataset[0].train_mask #train_indices #dataset[0].train_mask #train_indices #dataset[0].train_mask.repeat(PSEUDO_EPOCHS)\n",
    "val =  dataset[0].val_mask\n",
    "\n",
    "\n",
    "# X = dataset[0].x\n",
    "# y = dataset[0].y\n",
    "\n",
    "# test = dataset[0].test_mask\n",
    "# train = ~test #dataset[0].train_mask\n",
    "# val = dataset[0].val_mask\n",
    "\n",
    "# y_train = y[train]\n",
    "# y_test = y[test]\n",
    "\n",
    "edge_index = dataset[0].edge_index \n",
    "edge_index = add_self_loops(edge_index)[0]\n",
    "\n",
    "# edges_indices = []\n",
    "# for i in range(PSEUDO_EPOCHS):\n",
    "#     edges_indices.append(dataset[0].edge_index+i*dataset[0].x.shape[0])\n",
    "# edge_index = torch.cat(edges_indices, 1)\n",
    "\n",
    "bst = XGBClassifier( tree_method='gpu_hist', \n",
    "                           n_estimators=1100,\n",
    "                           max_depth=2,\n",
    "                    random_state=42,\n",
    "                    eta=0.3,\n",
    "                    reg_lambda=0.001,\n",
    "                           min_child_weight = 1,\n",
    "                           max_delta_step= 3,\n",
    "                           sampling_method= \"uniform\")\n",
    "   \n",
    "bst_nh = XGBClassifier( tree_method='gpu_hist', \n",
    "                           n_estimators=900,\n",
    "                           max_depth=2,\n",
    "                       random_state=42,\n",
    "                       reg_lambda=0.2953684210526316,\n",
    "                       eta=0.2733333333333333,\n",
    "                           min_child_weight = 2,\n",
    "                           max_delta_step= 4,\n",
    "                           sampling_method= \"uniform\",\n",
    "                      subsample=0.5)\n",
    "\n",
    "# bst = SGDClassifier(random_state=42, loss=\"log_loss\", eta0=1, learning_rate=\"constant\", penalty=\"l2\", alpha=0.0002) # XGBClassifier(booster=\"gblinear\") #RandomForestClassifier()\n",
    "   \n",
    "# bst_nh = SGDClassifier(random_state=42, loss=\"log_loss\", eta0=1, learning_rate=\"constant\", penalty=\"l2\", alpha=0.0002) #XGBClassifier(booster=\"gblinear\") #RandomForestClassifier()\n",
    "\n",
    "# bst = SVC(probability=True, C=100, kernel=\"linear\", degree=1)\n",
    "   \n",
    "# bst_nh = SVC(probability=True, C=100, kernel=\"linear\", degree=1)\n",
    "\n",
    "feature_based_aggregation:Feature_based_aggregation = {\n",
    "    \"concat\": True,\n",
    "    \"combined_clf\": clf,\n",
    "    \"n_estimators\": 1,\n",
    "    \n",
    "}\n",
    "weight = .5 #0.475\n",
    "classifier_based_aggregation:Classifier_based_aggregation = {\n",
    "    \"clf_list\": [bst, bst_nh],\n",
    "    \"n_estimators\": 1,\n",
    "    \"weights\": [weight, 1-weight]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4d85ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.73400\n",
      "[1]\tvalidation_0-mlogloss:1.63995\n",
      "[2]\tvalidation_0-mlogloss:1.54837\n",
      "[3]\tvalidation_0-mlogloss:1.48037\n",
      "[4]\tvalidation_0-mlogloss:1.45511\n",
      "[5]\tvalidation_0-mlogloss:1.42616\n",
      "[6]\tvalidation_0-mlogloss:1.40100\n",
      "[7]\tvalidation_0-mlogloss:1.37746\n",
      "[8]\tvalidation_0-mlogloss:1.37575\n",
      "[9]\tvalidation_0-mlogloss:1.36987\n",
      "[10]\tvalidation_0-mlogloss:1.36355\n",
      "[11]\tvalidation_0-mlogloss:1.35918\n",
      "[12]\tvalidation_0-mlogloss:1.34453\n",
      "[13]\tvalidation_0-mlogloss:1.34202\n",
      "[14]\tvalidation_0-mlogloss:1.33372\n",
      "[15]\tvalidation_0-mlogloss:1.33217\n",
      "[16]\tvalidation_0-mlogloss:1.32909\n",
      "[17]\tvalidation_0-mlogloss:1.32382\n",
      "[18]\tvalidation_0-mlogloss:1.32752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/home/dwalke/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:19:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalidation_0-mlogloss:1.32067\n",
      "[20]\tvalidation_0-mlogloss:1.31594\n",
      "[21]\tvalidation_0-mlogloss:1.32297\n",
      "[22]\tvalidation_0-mlogloss:1.32562\n",
      "[0]\tvalidation_0-mlogloss:1.66496\n",
      "[1]\tvalidation_0-mlogloss:1.47006\n",
      "[2]\tvalidation_0-mlogloss:1.35592\n",
      "[3]\tvalidation_0-mlogloss:1.25656\n",
      "[4]\tvalidation_0-mlogloss:1.16575\n",
      "[5]\tvalidation_0-mlogloss:1.10393\n",
      "[6]\tvalidation_0-mlogloss:1.04138\n",
      "[7]\tvalidation_0-mlogloss:0.99219\n",
      "[8]\tvalidation_0-mlogloss:0.94844\n",
      "[9]\tvalidation_0-mlogloss:0.89773\n",
      "[10]\tvalidation_0-mlogloss:0.87204\n",
      "[11]\tvalidation_0-mlogloss:0.85190\n",
      "[12]\tvalidation_0-mlogloss:0.82722\n",
      "[13]\tvalidation_0-mlogloss:0.82055\n",
      "[14]\tvalidation_0-mlogloss:0.80748\n",
      "[15]\tvalidation_0-mlogloss:0.79850\n",
      "[16]\tvalidation_0-mlogloss:0.79455\n",
      "[17]\tvalidation_0-mlogloss:0.79733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:19:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tvalidation_0-mlogloss:0.78743\n",
      "[19]\tvalidation_0-mlogloss:0.78669\n",
      "[20]\tvalidation_0-mlogloss:0.76802\n",
      "[21]\tvalidation_0-mlogloss:0.76707\n",
      "[22]\tvalidation_0-mlogloss:0.76692\n",
      "[23]\tvalidation_0-mlogloss:0.76274\n",
      "[24]\tvalidation_0-mlogloss:0.76288\n",
      "[25]\tvalidation_0-mlogloss:0.75665\n",
      "[26]\tvalidation_0-mlogloss:0.75304\n",
      "[27]\tvalidation_0-mlogloss:0.74388\n",
      "[28]\tvalidation_0-mlogloss:0.73596\n",
      "[29]\tvalidation_0-mlogloss:0.73232\n",
      "[30]\tvalidation_0-mlogloss:0.73394\n",
      "[31]\tvalidation_0-mlogloss:0.73615\n",
      "[32]\tvalidation_0-mlogloss:0.73575\n",
      "1.5777363777160645\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import time\n",
    "def user_function(origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors, hop):\n",
    "    return  updated_features + sum_neighbors #/ torch.max(sum_neighbors, 0)[0]\n",
    "\n",
    "framework_xgb = Framework(user_function, hops=3, use_feature_based_aggregation = False,\n",
    "              feature_based_aggregation = feature_based_aggregation,\n",
    "                classifier_based_aggregation = classifier_based_aggregation, gpu_idx = 1, handle_nan = 0, normalize=True, use_pseudo_attention=True,\n",
    "                    cosine_eps = .01 , dropout_attn=None)\n",
    "\n",
    "start = time.time()\n",
    "self_val, neighbors_val = framework_xgb.get_features(X, edge_index,val)\n",
    "self_val, neighbors_val = self_val.cpu(), neighbors_val.cpu()\n",
    "kwargs_list=[{\n",
    "    \"eval_set\":[(self_val, y[val])], \"early_stopping_rounds\":3\n",
    "}, {\"eval_set\":[(neighbors_val, y[val])], \"early_stopping_rounds\":3}]\n",
    "framework_xgb.fit(X, edge_index, y, train, kwargs_list=kwargs_list) #, kwargs_list=kwargs_list\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f7eb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:19:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "0.808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred = framework_xgb.predict(X, edge_index, test) \n",
    "pred_val = framework_xgb.predict(X, edge_index, val) \n",
    "y_test = y[test]\n",
    "y_val = y[val]\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9532e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2784135341644287\n",
      "0.726\n",
      "0.698\n"
     ]
    }
   ],
   "source": [
    "bst = SVC(probability=True, C=.7, kernel=\"linear\", degree=1)\n",
    "   \n",
    "bst_nh = SVC(probability=True, C=.7, kernel=\"linear\", degree=1)\n",
    "\n",
    "feature_based_aggregation:Feature_based_aggregation = {\n",
    "    \"concat\": True,\n",
    "    \"combined_clf\": clf,\n",
    "    \"n_estimators\": 1,\n",
    "    \n",
    "}\n",
    "weight = .5 #0.475\n",
    "classifier_based_aggregation:Classifier_based_aggregation = {\n",
    "    \"clf_list\": [bst, bst_nh],\n",
    "    \"n_estimators\": 1,\n",
    "    \"weights\": [weight, 1-weight]\n",
    "}\n",
    "\n",
    "framework_svc = Framework(user_function, hops=3, use_feature_based_aggregation = False,\n",
    "              feature_based_aggregation = feature_based_aggregation,\n",
    "                classifier_based_aggregation = classifier_based_aggregation, gpu_idx = 1, handle_nan = 0, normalize=True, use_pseudo_attention=True,\n",
    "                    cosine_eps = .01 , dropout_attn=None)\n",
    "\n",
    "start = time.time()\n",
    "framework_svc.fit(X, edge_index, y, train) \n",
    "print(time.time() - start)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred = framework_svc.predict(X, edge_index, test) \n",
    "pred_val = framework_svc.predict(X, edge_index, val) \n",
    "y_test = y[test]\n",
    "y_val = y[val]\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b977ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n",
      "0.826\n"
     ]
    }
   ],
   "source": [
    "pred_val = (framework_svc.predict_proba(X, edge_index, val) +  framework_xgb.predict_proba(X, edge_index, val)).argmax(1)\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "pred = (.4*framework_svc.predict_proba(X, edge_index, test) +  .6*framework_xgb.predict_proba(X, edge_index, test)).argmax(1)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698049ea",
   "metadata": {},
   "source": [
    "## Partial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5c15ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:45:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = framework.fit(X_train, rev_train_edge_index, y_train, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "87f5a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = framework.get_features(X_train, rev_train_edge_index,None)\n",
    "features = list(map(lambda f: f.cpu(), features))\n",
    "X_sbc = np.concatenate(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dc64dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015074, 14)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "64a66ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2)]\n",
      "['Features #0', 'Features #1', 'Features #2', 'Features #3', 'Features #4', 'Features #5', 'Features #6', 'Features #7', 'Features #8', 'Features #9', 'Features #10', 'Features #11', 'Features #12', 'Features #13']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "# clf = framework.fit(X_train, rev_train_edge_index, y_train, None)[0]#GradientBoostingRegressor(n_estimators=10).fit(X, y)\n",
    "features, feature_names = [(0,2)], [f\"Features #{i}\" for i in range(X_sbc.shape[1])]\n",
    "print(features)\n",
    "print(feature_names)\n",
    "deciles = {2: np.linspace(0, 1, num=5)}\n",
    "pd_results = partial_dependence(\n",
    "    clf, X_sbc, features=4, kind=\"average\", grid_resolution=100)\n",
    "display = PartialDependenceDisplay(\n",
    "    [pd_results], features=features, feature_names=feature_names,\n",
    "    target_idx=0, deciles=deciles\n",
    ")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf19809",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13360ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = Framework(user_function, hops=3, use_feature_based_aggregation = False,\n",
    "              feature_based_aggregation = feature_based_aggregation,\n",
    "                classifier_based_aggregation = classifier_based_aggregation, gpu_idx = 1, handle_nan = 0, normalize=True, use_pseudo_attention=True,\n",
    "                    cosine_eps = .01 , dropout_attn=None)\n",
    "\n",
    "self_val, neighbors_val = framework.get_features(X, edge_index,val)\n",
    "self_val, neighbors_val = self_val.cpu(), neighbors_val.cpu()\n",
    "self_train, neighbors_train = framework.get_features(X, edge_index,train)\n",
    "self_train, neighbors_train = self_train.cpu(), neighbors_train.cpu()\n",
    "\n",
    "self_test, neighbors_test = framework.get_features(X, edge_index,test)\n",
    "self_test, neighbors_test = self_test.cpu(), neighbors_test.cpu()\n",
    "\n",
    "X_train_self = self_train\n",
    "X_train_neigh = neighbors_train\n",
    "y_train = y[train]\n",
    "X_val_self = self_val\n",
    "X_val_neigh = neighbors_val\n",
    "y_val = y[val]\n",
    "X_test_self = self_test\n",
    "X_test_neigh = neighbors_test\n",
    "y_test = y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a08bc7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters self:  {'alpha': 0.05829725506606954, 'booster': 'dart', 'colsample_bylevel': 0.717819726384605, 'colsample_bynode': 0.701294796439535, 'colsample_bytree': 0.8341038094607527, 'eta': 0.03104742267586813, 'max_delta_step': 3, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 9, 'rate_drop': 0.30909818686663004, 'reg_lambda': 0.03289950239042971, 'skip_drop': 0.21073731947232097, 'subsample': 0.8199534198900966}\n",
      "Best set of hyperparameters neighbor:  {'alpha': 0.07148295824648293, 'booster': 2, 'colsample_bylevel': 0.889831867304163, 'colsample_bynode': 0.6806418352162596, 'colsample_bytree': 0.9358447943019634, 'eta': 0.03622255613770491, 'max_delta_step': 3, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 7, 'rate_drop': 0.7327269501508407, 'reg_lambda': 0.12796042172483413, 'skip_drop': 0.5709088020105434, 'subsample': 0.7593303490564857}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp,STATUS_OK\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "booster_self = [\"gbtree\", \"dart\"]\n",
    "booster_neigh = [\"gbtree\",  \"dart\"]\n",
    "\n",
    "n_estimators_self = [5, 50, 65, 70, 75, 80, 90, 100,110, 120, 150, 200, 400]\n",
    "n_estimators_neigh = [5, 50, 75, 100, 125, 150,160,170, 175,180, 200]\n",
    "\n",
    "max_depth_self = [None, 1, 2, 3, 4, 8]\n",
    "max_depth_neigh = [None,2, 3, 4, 5,6,7,8,9,10]\n",
    "\n",
    "max_delta_step_self = [None, 1, 2, 3, 4, 8]\n",
    "max_delta_step_neigh = [None, 1, 2, 3, 4, 8]\n",
    "\n",
    "min_child_weight_self = [None, 1, 2, 3, 4, 8]\n",
    "min_child_weight_neigh = [None, 1, 2, 3, 4, 8]\n",
    "# Define the hyperparameter space\n",
    "space_self = {\n",
    "    'booster': hp.choice('booster',booster_self),\n",
    "    'n_estimators': hp.choice('n_estimators',n_estimators_self),\n",
    "    'max_depth': hp.choice('max_depth',max_depth_self),\n",
    "    'eta': hp.loguniform('eta', -5, -1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'max_delta_step': hp.choice('max_delta_step',max_delta_step_self),\n",
    "    'min_child_weight': hp.choice('min_child_weight',min_child_weight_self),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.02, 0.1),\n",
    "    'alpha': hp.uniform('alpha', 0, 0.1),\n",
    "   'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.7, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.7, 1.0),\n",
    "    'rate_drop': hp.uniform('rate_drop', 0.0, 1.0),\n",
    "    'skip_drop': hp.uniform('skip_drop', 0.0, 1.0),\n",
    "}\n",
    "\n",
    "space_neigh = {\n",
    "    'booster': hp.choice('booster',booster_neigh),\n",
    "    'n_estimators': hp.choice('n_estimators',n_estimators_neigh),\n",
    "    'max_depth': hp.choice('max_depth',max_depth_neigh),\n",
    "    'eta': hp.loguniform('eta', -5, -1),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'max_delta_step': hp.choice('max_delta_step',max_delta_step_neigh),\n",
    "    'min_child_weight': hp.choice('min_child_weight',min_child_weight_neigh),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 0.15),\n",
    "    'alpha': hp.uniform('alpha', 0, 0.15),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.6, 1),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.6, 1),\n",
    "    'rate_drop': hp.uniform('rate_drop', 0.0, 1.0),\n",
    "    'skip_drop': hp.uniform('skip_drop', 0.0, 1.0),\n",
    "}\n",
    "\n",
    "                        \n",
    "# Define the objective function to minimize\n",
    "def objective_self(params):\n",
    "    xgb_model = XGBClassifier(tree_method='gpu_hist',random_state=42, **params)\n",
    "    xgb_model.fit(X_train_self, y_train)\n",
    "    y_pred = xgb_model.predict(X_val_self)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Define the objective function to minimize\n",
    "def objective_neigh(params):\n",
    "    xgb_model = XGBClassifier(tree_method='gpu_hist',random_state=42, **params)\n",
    "    xgb_model.fit(X_train_neigh, y_train)\n",
    "    y_pred = xgb_model.predict(X_val_neigh)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Perform the optimization\n",
    "# best_params_self = fmin(objective_self, space_self, algo=tpe.suggest, max_evals=200)\n",
    "# best_params_neigh = fmin(objective_neigh, space_neigh, algo=tpe.suggest, max_evals=200)\n",
    "print(\"Best set of hyperparameters self: \", best_params_self)\n",
    "print(\"Best set of hyperparameters neighbor: \", best_params_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac672e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_self = {'alpha': 0.05829725506606954, 'booster': 0, 'colsample_bylevel': 0.717819726384605, 'colsample_bynode': 0.701294796439535, 'colsample_bytree': 0.8341038094607527, 'eta': 0.03104742267586813, 'max_delta_step': 3, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 9, 'rate_drop': 0.30909818686663004, 'reg_lambda': 0.03289950239042971, 'skip_drop': 0.21073731947232097, 'subsample': 0.8199534198900966}\n",
    "best_params_neigh = {'alpha': 0.07148295824648293, 'booster': 2, 'colsample_bylevel': 0.889831867304163, 'colsample_bynode': 0.6806418352162596, 'colsample_bytree': 0.9358447943019634, 'eta': 0.03622255613770491, 'max_delta_step': 3, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 7, 'rate_drop': 0.7327269501508407, 'reg_lambda': 0.12796042172483413, 'skip_drop': 0.5709088020105434, 'subsample': 0.7593303490564857}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4175d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n",
      "0.804\n"
     ]
    }
   ],
   "source": [
    "best_params_self[\"booster\"] = \"dart\"\n",
    "best_params_self[\"n_estimators\"] = n_estimators_self[best_params_self[\"n_estimators\"]]\n",
    "best_params_self[\"max_depth\"] = max_depth_self[best_params_self[\"max_depth\"]]\n",
    "best_params_self[\"max_delta_step\"] = max_delta_step_self[best_params_self[\"max_delta_step\"]]\n",
    "best_params_self[\"min_child_weight\"] = min_child_weight_self[best_params_self[\"min_child_weight\"]]\n",
    "\n",
    "best_params_neigh[\"booster\"] = \"dart\"\n",
    "best_params_neigh[\"n_estimators\"] = n_estimators_neigh[best_params_neigh[\"n_estimators\"]]\n",
    "best_params_neigh[\"max_depth\"] = max_depth_neigh[best_params_neigh[\"max_depth\"]]\n",
    "best_params_neigh[\"max_delta_step\"] = max_delta_step_neigh[best_params_neigh[\"max_delta_step\"]]\n",
    "best_params_neigh[\"min_child_weight\"] = min_child_weight_neigh[best_params_neigh[\"min_child_weight\"]]\n",
    "\n",
    "xgb_model_self = XGBClassifier(tree_method='hist',device=\"cuda:0\", **best_params_self)\n",
    "xgb_model_neigh = XGBClassifier(tree_method='hist',device=\"cuda:0\", **best_params_neigh)\n",
    "\n",
    "xgb_model_self.fit(X_train_self, y_train)\n",
    "xgb_model_neigh.fit(X_train_neigh, y_train)\n",
    "\n",
    "\n",
    "y_pred_proba_self_val = xgb_model_self.predict_proba(X_val_self)\n",
    "y_pred_proba_neigh_val = xgb_model_neigh.predict_proba(X_val_neigh)\n",
    "y_pred_proba_self_test = xgb_model_self.predict_proba(X_test_self)\n",
    "y_pred_proba_neigh_test = xgb_model_neigh.predict_proba(X_test_neigh)\n",
    "\n",
    "weight = 0.475\n",
    "y_pred_proba_val = weight* y_pred_proba_self_val + (1-weight)*y_pred_proba_neigh_val\n",
    "y_pred_proba_test = weight* y_pred_proba_self_test + (1-weight)*y_pred_proba_neigh_test\n",
    "y_pred_val = y_pred_proba_val.argmax(1)\n",
    "y_pred_test = y_pred_proba_test.argmax(1)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_val))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a115b9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_test_0 = framework_svc.predict_proba(X, edge_index, test) \n",
    "accuracy_score(y_test, (y_pred_proba_test_0 + y_pred_proba_test).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9176d545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_test_0 = framework_lin.predict_proba(X, edge_index, test) \n",
    "accuracy_score(y_test, (y_pred_proba_test_0 + y_pred_proba_test).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92278220",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "1) Combination of different classifiers (e.g., SVC with XGBoost trees)\n",
    "2) Hops decay\n",
    "3) Combination of diifferent aggregators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51067a",
   "metadata": {},
   "source": [
    "## Hyperopt linear xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fb4df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [00:06<00:00, 15.10trial/s, best loss: -0.524]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [00:12<00:00,  7.83trial/s, best loss: -0.712]\n",
      "Best set of hyperparameters self lin:  {'alpha': 3.144119410867499e-05, 'feature_selector': 0, 'n_estimators': 0, 'reg_lambda': 0.07465657953014855, 'updater': 0}\n",
      "Best set of hyperparameters neighbor lin:  {'alpha': 8.439797309137466e-05, 'feature_selector': 0, 'n_estimators': 10, 'reg_lambda': 0.052744670914722055, 'updater': 0}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp,STATUS_OK\n",
    "\n",
    "\n",
    "n_estimators_self_lin = [5, 50, 65, 70, 75, 80, 90, 100,110, 120, 150, 200, 400]\n",
    "n_estimators_neigh_lin = [5, 50, 75, 100, 125, 150,160,170, 175,180, 200]\n",
    "\n",
    "updater_self = [\"shotgun\"]\n",
    "updater_neigh = [\"shotgun\"]\n",
    "\n",
    "feature_selector_self = [\"cyclic\"]\n",
    "feature_selector_neigh = [\"cyclic\"]\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space_self_lin = {\n",
    "    'n_estimators': hp.choice('n_estimators',n_estimators_self_lin),\n",
    "    'updater': hp.choice('updater',updater_self),\n",
    "    'feature_selector': hp.choice('feature_selector',feature_selector_self),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.02, 0.1),\n",
    "    'alpha': hp.uniform('alpha', 0, 0.1),\n",
    "}\n",
    "\n",
    "space_neigh_lin = {\n",
    "    'n_estimators': hp.choice('n_estimators',n_estimators_neigh_lin),\n",
    "     'updater': hp.choice('updater',updater_neigh),\n",
    "    'feature_selector': hp.choice('feature_selector',feature_selector_neigh),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 0.15),\n",
    "    'alpha': hp.uniform('alpha', 0, 0.15),\n",
    "}\n",
    "\n",
    "                        \n",
    "# Define the objective function to minimize\n",
    "def objective_self_lin(params):\n",
    "    xgb_model = XGBClassifier(  booster=\"gblinear\", random_state=42, **params)\n",
    "    xgb_model.fit(X_train_self, y_train)\n",
    "    y_pred = xgb_model.predict(X_val_self)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Define the objective function to minimize\n",
    "def objective_neigh_lin(params):\n",
    "    xgb_model = XGBClassifier(booster=\"gblinear\", random_state=42, **params)\n",
    "    xgb_model.fit(X_train_neigh, y_train)\n",
    "    y_pred = xgb_model.predict(X_val_neigh)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Perform the optimization\n",
    "best_params_self_lin = fmin(objective_self_lin, space_self_lin, algo=tpe.suggest, max_evals=100)\n",
    "best_params_neigh_lin = fmin(objective_neigh_lin, space_neigh_lin, algo=tpe.suggest, max_evals=100)\n",
    "print(\"Best set of hyperparameters self lin: \", best_params_self_lin)\n",
    "print(\"Best set of hyperparameters neighbor lin: \", best_params_neigh_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7381e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:09:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "[10:09:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "0.72\n",
      "0.713\n"
     ]
    }
   ],
   "source": [
    "best_params_self_lin[\"n_estimators\"] = n_estimators_self_lin[best_params_self_lin[\"n_estimators\"]]\n",
    "best_params_self_lin[\"updater\"] = updater_self[best_params_self_lin[\"updater\"]]\n",
    "best_params_self_lin[\"feature_selector\"] = feature_selector_self[best_params_self_lin[\"feature_selector\"]]\n",
    "\n",
    "best_params_neigh_lin[\"n_estimators\"] = n_estimators_neigh_lin[best_params_neigh_lin[\"n_estimators\"]]\n",
    "best_params_neigh_lin[\"updater\"] = updater_neigh[best_params_neigh_lin[\"updater\"]]\n",
    "best_params_neigh_lin[\"feature_selector\"] = feature_selector_neigh[best_params_neigh_lin[\"feature_selector\"]]\n",
    "\n",
    "xgb_model_self_lin = XGBClassifier(device=\"gpu\", booster=\"gblinear\", random_state=42,**best_params_self_lin)\n",
    "xgb_model_neigh_lin = XGBClassifier(device=\"gpu\", booster=\"gblinear\", random_state=42, **best_params_neigh_lin)\n",
    "\n",
    "xgb_model_self_lin.fit(X_train_self, y_train)\n",
    "xgb_model_neigh_lin.fit(X_train_neigh, y_train)\n",
    "\n",
    "\n",
    "y_pred_proba_self_val_lin = xgb_model_self_lin.predict_proba(X_val_self)\n",
    "y_pred_proba_neigh_val_lin = xgb_model_neigh_lin.predict_proba(X_val_neigh)\n",
    "y_pred_proba_self_test_lin = xgb_model_self_lin.predict_proba(X_test_self)\n",
    "y_pred_proba_neigh_test_lin = xgb_model_neigh_lin.predict_proba(X_test_neigh)\n",
    "\n",
    "weight = 0.475\n",
    "y_pred_proba_val_lin = weight* y_pred_proba_self_val_lin + (1-weight)*y_pred_proba_neigh_val_lin\n",
    "y_pred_proba_test_lin = weight* y_pred_proba_self_test_lin + (1-weight)*y_pred_proba_neigh_test_lin\n",
    "y_pred_val_lin = y_pred_proba_val_lin.argmax(1)\n",
    "y_pred_test_lin = y_pred_proba_test_lin.argmax(1)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_val_lin))\n",
    "print(accuracy_score(y_test, y_pred_test_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b3bbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, (y_pred_proba_test + y_pred_proba_test_lin).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2965f67",
   "metadata": {},
   "source": [
    "## Hyperopt SGD as linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6a9d987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [01:29<00:00,  1.12trial/s, best loss: -0.6]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100/100 [01:24<00:00,  1.19trial/s, best loss: -0.6]\n",
      "Best set of hyperparameters self:  {'alpha': 0.00016234708404326437, 'eta0': 0.009712344844625765, 'l1_ratio': 0.9066656763340981, 'loss': 1, 'n_iter_no_change': 0, 'penalty': 2}\n",
      "Best set of hyperparameters neighbor:  {'alpha': 0.00015955127756278622, 'eta0': 0.07263964319593422, 'l1_ratio': 0.8220050106364165, 'loss': 1, 'n_iter_no_change': 1, 'penalty': 2}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp,STATUS_OK\n",
    "\n",
    "loss_self = [\"modified_huber\", \"log_loss\"]\n",
    "loss_neigh = [\"modified_huber\", \"log_loss\"]\n",
    "\n",
    "penalty_self = [\"l2\", \"l1\", \"elasticnet\"]\n",
    "penalty_neigh = [\"l2\", \"l1\", \"elasticnet\"]\n",
    "\n",
    "n_iter_no_change_self = [5, 10, 20]\n",
    "n_iter_no_change_neigh = [5, 10, 20]\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space_self_sgd = {\n",
    "    'loss': hp.choice('loss',loss_self),\n",
    "    'penalty': hp.choice('penalty',penalty_self),\n",
    "    'n_iter_no_change': hp.choice('n_iter_no_change',n_iter_no_change_self),\n",
    "    'eta0': hp.loguniform('eta0', -5, -1),\n",
    "    'alpha': hp.uniform('alpha', 0.00008, 0.00018),\n",
    "    'l1_ratio':hp.uniform('l1_ratio', 0.0, 1.0),\n",
    "}\n",
    "\n",
    "space_neigh_sgd = {\n",
    "    'loss': hp.choice('loss',loss_neigh),\n",
    "    'penalty': hp.choice('penalty',penalty_neigh),\n",
    "    'n_iter_no_change': hp.choice('n_iter_no_change',n_iter_no_change_neigh),\n",
    "    'eta0': hp.loguniform('eta0', -5, -1),\n",
    "    'alpha': hp.uniform('alpha', 0.00008, 0.00018),\n",
    "    'l1_ratio':hp.uniform('l1_ratio', 0.0, 1.0),\n",
    "}\n",
    "\n",
    "                        \n",
    "# Define the objective function to minimize\n",
    "def objective_self_sgd(params):\n",
    "    model = SGDClassifier(random_state=42, n_jobs=-1,tol=None, **params)\n",
    "    model.fit(X_train_self, y_train)\n",
    "    y_pred = model.predict(X_val_self)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Define the objective function to minimize\n",
    "def objective_neigh_sgd(params):\n",
    "    model = SGDClassifier(random_state=42, n_jobs=-1,tol=None, **params)\n",
    "    model.fit(X_train_self, y_train)\n",
    "    y_pred = model.predict(X_val_self)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# Perform the optimization\n",
    "best_params_self_sgd = fmin(objective_self_sgd, space_self_sgd, algo=tpe.suggest, max_evals=100)\n",
    "best_params_neigh_sgd = fmin(objective_neigh_sgd, space_neigh_sgd, algo=tpe.suggest, max_evals=100)\n",
    "print(\"Best set of hyperparameters self: \", best_params_self_sgd)\n",
    "print(\"Best set of hyperparameters neighbor: \", best_params_neigh_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23c84a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708\n",
      "0.706\n"
     ]
    }
   ],
   "source": [
    "best_params_self_sgd[\"loss\"] = loss_self[best_params_self_sgd[\"loss\"]]\n",
    "best_params_self_sgd[\"penalty\"] = penalty_self[best_params_self_sgd[\"penalty\"]]\n",
    "best_params_self_sgd[\"n_iter_no_change\"] = n_iter_no_change_self[best_params_self_sgd[\"n_iter_no_change\"]]\n",
    "\n",
    "best_params_neigh_sgd[\"loss\"] = loss_neigh[best_params_neigh_sgd[\"loss\"]]\n",
    "best_params_neigh_sgd[\"penalty\"] = penalty_neigh[best_params_neigh_sgd[\"penalty\"]]\n",
    "best_params_neigh_sgd[\"n_iter_no_change\"] = n_iter_no_change_neigh[best_params_neigh_sgd[\"n_iter_no_change\"]]\n",
    "\n",
    "sgd_model_self = SGDClassifier(random_state=42, n_jobs=-1,tol=None, **best_params_self_sgd)\n",
    "sgd_model_neigh = SGDClassifier(random_state=42, n_jobs=-1,tol=None, **best_params_neigh_sgd)\n",
    "\n",
    "sgd_model_self.fit(X_train_self, y_train)\n",
    "sgd_model_neigh.fit(X_train_neigh, y_train)\n",
    "\n",
    "\n",
    "y_pred_proba_self_val_sgd = sgd_model_self.predict_proba(X_val_self)\n",
    "y_pred_proba_neigh_val_sgd = sgd_model_neigh.predict_proba(X_val_neigh)\n",
    "y_pred_proba_self_test_sgd = sgd_model_self.predict_proba(X_test_self)\n",
    "y_pred_proba_neigh_test_sgd = sgd_model_neigh.predict_proba(X_test_neigh)\n",
    "\n",
    "weight = 0.475\n",
    "y_pred_proba_val_sgd = weight* y_pred_proba_self_val_sgd + (1-weight)*y_pred_proba_neigh_val_sgd\n",
    "y_pred_proba_test_sgd = weight* y_pred_proba_self_test_sgd + (1-weight)*y_pred_proba_neigh_test_sgd\n",
    "y_pred_val_sgd = y_pred_proba_val_sgd.argmax(1)\n",
    "y_pred_test_sgd = y_pred_proba_test_sgd.argmax(1)\n",
    "\n",
    "print(accuracy_score(y_val, y_pred_val_sgd))\n",
    "print(accuracy_score(y_test, y_pred_test_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af0b8021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, (y_pred_proba_test + y_pred_proba_test_sgd).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9642261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Todo linear sgd pipeline\n",
    "## final eval\n",
    "## stacking/bagging/boosting algorithms in framework- multi classifiiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "700d0f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"gat_pred_0834.csv\")\n",
    "gat_pred = df[\"pred\"].values\n",
    "gat_true = df[\"true\"].values\n",
    "np.equal(gat_true, y_test).sum() == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ae15692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_self[~np.equal(y_pred_test, gat_pred)] != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "043fe8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2054e-03, 2.1152e-04, 9.5923e-04,  ..., 2.3565e-03, 4.7782e-04,\n",
       "         1.1903e-05],\n",
       "        [1.1781e-04, 1.4961e-04, 1.2001e-04,  ..., 0.0000e+00, 5.0621e-05,\n",
       "         8.4189e-06],\n",
       "        [2.9530e-01, 1.8666e-04, 9.4587e-04,  ..., 8.8360e-03, 3.5020e-04,\n",
       "         1.4027e-04],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 2.1688e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 4.7500e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_neigh[~np.equal(y_pred_test, gat_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f651fe7e",
   "metadata": {},
   "source": [
    "## Old experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "451ae41e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mself\u001b[39m, neighbors \u001b[38;5;241m=\u001b[39m framework\u001b[38;5;241m.\u001b[39mget_features(X, edge_index, \u001b[43mtrain_indices\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m self_val, neighbors_val \u001b[38;5;241m=\u001b[39m framework\u001b[38;5;241m.\u001b[39mget_features(X, edge_index,val)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m, neighbors, self_val, neighbors_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), neighbors\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),self_val\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), neighbors_val\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_indices' is not defined"
     ]
    }
   ],
   "source": [
    "self, neighbors = framework.get_features(X, edge_index, train_indices, True)\n",
    "self_val, neighbors_val = framework.get_features(X, edge_index,val)\n",
    "self, neighbors, self_val, neighbors_val = self.cpu().numpy(), neighbors.cpu().numpy(),self_val.cpu().numpy(), neighbors_val.cpu().numpy()\n",
    "bst.fit(self, y[train], eval_set=[(self_val, y[val])], early_stopping_rounds=5)\n",
    "bst_nh.fit(neighbors, y[train], eval_set=[(neighbors_val, y[val])], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90d7f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "tensor(0.7910)\n",
      "0.109\n",
      "tensor(0.7930)\n",
      "0.20800000000000002\n",
      "tensor(0.7970)\n",
      "0.30700000000000005\n",
      "tensor(0.8000)\n",
      "0.406\n",
      "tensor(0.8090)\n",
      "0.505\n",
      "tensor(0.8090)\n",
      "0.6040000000000001\n",
      "tensor(0.7830)\n",
      "0.7030000000000001\n",
      "tensor(0.7360)\n",
      "0.802\n",
      "tensor(0.6820)\n",
      "0.901\n",
      "tensor(0.6130)\n",
      "1.0\n",
      "tensor(0.5560)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0.01, 1 , 11, endpoint=True):\n",
    "    print(i)\n",
    "    self_test, neighbors_test = framework.get_features(X, edge_index,test_indices)\n",
    "    self_test, neighbors_test = self_test.cpu().numpy(), neighbors_test.cpu().numpy()\n",
    "    pred = (bst.predict_proba(self_test)*i + (1-i)*bst_nh.predict_proba(neighbors_test)).argmax(-1) \n",
    "    y_test = y[test_indices]\n",
    "    print(np.equal(pred, y_test).sum() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acd1cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/dwalke/miniconda3/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mframework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mgrid_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreg_lambda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#1100\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_child_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#2\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_delta_step\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#4\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#0.3\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#2\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreg_lambda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2953684210526316\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#700\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_child_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#2\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_delta_step\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#4\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2733333333333333\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#0.375025\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#2\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 386\u001b[0m, in \u001b[0;36mFramework.grid_search\u001b[0;34m(self, X_train, edge_index, y_train, train_mask, grid_params, **grid_kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m optimzed_clfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    381\u001b[0m grid_self \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m    382\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf_list[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    383\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mgrid_params[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgrid_kwargs\n\u001b[1;32m    385\u001b[0m )\n\u001b[0;32m--> 386\u001b[0m \u001b[43mgrid_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m optimzed_clfs\u001b[38;5;241m.\u001b[39mappend(grid_self\u001b[38;5;241m.\u001b[39mbest_estimator_)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "framework.grid_search(X, edge_index, y, val_indices, \n",
    "                      grid_params=[{'reg_lambda': [0.001],\n",
    "                                    'n_estimators':[1100],#1100\n",
    "                                   'min_child_weight':[1],#2\n",
    "                                   'max_delta_step': [3],#4\n",
    "                                   'eta': [0.3], #0.3\n",
    "                                   'max_depth':[2]},#2\n",
    "                                   {'reg_lambda': [0.2953684210526316],\n",
    "                                    'n_estimators':[900],#700\n",
    "                                   'min_child_weight': [2],#2\n",
    "                                   'max_delta_step': [4],#4\n",
    "                                   'eta': [0.2733333333333333],#0.375025\n",
    "                                   'max_depth':[2]\n",
    "                                   }],#2\n",
    "                                  scoring=\"accuracy\", n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10b583",
   "metadata": {},
   "source": [
    "## Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061f77fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_based_aggregation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m     11\u001b[0m                            [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     12\u001b[0m X_f \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     14\u001b[0m test_framework \u001b[38;5;241m=\u001b[39m Framework(user_function, hops\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, use_feature_based_aggregation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m---> 15\u001b[0m               feature_based_aggregation \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_based_aggregation\u001b[49m,\n\u001b[1;32m     16\u001b[0m                 classifier_based_aggregation \u001b[38;5;241m=\u001b[39m classifier_based_aggregation, gpu_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, handle_nan \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_pseudo_attention\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m test_framework\u001b[38;5;241m.\u001b[39mget_features(X_f, edge_index, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_based_aggregation' is not defined"
     ]
    }
   ],
   "source": [
    "## small test case\n",
    "\n",
    "def user_function(origin_features, updated_features, sum_neighbors, mul_neighbors, num_neighbors):\n",
    "    return updated_features + sum_neighbors\n",
    "\n",
    "\n",
    "# edge_index = torch.tensor([[0,1,2,3], [0,0,0, 2]], dtype=torch.long)\n",
    "# X_f = torch.tensor([[0,1,2], [2,4,8],[4,8,16], [8,16,32]], dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([[1,2,3,4,4,5,6,7,7,7,8,8,9],\n",
    "                           [0,0,1,1,0,2,3,3,0,4,4,2,5]], dtype=torch.long)\n",
    "X_f = torch.tensor([[0,0,0,0], [1,0,0,0],[0,1,0,0], [0,0,1,0], [0,0,0,1], [1,1,0,0], [1,0,1,0], [1,0,0,1], [0,1,1,0], [0,1,0,1]], dtype=torch.float)\n",
    "\n",
    "test_framework = Framework(user_function, hops=2, use_feature_based_aggregation = False,\n",
    "              feature_based_aggregation = feature_based_aggregation,\n",
    "                classifier_based_aggregation = classifier_based_aggregation, gpu_idx = 1, handle_nan = 0, normalize=False, use_pseudo_attention=False)\n",
    "test_framework.get_features(X_f, edge_index, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dc2ff-bbe1-435c-815e-76ebcee93e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c213dc",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Results of SBC similar to \"Edges are all you need\" without normalize and without pseudo-attention\n",
    "- Iterative aggregation through hops similar to GNN layer\n",
    "- Graph-awareness in ML Algorithms: with zero hops or just hop the acc drops a lot\n",
    "- Extremely fast computation wiith node lifting and torch scatter which can utilize a GPU\n",
    "- Even without SparsePCA high acc although number of features is now higher than number of nodes -> important for Ronalds Dataset (would still recommend implement dimensionality reduction in framework - before or after? aggregation part) -> potential reason: sparsity of cora features\n",
    "- solely \"feature engineering/manipulation\" (I do not change algorithmic details) -> compatible with scikit learn, xgboost\n",
    "- integration in Rahuls tools in future?\n",
    "- new RQ?: How many samples are really required for training when I use high regularization params, dropouts, subsamples etc. -> + TODO for me in this context: read mopre about, generalizations, and \"grooking\" (https://arxiv.org/abs/2309.02390)\n",
    "\n",
    "- Frage an Robert: Hat Ronald vllt doch viele Samples obwohl wenige Patienten? Mehrere Messungen mit Label fÃ¼r einen Patienten?\n",
    "\n",
    "### Problems with Cora - datasets\n",
    "-> potentially aim is rather to be just competetive with others than better\n",
    "1) Full split (Sometimes used, sometime even differences there sota 87-90%) -> 88 % hard to become better\n",
    "2) Public split (Couldnt reproduce their value with GAT) -> 78 % ?  \n",
    "3) Aleksa gordic split, other edge index and normalized features (up to 83 % with his implementation) -> 81 %\n",
    "\n",
    "Questions: \n",
    "- Other benchmarks than only biological or medical data? If so which one?\n",
    "- Do we want to perform better?\n",
    "- Do we want to perform better when having all samples or less samples?\n",
    "- Do we want to set up own benchmarks or want to use benchmarks from the papers?\n",
    "- test other algorithms than just xgboost and random forest?\n",
    "- GAT uses masks -> so the aggregation is still done on all nodes?\n",
    "\n",
    "=> Then I can focus hyperparameter tuning + having a goal to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0f655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
