{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87003c47-b14b-4138-a8c5-727a0ac77a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, ChebConv, SAGEConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from GNNNestedCVEvaluationInductive import GNNNestedCVEvaluationInductive\n",
    "from torch_geometric.datasets import PPI\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2c3025-439d-48d0-a380-0f53a720a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim = 121, dropout = .2, normalize = False, add_self_loops = True):\n",
    "        super(GCN, self).__init__()\n",
    "        hidden_dim = int(hidden_dim)\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.conv3 = GCNConv(hidden_dim, out_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.lin1 = Linear(in_dim, hidden_dim)\n",
    "        self.lin2 = Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index) +self.lin1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)+self.lin2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)+self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb811edd-a4aa-4398-9bb9-9358e107dea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PPI(root='data/PPI')\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e16ff5-b97d-4746-8ed0-c4245b2715c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNSpace():\n",
    "    def __init__(self, dataset):\n",
    "        EPS = 1e-6\n",
    "        # self.hidden_dim_limits = (8, 1024)\n",
    "        # self.dropout_limits = (0.0, 0.8)\n",
    "        # self.weight_decay_limits = (1e-5, 1e-2)\n",
    "        # self.lr_limits = (1e-4, 1e-1)\n",
    "        # self.out_dim = [dataset.num_classes]\n",
    "        # self.gnn_space = None\n",
    "        # self.initialize_space()\n",
    "        self.hidden_dim_limits = (8, 1024)\n",
    "        self.dropout_limits = (0.0, 0.8)\n",
    "        self.weight_decay_limits = (1e-7, 1e-4)\n",
    "        self.lr_limits = (1e-5, 1e-2)\n",
    "        self.out_dim = [dataset.num_classes]\n",
    "        self.gnn_space = None\n",
    "        self.initialize_space()\n",
    "\n",
    "    def initialize_space(self):\n",
    "        gnn_choices = {\n",
    "            # 'out_dim': self.out_dim\n",
    "        }\n",
    "         \n",
    "        self.gnn_space = {\n",
    "            **{key: hp.choice(key, value) for key, value in gnn_choices.items()},\n",
    "            'lr': hp.loguniform('lr',np.log(self.lr_limits[0]), np.log(self.lr_limits[1])),\n",
    "            'weight_decay': hp.loguniform('weight_decay',np.log(self.weight_decay_limits[0]), np.log(self.weight_decay_limits[1])),\n",
    "            'dropout': hp.uniform('dropout', self.dropout_limits[0], self.dropout_limits[1]),\n",
    "            'hidden_dim': hp.qloguniform('hidden_dim', low=np.log(self.hidden_dim_limits[0]), high=np.log(self.hidden_dim_limits[1]), q=16)\n",
    "        }\n",
    "        \n",
    "    def add_choice(self, key, items):\n",
    "        self.gnn_space[key] = hp.choice(key, items)\n",
    "        \n",
    "    def add_uniform(self, key, limits: tuple):\n",
    "        self.gnn_space[key] = hp.uniform(key, limits[0], limits[1])\n",
    "        \n",
    "    def add_loguniform(self, key, limits: tuple):\n",
    "        self.gnn_space[key] = hp.loguniform(key, np.log(limits[0]), np.log(limits[1]))\n",
    "        \n",
    "    def add_qloguniform(self, key, limits, q):\n",
    "        self.gnn_space[key] = hp.qloguniform(key, low=np.log(limits[0]), high=np.log(limits[1]), q=q)\n",
    "\n",
    "class GCNSpace(GNNSpace):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__(dataset)\n",
    "\n",
    "    def get_space(self):\n",
    "        self.add_choice('normalize', [True])\n",
    "        self.add_choice('add_self_loops', [True]) #False\n",
    "        return self.gnn_space    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3785e8f0-63d0-4962-83ec-949fa55df694",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992986aa-d6f9-4ce6-bea9-42519c25ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0304852-f2e2-4171-bf8a-dd659944fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_space = GCNSpace(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c055c49-db3a-461f-ace1-aa65065d940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_store = {}\n",
    "param_store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92c0f2a-ea07-471e-a6e9-eaba48b8140c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d340858020594082802bfa9e56540740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/17 07:01:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/17 07:01:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/07/17 07:01:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/07/17 07:01:15 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/07/17 07:01:15 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/dwalke/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gnn_nestedCV_evaluation \u001b[38;5;241m=\u001b[39m GNNNestedCVEvaluationInductive(device, GCN,data, max_evals\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gcn_space\u001b[38;5;241m.\u001b[39mget_space()\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m, epochs  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m, PATIENCE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgnn_nestedCV_evaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnested_cross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgcn_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m score_store[GCN\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m gnn_nestedCV_evaluation\u001b[38;5;241m.\u001b[39mnested_inductive_cv\u001b[38;5;241m.\u001b[39mouter_scores\n\u001b[1;32m      4\u001b[0m param_store[GCN\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m gnn_nestedCV_evaluation\u001b[38;5;241m.\u001b[39mnested_inductive_cv\u001b[38;5;241m.\u001b[39mbest_params_per_fold\n",
      "File \u001b[0;32m~/git/graph_aware_ml/GNNNestedCVEvaluationInductive.py:83\u001b[0m, in \u001b[0;36mGNNNestedCVEvaluationInductive.nested_cross_validate\u001b[0;34m(self, k_outer, k_inner, space)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnested_inductive_cv \u001b[38;5;241m=\u001b[39m NestedInductiveCV(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, k_outer, k_inner, train_fun, evaluate_fun,max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_evals, parallelism \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallelism, minimalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminimize)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnested_inductive_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mouter_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnested_inductive_cv\n",
      "File \u001b[0;32m~/git/graph_aware_ml/NestedCV.py:47\u001b[0m, in \u001b[0;36mNestedInductiveCV.outer_cv\u001b[0;34m(self, space)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m outer_i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkf_outer\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata))):\n\u001b[1;32m     46\u001b[0m     inner_indcutive_cv \u001b[38;5;241m=\u001b[39m InnerInductiveCV(train_index, \u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_args])\n\u001b[0;32m---> 47\u001b[0m     fitted_model, best_params, best_inner_scores, train_time \u001b[38;5;241m=\u001b[39m \u001b[43minner_indcutive_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparam_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# self.best_models.append(copy.deepcopy(fitted_model).cpu() if hasattr(fitted_model, \"cpu\") else fitted_model)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_params(best_params)\n",
      "File \u001b[0;32m~/git/graph_aware_ml/NestedCV.py:75\u001b[0m, in \u001b[0;36mInnerInductiveCV.hyperparam_tuning\u001b[0;34m(self, space)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhyperparam_tuning\u001b[39m(\u001b[38;5;28mself\u001b[39m, space):\n\u001b[0;32m---> 75\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     sc\u001b[38;5;241m.\u001b[39msetLogLevel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOFF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m     logging\u001b[38;5;241m.\u001b[39mgetLogger()\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mCRITICAL)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:203\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:296\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:421\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1586\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1578\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1579\u001b[0m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[1;32m   1581\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1583\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1584\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1586\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1588\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gnn_nestedCV_evaluation = GNNNestedCVEvaluationInductive(device, GCN,data, max_evals= len(gcn_space.get_space().keys())*20, epochs  = 10000, PATIENCE=10)\n",
    "gnn_nestedCV_evaluation.nested_cross_validate(5, 5, gcn_space.get_space())\n",
    "score_store[GCN.__name__] = gnn_nestedCV_evaluation.nested_inductive_cv.outer_scores\n",
    "param_store[GCN.__name__] = gnn_nestedCV_evaluation.nested_inductive_cv.best_params_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271af579-c52c-4d8d-919e-9a80a378e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in score_store:\n",
    "    print(f\"{key}: {score_store[key].mean()} +- {score_store[key].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610ecac-85b7-4aef-b8e7-04cb7f886a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80e487-1209-4a26-9579-0dcc7ce52cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_nestedCV_evaluation.nested_inductive_cv.best_params_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526de85b-7421-4275-89f6-0fb21bd653dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnn_nestedCV_evaluation.nested_inductive_cv.outer_scores.mean(), gnn_nestedCV_evaluation.nested_inductive_cv.outer_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88732e6-190d-4e6d-a8ba-8128f3977b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_nestedCV_evaluation.nested_inductive_cv.inner_scores.mean(), gnn_nestedCV_evaluation.nested_inductive_cv.inner_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc09742-6990-4cd4-9967-24defa99469a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c07a5-a2ef-42be-9ec8-56515aba7cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
