{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a511a919-06c1-45d3-bc7d-3aa441de49c8",
   "metadata": {},
   "source": [
    "# Benchmark for GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f183e-e448-45f5-b19f-d2aaa785c0ef",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1c65ba-0223-44e0-9b52-c86a995eba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.loader import DataLoader\n",
    "from GNNTraining import GNNTraining\n",
    "import torch\n",
    "\n",
    "TRAIN = \"train\"\n",
    "VAL = \"val\"\n",
    "TEST = \"test\"\n",
    "set_names = [TRAIN, TEST, VAL]\n",
    "\n",
    "train_dataset = PPI(root='/tmp/PPI', split=\"train\")\n",
    "val_dataset = PPI(root='/tmp/PPI', split=\"val\")\n",
    "test_dataset = PPI(root='/tmp/PPI', split=\"test\")\n",
    "\n",
    "train_loader = iter(DataLoader(train_dataset, batch_size=len(train_dataset)))\n",
    "val_loader = iter(DataLoader(val_dataset, batch_size=len(val_dataset)))\n",
    "test_loader = iter(DataLoader(test_dataset, batch_size=len(test_dataset)))\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "train_set = next(train_loader)\n",
    "test_set = next(test_loader)\n",
    "val_set = next(val_loader)\n",
    "\n",
    "sets = dict()\n",
    "sets[TRAIN] = train_dataset\n",
    "sets[TEST] = test_dataset\n",
    "sets[VAL] = val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f434c2-f7d9-43f5-b5f1-1e1876b2ffb4",
   "metadata": {},
   "source": [
    "## Define GNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93afa03f-a35a-44df-82e0-212cf82859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout = .2, normalize = False, add_self_loops = True):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.lin1 = Linear(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.lin2 = Linear(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, out_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.lin3 = Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index) + self.lin2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502eed98-264e-47d5-9280-955002a07814",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8bf61d-0c5c-427f-910f-68f8ce721735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381410ce729a4f36ab17039379e816c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d990e17e9940829efcb1e8e7db956e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m tqdm(param_grid\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()):    \n\u001b[1;32m     18\u001b[0m     gnnTraining \u001b[38;5;241m=\u001b[39m GNNTraining(device \u001b[38;5;241m=\u001b[39m device,\n\u001b[1;32m     19\u001b[0m             GNN \u001b[38;5;241m=\u001b[39m GNN,\n\u001b[1;32m     20\u001b[0m             sets \u001b[38;5;241m=\u001b[39m sets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m             epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     26\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m: params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNORMALIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m: params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELF_LOOPS\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mgnnTraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gnnTraining\u001b[38;5;241m.\u001b[39mbest_val_loss \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m best_val_overall:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated params\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/graph_aware_ml/GNNTraining.py:78\u001b[0m, in \u001b[0;36mGNNTraining.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(out, loader\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     77\u001b[0m     acc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m set_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_names:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "space = {\n",
    "    \"WEIGHT_DECAYS\": [0],\n",
    "    \"DROPOUT\": [0.0, 0.2, 0.4],\n",
    "    \"HIDDEN_DIMS\": [128, 256, 512],\n",
    "    \"LEARNING_RATES\": [1e-4, 5e-3, 1e-3, 5e-4],\n",
    "    \"SELF_LOOPS\": [True, False],\n",
    "    \"NORMALIZE\": [True, False],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(space)\n",
    "best_params_overall = None\n",
    "best_val_overall = float(\"inf\")\n",
    "\n",
    "for params in tqdm(param_grid.__iter__()):    \n",
    "    gnnTraining = GNNTraining(device = device,\n",
    "            GNN = GNN,\n",
    "            sets = sets,\n",
    "            hidden_dim = params[\"HIDDEN_DIMS\"],\n",
    "            lr = params[\"LEARNING_RATES\"],\n",
    "            dropout = params[\"DROPOUT\"],\n",
    "            weight_decay=params[\"WEIGHT_DECAYS\"],\n",
    "            epochs = 1000,\n",
    "            kwargs = {\"normalize\": params[\"NORMALIZE\"], 'add_self_loops': params[\"SELF_LOOPS\"]})\n",
    "    gnnTraining.train()\n",
    "    \n",
    "    if gnnTraining.best_val_loss <= best_val_overall:\n",
    "        print(\"Updated params\")\n",
    "        best_val_overall = gnnTraining.best_val_loss\n",
    "        best_params_overall = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f7364-dfb3-443d-81a9-3c2694748f31",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bd129f-0eb5-4df4-9c8e-4d8476850500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d5d9f73470459aa7f0f9f22ba64e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9600572791884782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GNNTraining import GNNTraining\n",
    "from GNNEvaluate import GNNEvaluate \n",
    "\n",
    "gnnTraining = GNNTraining(device = device,\n",
    "            GNN = GNN,\n",
    "            sets = sets,\n",
    "            hidden_dim = 512,\n",
    "            lr = 5e-3,\n",
    "            dropout = 0.2,\n",
    "            weight_decay=0.0,\n",
    "            epochs = 1000,\n",
    "            kwargs = {\"normalize\": True, 'add_self_loops': True})\n",
    "best_model = gnnTraining.train()\n",
    "\n",
    "gnnEvaluate = GNNEvaluate(device = device,\n",
    "            sets = sets)\n",
    "gnnEvaluate.evaluate(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3a912-42a5-44d8-b5df-36409bce743b",
   "metadata": {},
   "source": [
    "## Standard deviation over 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb772607-bd4d-4492-bbf6-42fc06d95813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee9b243eff74a27aca92c8e76cc1c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f64eaddde9a4d5092428038500a051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a174398a6a0493897e95fdf7e79308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7af5932d2547ef80ec98cdb897754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4139313ae1a4435fa673b1239d5a9a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d6599b722a4b1d93cf2a19fddd242c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08791309716a43c9a277fa3d5d3c2915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac9010a82804b4a95e3fd2a5ff9e812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad60c974da67495fa2ba6b1ec0086247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612841bb3b0a4fafaefb85614a4bb477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae5a2564dbb4ff78d63d0f5063f02a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from GNNTraining import GNNTraining\n",
    "from GNNEvaluate import GNNEvaluate \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "times = []\n",
    "scores = []\n",
    "for i in tqdm(range(10)):\n",
    "    gnnTraining = GNNTraining(device = device,\n",
    "             GNN = GNN,\n",
    "            sets = sets,\n",
    "            hidden_dim = 512,\n",
    "            lr = 5e-3,\n",
    "            dropout = 0.2,\n",
    "            weight_decay=0.0,\n",
    "            epochs = 1000,\n",
    "            kwargs = {\"normalize\": True, 'add_self_loops': True})\n",
    "    best_model = gnnTraining.train()\n",
    "    times.append(gnnTraining.training_time)\n",
    "    \n",
    "    gnnEvaluate = GNNEvaluate(device = device,\n",
    "                sets = sets)\n",
    "    score = gnnEvaluate.evaluate(best_model)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bdf630c-15f7-4303-bf23-2da1e87d352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.960577126981376 +- 0.000838829249817186; 343.01980459690094\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"F1-score: {np.mean(scores)} +- {np.std(scores)}; {np.mean(times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7a0993-e46f-4677-bf83-3c0f29ad8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout = .2, normalize = False, add_self_loops = True):\n",
    "        super(GCN, self).__init__()\n",
    "        hidden_dim = int(hidden_dim)\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.conv3 = GCNConv(hidden_dim, out_dim, normalize = normalize, add_self_loops=add_self_loops)\n",
    "        self.lin1 = Linear(in_dim, hidden_dim)\n",
    "        self.lin2 = Linear(hidden_dim, hidden_dim)\n",
    "        self.lin3 = Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv1(x, edge_index) +self.lin1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)+self.lin2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)+self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a29d2595-9780-4bd3-9ec9-69c11677e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "def train_val_data(train_data, manual_seed = None, train_size = 0.8):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(manual_seed)\n",
    "    train_index = torch.arange(len(train_data))\n",
    "    min = int(train_size*train_index.shape[0])\n",
    "    rand_train_index = torch.randperm(train_index.shape[0])\n",
    "    rand_train_index_train_index = rand_train_index[:min]\n",
    "    rand_train_index_val_index = rand_train_index[min:]\n",
    "\n",
    "    new_train_idx = train_index[rand_train_index_train_index]\n",
    "    new_val_idx = train_index[rand_train_index_val_index]\n",
    "\n",
    "    return train_data[new_train_idx.tolist()], train_data[new_val_idx.tolist()]\n",
    "    \n",
    "def evaluate_fun(fitted_model, data):\n",
    "    preds = []\n",
    "    y = []\n",
    "    with torch.inference_mode():\n",
    "        fitted_model.eval()\n",
    "        for graph in data:\n",
    "            graph = graph.to(device)\n",
    "            out = fitted_model(graph.x, graph.edge_index)\n",
    "            preds.append((out > 0).float())\n",
    "            y.append(graph.y)\n",
    "            graph = graph.cpu()\n",
    "    preds = (torch.cat(preds).cpu().detach() > 0)\n",
    "    y = torch.cat(y).cpu()\n",
    "    \n",
    "    return f1_score(y, preds, average = \"micro\")\n",
    "\n",
    "def train_fun(data, hyperparameters):\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    start = time.time()\n",
    "    scores = []\n",
    "    lr = hyperparameters['lr']\n",
    "    weight_decay = hyperparameters[\"weight_decay\"]\n",
    "    \n",
    "    filtered_keys = list(filter(lambda key: key not in [\"weight_decay\", \"lr\"], hyperparameters.keys()))\n",
    "    model_hyperparams = {key: hyperparameters[key] for key in filtered_keys}\n",
    "    model = GCN(in_dim=data.x.shape[-1], **model_hyperparams).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    never_breaked = True\n",
    "    train_data, val_data = train_val_data(data, 42, 0.8)\n",
    "    for epoch in range(1000):\n",
    "        acc_loss = 0\n",
    "        for graph in train_data:\n",
    "            model.train()\n",
    "            graph = graph.to(device)\n",
    "            out = model(graph.x, graph.edge_index)\n",
    "            loss = loss_fn(out, graph.y)\n",
    "            acc_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            graph = graph.cpu()\n",
    "        print(acc_loss)\n",
    "        score = evaluate_fun(model, val_data)\n",
    "        scores.append(score)\n",
    "        worst_score = float(\"-inf\")\n",
    "        mean_score = np.mean(scores[-(100 + 1):]) if len(scores) > 100 else worst_score\n",
    "        not_improved = score < mean_score\n",
    "        \n",
    "        if epoch > (100) and not_improved:\n",
    "            never_breaked = False\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f161b7e-398d-4a49-81d9-29ffaa033ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.587925016880035\n",
      "8.736396133899689\n",
      "8.31795871257782\n",
      "8.104421705007553\n",
      "7.995105862617493\n",
      "7.908246874809265\n",
      "7.830211102962494\n",
      "7.75655409693718\n",
      "7.685425758361816\n",
      "7.614999949932098\n",
      "7.543794393539429\n",
      "7.4707159996032715\n",
      "7.3952131271362305\n",
      "7.31724551320076\n",
      "7.2372488379478455\n",
      "7.155951887369156\n",
      "7.07419815659523\n",
      "6.992789179086685\n",
      "6.912252247333527\n",
      "6.832769423723221\n",
      "6.754324048757553\n",
      "6.676917284727097\n",
      "6.600549787282944\n",
      "6.525219887495041\n",
      "6.450927019119263\n",
      "6.377662509679794\n",
      "6.305420845746994\n",
      "6.234208881855011\n",
      "6.164037615060806\n",
      "6.094921201467514\n",
      "6.026863664388657\n",
      "5.959864109754562\n",
      "5.893921583890915\n",
      "5.829029619693756\n",
      "5.765182316303253\n",
      "5.702373594045639\n",
      "5.640603303909302\n",
      "5.579877495765686\n",
      "5.520188510417938\n",
      "5.461531788110733\n",
      "5.403891950845718\n",
      "5.3472491800785065\n",
      "5.291594505310059\n",
      "5.236912101507187\n",
      "5.183179318904877\n",
      "5.1303883492946625\n",
      "5.0785326063632965\n",
      "5.027594298124313\n",
      "4.977543145418167\n",
      "4.928355187177658\n",
      "4.880017548799515\n",
      "4.832514196634293\n",
      "4.785819888114929\n",
      "4.739917427301407\n",
      "4.6947861313819885\n",
      "4.650409013032913\n",
      "4.606773644685745\n",
      "4.563861161470413\n",
      "4.521652460098267\n",
      "4.480131030082703\n",
      "4.439278289675713\n",
      "4.399077206850052\n",
      "4.359512031078339\n",
      "4.3205635994672775\n",
      "4.2822146862745285\n",
      "4.2444464564323425\n",
      "4.207239121198654\n",
      "4.170581325888634\n",
      "4.134465113282204\n",
      "4.098883017897606\n",
      "4.063816890120506\n",
      "4.029254421591759\n",
      "3.9951707869768143\n",
      "3.961563140153885\n",
      "3.928409829735756\n",
      "3.89572212100029\n",
      "3.8634699434041977\n",
      "3.831697568297386\n",
      "3.800358012318611\n",
      "3.7696957290172577\n",
      "3.739470735192299\n",
      "3.710517942905426\n",
      "3.681016355752945\n",
      "3.651162266731262\n",
      "3.621402144432068\n",
      "3.5927693396806717\n",
      "3.5642228573560715\n",
      "3.536758527159691\n",
      "3.5094269067049026\n",
      "3.482883170247078\n",
      "3.456023946404457\n",
      "3.4293831139802933\n",
      "3.4027523547410965\n",
      "3.3772760927677155\n",
      "3.351854994893074\n",
      "3.3274348378181458\n",
      "3.303418442606926\n",
      "3.2792199552059174\n",
      "3.2550897151231766\n",
      "3.2309377193450928\n",
      "3.206896796822548\n",
      "3.1840223222970963\n",
      "3.16084648668766\n",
      "3.138941541314125\n",
      "3.1168145537376404\n",
      "3.0964607149362564\n",
      "3.0759721398353577\n",
      "3.058447077870369\n",
      "3.0408569127321243\n",
      "3.028091549873352\n",
      "3.015005111694336\n",
      "3.001977249979973\n",
      "2.9776982963085175\n",
      "2.94275863468647\n",
      "2.94208724796772\n",
      "2.954924538731575\n",
      "2.911676436662674\n",
      "2.895752251148224\n",
      "2.861071690917015\n",
      "2.8491347581148148\n",
      "2.8290461003780365\n",
      "2.8110877871513367\n",
      "2.778983399271965\n",
      "2.7648959159851074\n",
      "2.7422596514225006\n",
      "2.7221422344446182\n",
      "2.703193113207817\n",
      "2.689952075481415\n",
      "2.67084339261055\n",
      "2.6557881087064743\n",
      "2.6405254900455475\n",
      "2.624936133623123\n",
      "2.6066580414772034\n",
      "2.589959129691124\n",
      "2.574456498026848\n",
      "2.5610797703266144\n",
      "2.546344429254532\n",
      "2.5317893773317337\n",
      "2.515457034111023\n",
      "2.5006546899676323\n",
      "2.488342635333538\n",
      "2.4734966307878494\n",
      "2.4573935121297836\n",
      "2.4433728009462357\n",
      "2.430049754679203\n",
      "2.4181548357009888\n",
      "2.402747541666031\n",
      "2.388974756002426\n",
      "2.375775024294853\n",
      "2.361034043133259\n",
      "2.3481089994311333\n",
      "2.3359606191515923\n",
      "2.3247656002640724\n",
      "2.309961251914501\n",
      "2.2964228242635727\n",
      "2.2852064073085785\n",
      "2.2710254788398743\n",
      "2.262050211429596\n",
      "2.2541468515992165\n",
      "2.2370160594582558\n",
      "2.2247904539108276\n",
      "2.2154791951179504\n",
      "2.203911915421486\n",
      "2.1975133195519447\n",
      "2.1879633739590645\n",
      "2.1720780357718468\n",
      "2.155773736536503\n",
      "2.1429168209433556\n",
      "2.132828064262867\n",
      "2.133082665503025\n",
      "2.137754872441292\n",
      "2.130769856274128\n",
      "2.111471638083458\n",
      "2.10473395884037\n",
      "2.1157269552350044\n",
      "2.0975732430815697\n",
      "2.072329342365265\n",
      "2.0878827944397926\n",
      "2.0661537125706673\n",
      "2.066498063504696\n",
      "2.03952506929636\n",
      "2.044023886322975\n",
      "2.033248133957386\n",
      "2.0253524258732796\n",
      "2.013979822397232\n",
      "2.0163693204522133\n",
      "2.015530824661255\n",
      "2.0249189287424088\n",
      "2.032019890844822\n",
      "2.015916995704174\n",
      "1.9790084287524223\n",
      "1.94368826597929\n",
      "1.9168641939759254\n",
      "1.9009446129202843\n",
      "1.8883639425039291\n",
      "1.880077175796032\n",
      "1.8749595060944557\n",
      "1.8644853979349136\n",
      "1.857348047196865\n",
      "1.8546986281871796\n",
      "1.84464330971241\n",
      "1.8326230943202972\n",
      "1.8248363733291626\n",
      "1.814187079668045\n",
      "1.8066979944705963\n",
      "1.8008824363350868\n",
      "1.7894928753376007\n",
      "1.7823762223124504\n",
      "1.7769780978560448\n",
      "1.7667939811944962\n",
      "1.7621150463819504\n",
      "1.7569869011640549\n",
      "1.747787818312645\n",
      "1.7416508570313454\n",
      "1.7333343625068665\n",
      "1.721790686249733\n",
      "1.7171275541186333\n",
      "1.7115093991160393\n",
      "1.7016268000006676\n",
      "1.6965941488742828\n",
      "1.690750204026699\n",
      "1.679550126194954\n",
      "1.6759488433599472\n",
      "1.673046164214611\n",
      "1.6620179787278175\n",
      "1.6537183299660683\n",
      "1.6479758620262146\n",
      "1.6388590559363365\n",
      "1.6350115612149239\n",
      "1.6289293393492699\n",
      "1.6189038828015327\n",
      "1.6149411723017693\n",
      "1.610871747136116\n",
      "1.6028469577431679\n",
      "1.5999063774943352\n",
      "1.5932932272553444\n",
      "1.5822050645947456\n",
      "1.5782112553715706\n",
      "1.5780629590153694\n",
      "1.5700167119503021\n",
      "1.5590452179312706\n",
      "1.5529171228408813\n",
      "1.5438810214400291\n",
      "1.540205791592598\n",
      "1.53530403226614\n",
      "1.5271326526999474\n",
      "1.5304049775004387\n",
      "1.5307254269719124\n",
      "1.513101503252983\n",
      "1.5043304935097694\n",
      "1.5067428946495056\n",
      "1.4970963224768639\n",
      "1.4897195473313332\n",
      "1.4837473705410957\n",
      "1.4731059297919273\n",
      "1.4728740081191063\n",
      "1.470172718167305\n",
      "1.4676687121391296\n",
      "1.4706990420818329\n",
      "1.4612211287021637\n",
      "1.4461957551538944\n",
      "1.4371274337172508\n",
      "1.4457641169428825\n",
      "1.439802248030901\n",
      "1.4275089837610722\n",
      "1.4233886264264584\n",
      "1.4193476736545563\n",
      "1.4230848103761673\n",
      "1.4149169437587261\n",
      "1.3963425122201443\n",
      "1.4134859293699265\n",
      "1.4127546474337578\n",
      "1.386140163987875\n",
      "1.3972972966730595\n",
      "1.4010926000773907\n",
      "1.3831010162830353\n",
      "1.3829191774129868\n",
      "1.3703344278037548\n",
      "1.3678456507623196\n",
      "1.3490317165851593\n",
      "1.352208960801363\n",
      "1.3363787531852722\n",
      "1.3424365371465683\n",
      "1.3327599093317986\n",
      "1.3228723295032978\n",
      "1.3109224773943424\n",
      "1.3079617507755756\n",
      "1.306531760841608\n",
      "1.2940929755568504\n",
      "1.290631677955389\n",
      "1.2809050157666206\n",
      "1.2827197052538395\n",
      "1.271289024502039\n",
      "1.2681095264852047\n",
      "1.2613832578063011\n",
      "1.2626392804086208\n",
      "1.24937030300498\n",
      "1.2449090145528316\n",
      "1.2403981983661652\n",
      "1.2421210817992687\n",
      "1.229946419596672\n",
      "1.2261048071086407\n",
      "1.237760841846466\n",
      "1.228755995631218\n",
      "1.2165522500872612\n",
      "1.215029925107956\n",
      "1.207041710615158\n",
      "1.1997477672994137\n",
      "1.198242411017418\n",
      "1.1884015388786793\n",
      "1.1868922710418701\n",
      "1.1840208396315575\n",
      "1.173964012414217\n",
      "1.1742025054991245\n",
      "1.173142809420824\n",
      "1.1651071608066559\n",
      "1.1569567658007145\n",
      "1.1535352170467377\n",
      "1.1571118645370007\n",
      "1.1578453294932842\n",
      "1.1522436551749706\n",
      "1.1429202258586884\n",
      "1.136421825736761\n",
      "1.1377297975122929\n",
      "1.1354353241622448\n",
      "1.1256820298731327\n",
      "1.1304713040590286\n",
      "1.1251990534365177\n",
      "1.1113303899765015\n",
      "1.112436018884182\n",
      "1.1124250516295433\n",
      "1.1056070663034916\n",
      "1.1066055744886398\n",
      "1.0971404947340488\n",
      "1.093387197703123\n",
      "1.104530856013298\n",
      "1.0889069326221943\n",
      "1.085453413426876\n",
      "1.096078023314476\n",
      "1.073815930634737\n",
      "1.0793799944221973\n",
      "1.0757428519427776\n",
      "1.070512868463993\n",
      "1.0625066682696342\n",
      "1.0621731467545033\n",
      "1.0698179937899113\n",
      "1.0584810934960842\n",
      "1.0509368889033794\n",
      "1.0523508787155151\n",
      "1.060994416475296\n",
      "1.0433087274432182\n",
      "1.0473020784556866\n",
      "1.0469677820801735\n",
      "1.0471390187740326\n",
      "1.0313326455652714\n",
      "1.0294016040861607\n",
      "1.033113982528448\n",
      "1.033307209610939\n",
      "1.019565925002098\n",
      "1.0240928828716278\n",
      "1.0273968875408173\n",
      "1.0260249488055706\n",
      "1.0253943242132664\n",
      "1.009913370013237\n",
      "1.0116637907922268\n",
      "1.0086171515285969\n",
      "1.0019562542438507\n",
      "0.9966933391988277\n",
      "0.9945090152323246\n",
      "0.9861025735735893\n",
      "0.9813967905938625\n",
      "0.9830819591879845\n",
      "0.9804192632436752\n",
      "0.9717959687113762\n",
      "0.9672937989234924\n",
      "0.9607555903494358\n",
      "0.9589203745126724\n",
      "0.9601320661604404\n",
      "0.9514529407024384\n",
      "0.9489123784005642\n",
      "0.9481066577136517\n",
      "0.9500586241483688\n",
      "0.9429412893950939\n",
      "0.9443933442234993\n",
      "0.9420145489275455\n",
      "0.9439933337271214\n",
      "0.9500603787600994\n",
      "0.9545266181230545\n",
      "0.9494152143597603\n",
      "0.9508982747793198\n",
      "0.9566078595817089\n",
      "0.9408588483929634\n",
      "0.9313205033540726\n",
      "0.9272660538554192\n",
      "0.9149782806634903\n",
      "0.9178945198655128\n",
      "0.9386218972504139\n",
      "0.9266335144639015\n",
      "0.9182356372475624\n",
      "0.9121805280447006\n",
      "0.8971490375697613\n",
      "0.8942790850996971\n",
      "0.8934656195342541\n",
      "0.8871598020195961\n",
      "0.8865673802793026\n",
      "0.8899866230785847\n",
      "0.8867615759372711\n",
      "0.8932286500930786\n",
      "0.8934386037290096\n",
      "0.8893471024930477\n",
      "0.8975911252200603\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model = train_fun(train_dataset, {'add_self_loops': True,\n",
    "  'dropout': 0.0,\n",
    "  'hidden_dim': 1028,\n",
    "  'lr': 3e-4,\n",
    "  'normalize': True,\n",
    "  'out_dim': 121,\n",
    "  'weight_decay':0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a76ba5b3-b96d-46b6-ba3e-859cd931997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420233472801247"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fun(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b83df1ca-c00f-45c3-80b9-2839276ab5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c806824-8fc9-4bf2-84e1-f7273c4a37ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7799e220-0b90-46d1-af27-cc41c06f8390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f037489-825f-44be-876e-ac3fbdc01834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
