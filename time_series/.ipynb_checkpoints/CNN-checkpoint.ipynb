{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18229354-cd3e-43bd-a34c-8bdd0e220f75",
   "metadata": {},
   "source": [
    "## Dataset loader and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20ee0d6-e85e-4935-a58c-fbb3f76452f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from dataAnalysis.DataAnalysis import DataAnalysis\n",
    "import pandas as pd\n",
    "import torch\n",
    " \n",
    "data = pd.read_csv(r\"../sbcdata.csv\", header=0)\n",
    "data_analysis = DataAnalysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8784566-1c9f-4f64-814a-6afaa149ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((data_analysis.get_training_data(), data_analysis.get_testing_data()))\n",
    "max_Id = data[\"Id\"].unique().max()\n",
    "gw_data = data_analysis.get_gw_testing_data().copy(deep=True)\n",
    "gw_data = gw_data.assign(Id=lambda x: x.Id + max_Id)\n",
    "data = pd.concat((data, gw_data))\n",
    "data = data.sort_values([\"Id\", \"Time\"])\n",
    "data = data.reset_index(drop=True)\n",
    "popped_index = data.pop(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517e270b-b2e4-4287-a297-37155c5cbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAnalysis.Constants import SEX_CATEGORY_COLUMN_NAME, SEX_COLUMN_NAME, FEATURES, LABEL_COLUMN_NAME\n",
    "\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data.loc[:, SEX_COLUMN_NAME] ==\"W\"\n",
    "\n",
    "data[SEX_CATEGORY_COLUMN_NAME] = data[SEX_CATEGORY_COLUMN_NAME].astype(\"int8\")\n",
    "data[\"Label\"] = data[\"Label\"] == \"Sepsis\"\n",
    "data[\"Label\"] = data[\"Label\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d6c76-3460-47ff-bbe1-e6dcc876b3f6",
   "metadata": {},
   "source": [
    "## Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6921df7b-52bf-4fbf-b464-312158cff5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79.  ,   0.  ,   8.1 , ...,   4.36,  86.  , 167.  ],\n",
       "       [ 35.  ,   0.  ,  10.6 , ...,   6.02,  79.9 , 199.  ],\n",
       "       [ 47.  ,   1.  ,   8.7 , ...,   4.37,  89.9 , 298.  ],\n",
       "       ...,\n",
       "       [ 32.  ,   1.  ,   7.2 , ...,   3.87,  87.9 , 221.  ],\n",
       "       [ 47.  ,   0.  ,   8.3 , ...,   4.08,  91.9 , 148.  ],\n",
       "       [ 47.  ,   0.  ,   8.9 , ...,   4.39,  92.3 , 150.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"Set\"] == \"Training\", FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5cee5b-a4cd-422e-8eab-a54b1902535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data.loc[data[\"Set\"] == \"Training\", FEATURES].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996e288-96e8-44e0-8131-ae790eb0dace",
   "metadata": {},
   "source": [
    "## Padding to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f06201-e1ca-43bf-8bbd-8f4c7535267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_grouped_data = data.groupby(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d70a5569-3843-46ba-9beb-61b8f0207504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21671f9397294612a0d62173fd2866e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/866517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "max_len = 0\n",
    "for id, data_group in tqdm(id_grouped_data):\n",
    "    max_len = max(max_len, data_group.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef818a9-caac-4f72-977f-677537e35674",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_ids = data.loc[data[\"Set\"] == \"Training\", \"Id\"].unique()\n",
    "max_train_idx = int(len(unique_train_ids)*.8)\n",
    "val_ids = unique_train_ids[max_train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f491cf-ef73-4245-9159-37953f0ae1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaca5ccf8044d96829d8f23f66006d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/866517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pad_value = 0\n",
    "TRAIN = \"train\"\n",
    "GW = \"gw_test\"\n",
    "TEST = \"test\"\n",
    "VAL = \"val\"\n",
    "\n",
    "features = dict({})\n",
    "features[TRAIN] = []\n",
    "features[VAL] = []\n",
    "features[TEST] = []\n",
    "features[GW] = []\n",
    "\n",
    "labels = dict({})\n",
    "labels[TRAIN] = []\n",
    "labels[VAL] = []\n",
    "labels[TEST] = []\n",
    "labels[GW] = []\n",
    "\n",
    "for id, data_group in tqdm(id_grouped_data):\n",
    "    assert data_group[\"Set\"].unique().shape[0] == 1\n",
    "    assert data_group[\"Center\"].unique().shape[0] == 1\n",
    "\n",
    "    features_scaled = scaler.transform(data_group[FEATURES].values)\n",
    "\n",
    "    padded_features = np.pad(features_scaled, ((0, max_len - data_group.shape[0]), (0,0)), mode='constant', constant_values=pad_value)\n",
    "    padded_labels = np.pad(data_group[LABEL_COLUMN_NAME].values, ((0, max_len - data_group.shape[0])), mode='constant', constant_values=pad_value)\n",
    "    \n",
    "    first_el = data_group.iloc[0, :]\n",
    "    if first_el[\"Set\"] == \"Training\":\n",
    "        if first_el[\"Id\"] in val_ids:\n",
    "            features[VAL].append(padded_features)\n",
    "            labels[VAL].append(padded_labels)\n",
    "            continue\n",
    "        if first_el[\"Id\"] not in val_ids:\n",
    "            features[TRAIN].append(padded_features)\n",
    "            labels[TRAIN].append(padded_labels)\n",
    "            continue\n",
    "    if first_el[\"Set\"] == \"Validation\":\n",
    "        if first_el[\"Center\"] == \"Greifswald\":\n",
    "            features[GW].append(padded_features)\n",
    "            labels[GW].append(padded_labels)\n",
    "            continue\n",
    "        if first_el[\"Center\"] == \"Leipzig\":\n",
    "            features[TEST].append(padded_features)\n",
    "            labels[TEST].append(padded_labels)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdac22-9b02-4077-a7f4-4db4a0ab5050",
   "metadata": {},
   "source": [
    "## Seed and hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c08009fa-f788-40d9-9a15-6ad7c5bb44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_embd = len(FEATURES)\n",
    "head_size = 16\n",
    "dropout = 0\n",
    "out_dim = 1 #binary \n",
    "device = torch.device(\"cuda:0\") #torch.device(\"cuda:2\") #torch.device(\"cuda:2\")\n",
    "WEIGHT = 664\n",
    "lr = 1e-2\n",
    "wd = 0\n",
    "n_blocks = 2\n",
    "n_heads = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92127f1f-f8bf-41b7-be8f-aa85d0e3eba3",
   "metadata": {},
   "source": [
    "## Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "270f681d-a1aa-4c29-99aa-b31cd962b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self,X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455e9028-81aa-4f8f-9e1d-3c8493b21e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loader = dict({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98a9c611-0cae-4f7d-983c-6bccab281d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loader(set_name):\n",
    "    global bitch_loader, sets, labels\n",
    "    dataset = Data(torch.from_numpy(np.array(features[set_name])).type(torch.float).to(device), torch.from_numpy(np.array(labels[set_name])).type(torch.float).to(device))\n",
    "    loader = DataLoader(dataset=dataset, batch_size=500) #max is 100_000\n",
    "    batch_loader[set_name] = loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d221dbe-a7c3-414f-a23e-f390f551e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_loader(TRAIN)\n",
    "add_loader(VAL)\n",
    "add_loader(GW)\n",
    "add_loader(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c638073-48af-4513-81f7-87f8729c4e14",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "21724db2-ec23-4f55-8416-315cded98d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "class ConvModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, fiter_size):\n",
    "        super(ConvModel, self).__init__()\n",
    "\n",
    "        self.pos_embedding_table = nn.Embedding(max_len, input_dim)\n",
    "        \n",
    "        self.conv = nn.Conv1d(input_dim, 1, fiter_size)\n",
    "\n",
    "    def forward(self, x, targets = None):\n",
    "        B, T, C = x.shape\n",
    "        pad_mask = (x != pad_value).type(torch.float)\n",
    "        ignore_mask = torch.bmm(pad_mask, pad_mask.transpose(-2,-1))\n",
    "        ignore_mask = ignore_mask == 0\n",
    "        \n",
    "        # pos_emb = self.pos_embedding_table(torch.arange(T, device = device)) ##destroys zer pad\n",
    "        # x = x + pos_emb\n",
    "        \n",
    "        x = torch.nn.functional.pad(x, (0,0,0,1,0,0), mode='constant', value=pad_value)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        logits = self.conv(x)\n",
    "\n",
    "        logits_mask = torch.logical_not(torch.all(ignore_mask, dim =-1))\n",
    "        return logits.squeeze(-2), logits_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b068f479-0156-4fa8-adaf-5ae7874131c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of train: 0.00256\n",
      "Loss of val: 0.00265\n",
      "Loss of test: 0.00242\n",
      "Loss of gw_test: 0.00221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.0025551448067725325,\n",
       " 'val': 0.0026532175342936044,\n",
       " 'test': 0.00241752695054262,\n",
       " 'gw_test': 0.002208342016806856}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvModel(input_dim, fiter_size=2).to(device)\n",
    "evaluate_loss_sets(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c075cc-1333-4706-85ed-11b6ab0e3acc",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aad2bf23-22df-4204-ae11-8ff78ae5f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, set_name):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        acc_loss = 0\n",
    "        batch_size = 0\n",
    "\n",
    "        for i, (x,y) in enumerate(batch_loader[set_name]):\n",
    "            B,_,_ = x.shape\n",
    "            logits, logits_mask = model(x)\n",
    "        \n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[logits_mask].squeeze(-1), y[logits_mask], pos_weight=torch.tensor(WEIGHT))\n",
    "            acc_loss += loss.item()\n",
    "            batch_size += B\n",
    "    return acc_loss / batch_size        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c607fedb-b8e6-4104-a818-778d1f00be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_sets(model):\n",
    "    losses = dict({})\n",
    "    for set_name in features.keys():\n",
    "        # if set_name != VAL:\n",
    "        #     continue\n",
    "        loss = evaluate_loss(model, set_name)\n",
    "        losses[set_name] = loss\n",
    "        print(f\"Loss of {set_name}: {loss:.5f}\") \n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bb27c79-5e05-4180-8181-b2be847ca22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_auroc(model, set_name):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        \n",
    "        logits_list = []\n",
    "        label_list = []\n",
    "\n",
    "        batch_size = 0\n",
    "        for i, (x,y) in enumerate(batch_loader[set_name]):\n",
    "            B,_,_ = x.shape\n",
    "            logits, logits_mask = model(x)\n",
    "\n",
    "            logits_list.extend(logits[logits_mask].squeeze(-1).tolist())\n",
    "            label_list.extend(y[logits_mask].squeeze(-1).tolist())\n",
    "            batch_size += B\n",
    "    auroc = roc_auc_score(np.array(label_list), torch.sigmoid(torch.tensor(logits_list)).numpy())\n",
    "    return auroc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82d13cdd-c7c2-404b-80be-e31f4362e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_auroc_sets(model):\n",
    "    for set_name in features.keys():\n",
    "        if set_name == TRAIN:\n",
    "            continue\n",
    "        auroc = evaluate_auroc(model, set_name)\n",
    "        print(f\"AUROC of {set_name}: {auroc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ef05b-7e7a-4a86-8f8e-31b46d9207c2",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2e6f14e-bba3-4066-9aa8-5e8b36d55f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "input_dim, n_embd, n_heads, dropout, n_blocks = len(FEATURES), len(FEATURES), 7, 0.0, 1\n",
    "model = ConvModel(input_dim, fiter_size=2).to(device)\n",
    "optim= torch.optim.Adam(model.parameters(), lr = 1e-2, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fbfb5f8e-7250-4872-a7cc-fe0e6780d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# evaluate_auroc_sets(TransformerModel(input_dim, n_embd, n_heads, dropout, n_blocks).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18781ac1-dfc7-4784-b8a6-e8159f74fe5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([0, 416])) must be the same as input size (torch.Size([0, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_loss_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m last_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\u001b[38;5;66;03m#5\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[112], line 6\u001b[0m, in \u001b[0;36mevaluate_loss_sets\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m({})\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m set_name \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# if set_name != VAL:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     losses[set_name] \u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "Cell \u001b[0;32mIn[111], line 11\u001b[0m, in \u001b[0;36mevaluate_loss\u001b[0;34m(model, set_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m B,_,_ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      9\u001b[0m logits, logits_mask \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlogits_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlogits_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWEIGHT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m acc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m batch_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m B\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3193\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3190\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([0, 416])) must be the same as input size (torch.Size([0, 1]))"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "evaluate_loss_sets(model)\n",
    "last_val_loss = None\n",
    "for epoch in range(5):#5\n",
    "    for i, (x,y) in tqdm(enumerate(batch_loader[TRAIN])):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        logits, logits_mask = model(x)\n",
    "        print(x.shape)\n",
    "        print(logits.shape)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logits[logits_mask].squeeze(-1), y[logits_mask], pos_weight=torch.tensor(WEIGHT))\n",
    "            \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    losses = evaluate_loss_sets(model)\n",
    "    # if last_val_loss and last_val_loss <= losses[VAL]:\n",
    "    #     print(epoch)\n",
    "    #     break\n",
    "    last_val_loss = losses[VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee88475f-5a55-4ecf-b1aa-8a105a39e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC of val: 0.89290\n",
      "AUROC of test: 0.90647\n",
      "AUROC of gw_test: 0.89353\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "evaluate_auroc_sets(model) ##removed pos awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f9449be1-2697-46e9-be92-20795ccc6861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 0],\n",
       "        [4, 5, 6, 0]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3], [4,5,6]]])\n",
    "np.pad(a, ((0, 0), (0,0), (0,1)), mode='constant', constant_values=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ba0926d7-cc58-43c7-9a44-3dcbc48e85e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 0],\n",
       "         [4, 5, 6, 0]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.pad(a, (0,1,0,0,0,0), mode='constant', value=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0690f217-2be2-48c9-af57-6e6c9c770dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad(): argument 'pad' (position 2) must be tuple of ints, but found element of type tuple at pos 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m padding \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply padding using torch.nn.functional.pad\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m x_padded \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: pad(): argument 'pad' (position 2) must be tuple of ints, but found element of type tuple at pos 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = a  # Replace ... with your actual input tensor\n",
    "pad_value = 0  # Replace 0 with your desired constant padding value\n",
    "\n",
    "# Padding dimensions: ((before_dim1, after_dim1), (before_dim2, after_dim2), (before_dim3, after_dim3))\n",
    "padding = ((0, 0), (0, 0), (0, 1))\n",
    "\n",
    "# Apply padding using torch.nn.functional.pad\n",
    "x_padded = torch.nn.functional.pad(x, padding, mode='constant', value=pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e24f67-0d24-4bb7-a7c9-606150f8f112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
