{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369593e8-c7bb-4bf0-bb63-b13a7d3ffad2",
   "metadata": {},
   "source": [
    "# Evaluation graph awareness along different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a632dd5-e3e5-4c67-8627-df75bf73e468",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151bf675-4602-4d34-ab80-fa8a66ad9904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dwalke/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from EnsembleFramework import Framework\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "dataset_name = 'Cora'\n",
    "split = \"public\"\n",
    "dataset = Planetoid(root='data/', name=dataset_name, split=split)\n",
    "dataset.transform = T.NormalizeFeatures()\n",
    "\n",
    "features =  dataset[0].x\n",
    "y =  dataset[0].y\n",
    "\n",
    "test =  dataset[0].test_mask\n",
    "train = dataset[0].train_mask\n",
    "val =  dataset[0].val_mask\n",
    "\n",
    "edge_index = dataset[0].edge_index \n",
    "edge_index = add_self_loops(edge_index)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cd6cf-504b-4a17-a1a6-271ad0f29886",
   "metadata": {},
   "source": [
    "## Define Hyperparameter spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9949416-8b1b-4049-a0e2-cf816067ef54",
   "metadata": {},
   "source": [
    "### Logistic regression hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f333c8f-7023-4942-a06f-2145c84a3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "lr_choices = {\n",
    "    'penalty': [\"l2\"],\n",
    "    'max_iter': [2**i for i in range(6, 15)],\n",
    "}\n",
    "\n",
    "lr_space = {\n",
    "    **{key: hp.choice(key, value) for key, value in lr_choices.items()},\n",
    "    'tol': hp.loguniform('tol', -11, -3),\n",
    "    'C': hp.uniform('C', 0.0, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f614b-0c1b-410a-9596-8cbfee4c3e75",
   "metadata": {},
   "source": [
    "### Support Vector classfiier hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0297cd6-7d10-4001-a085-9410bff2474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "svc_choices = {\n",
    "    'gamma': [\"scale\", \"auto\"],\n",
    "    \"probability\": [True]\n",
    "}\n",
    "\n",
    "svc_space = {\n",
    "    **{key: hp.choice(key, value) for key, value in svc_choices.items()},\n",
    "    'C': hp.uniform('C', 0.0, 150)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f5b7c-7b28-44b6-9570-4d68cbc81921",
   "metadata": {},
   "source": [
    "### Decision tree hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c096ef-fe5e-43b9-ad3d-0594f68fd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "dt_choices = {\n",
    "    'criterion': [\"gini\"],\n",
    "    'max_depth': [None, *[i**2 for i in range(5, 10)]]\n",
    "}\n",
    "\n",
    "dt_space = {\n",
    "    **{key: hp.choice(key, value) for key, value in dt_choices.items()},\n",
    "    'min_samples_split': hp.uniform('min_samples_split', 0.0, 1.0),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 0.0, .5),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0.0, 0.5),\n",
    "    'max_features': hp.uniform('max_features', 0.0, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad1a84-801c-4543-9859-23e8468dddbb",
   "metadata": {},
   "source": [
    "### XGBoost hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881b368f-ce37-4183-9e32-f9ce8529cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "booster_self = [\"gbtree\"]\n",
    "n_estimators_self = [1_400, 1_600, 1_800, 2_000]\n",
    "max_depth_self = [None,2, 3,4]\n",
    "max_delta_step_self = [1,2,3]\n",
    "min_child_weight_self = [None, *list(range(1,5,1))]\n",
    "\n",
    "xb_choices = {\n",
    "    'booster': booster_self,\n",
    "    'n_estimators': n_estimators_self,\n",
    "    'max_depth': max_depth_self,\n",
    "    'max_delta_step': max_delta_step_self,\n",
    "    'min_child_weight': min_child_weight_self,\n",
    "    # 'device': [\"cuda:2\"],\n",
    "    \"tree_method\": [\"hist\"]\n",
    "}\n",
    " \n",
    "xb_space = {\n",
    "    **{key: hp.choice(key, value) for key, value in xb_choices.items()},\n",
    "    'eta': hp.loguniform('eta', -3, -.4),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda',-5, 5),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha',-3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, .8),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2aa7c-3ab6-460b-94fd-8565792bfba2",
   "metadata": {},
   "source": [
    "### Random forest hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f97277c-6fa4-4f61-88cd-1bd524429be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "rf_choices = {\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'max_depth':  [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    \"criterion\":  [\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "rf_space = {\n",
    "    **{key: hp.choice(key, value) for key, value in rf_choices.items()},\n",
    "    'max_samples': hp.uniform('max_samples', 0.0, 1),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 0.0, 1.0),\n",
    "    'min_samples_split': hp.uniform('min_samples_split', 0.0, 1.0),\n",
    "     'max_features': hp.uniform('max_features', 0.0, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99753fd4-9fb3-4fb2-9bb9-15a688f4c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clfs_space = dict({})\n",
    "clfs_space[\"RandomForestClassifier\"] = rf_space\n",
    "clfs_space[\"LogisticRegression\"] = lr_space\n",
    "clfs_space[\"DecisionTreeClassifier\"] = dt_space\n",
    "clfs_space[\"XGBClassifier\"] = xb_space\n",
    "clfs_space[\"SVC\"] = svc_space\n",
    "\n",
    "clfs = [RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, XGBClassifier, SVC]\n",
    "clfs = [RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e6dee-03db-4a98-a522-19ba583abf0a",
   "metadata": {},
   "source": [
    "## Convert data in format for AutoTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d25f05-2645-41e1-97ac-b562ef7c9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_set = dict({})\n",
    "cora_set[\"X\"] = features\n",
    "cora_set[\"y\"] = y\n",
    "cora_set[\"test\"] = test\n",
    "cora_set[\"train\"] = train\n",
    "cora_set[\"val\"] = val\n",
    "cora_set[\"edge_index\"] = edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdded46-7f04-4d10-a421-f8a328419f98",
   "metadata": {},
   "source": [
    "## Start AutoTune search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b31f80-3ca9-4b8d-871d-0fb0709f6447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe918a893cb4f80bec2b197faaef61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d274bdfb6cc4678a96f3fcb7e747de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19d9d80effe402abd93d68297d5b127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/04 13:54:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Total Trials: 0: 0 succeeded, 0 failed, 0 cancelled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m searcher \u001b[38;5;241m=\u001b[39m AutoSearch(cora_set, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, pred_metric \u001b[38;5;241m=\u001b[39m accuracy_score, parallelism\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      9\u001b[0m hops \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_function\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:201\u001b[0m, in \u001b[0;36mAutoSearch.search\u001b[0;34m(self, clfs, clfs_space, hops, user_functions, attention_configs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attention_config \u001b[38;5;129;01min\u001b[39;00m tqdm(attention_configs):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m user_function \u001b[38;5;129;01min\u001b[39;00m user_functions:\n\u001b[0;32m--> 201\u001b[0m         search_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_hop_clf_attention_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m search_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m best_val:\n\u001b[1;32m    203\u001b[0m             best_val \u001b[38;5;241m=\u001b[39m search_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:145\u001b[0m, in \u001b[0;36mAutoSearch.search_hop_clf_attention_config\u001b[0;34m(self, hop, clf, user_function, attention_config, space)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_data()\n\u001b[1;32m    144\u001b[0m sparkTune \u001b[38;5;241m=\u001b[39m SparkTune(clf,user_function,hop,attention_config, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43msparkTune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m params \u001b[38;5;241m=\u001b[39m space_eval(space, params) \u001b[38;5;66;03m## index choices to original choices\u001b[39;00m\n\u001b[1;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m clf(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/git/graph_aware_ml/AutoTune2.py:109\u001b[0m, in \u001b[0;36mSparkTune.search\u001b[0;34m(self, space)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, space):\n\u001b[1;32m    108\u001b[0m     spark_trials \u001b[38;5;241m=\u001b[39m SparkTrials(parallelism \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_search\u001b[38;5;241m.\u001b[39mparallelism)\n\u001b[0;32m--> 109\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspark_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/spark.py:261\u001b[0m, in \u001b[0;36mSparkTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    260\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin thread exits with an exception raised.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin thread exits normally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/spark.py:239\u001b[0m, in \u001b[0;36mSparkTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    236\u001b[0m state\u001b[38;5;241m.\u001b[39mlaunch_dispatcher()\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# not supported\u001b[39;49;00m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoints_to_evaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# not supported\u001b[39;49;00m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# not supported\u001b[39;49;00m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    260\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin thread exits with an exception raised.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hyperopt/fmin.py:297\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masynchronous:\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# -- wait for workers to fill in the trials\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_interval_secs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserial_evaluate()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/context.py:382\u001b[0m, in \u001b[0;36mSparkContext._do_init.<locals>.signal_handler\u001b[0;34m(signal, frame)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignal_handler\u001b[39m(signal: Any, frame: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelAllJobs()\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from AutoTune2 import AutoSearch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "def user_function(kwargs):\n",
    "    return  normalize(kwargs[\"original_features\"] + kwargs[\"summed_neighbors\"], p=2.0, dim = 1)\n",
    "\n",
    "searcher = AutoSearch(cora_set, max_evals=500, pred_metric = accuracy_score, parallelism=50)\n",
    "hops = [0,1,2,3]\n",
    "store = searcher.search(clfs, clfs_space, hops=hops, user_functions= [user_function],\n",
    "                        attention_configs = [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa896bce-953f-44a9-aa4d-bf614687f859",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434eff4b-7028-4ed3-adc1-ac5a5f6284ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in store:\n",
    "    print(clf)\n",
    "    for hop in store[clf]:\n",
    "        print(str(hop) + \"\\t\" + str( store[clf][hop][\"test_acc\"]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b66246-7c39-4f4f-a4cf-c854b2ea47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_hop_to_params = dict({})\n",
    "for clf in store:\n",
    "    print(50*\"#\")\n",
    "    clf_hop_to_params[clf] = dict({})\n",
    "    for hop in store[clf]:\n",
    "        print(f\"Classifier {clf} with {hop} hops:\")\n",
    "        print(store[clf][hop][\"model\"].get_params())\n",
    "        clf_hop_to_params[clf][hop] = store[clf][hop][\"model\"].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce4b233-f17b-4a32-a0dc-bfe486158a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(clf_hop_to_params).to_csv(\"Hyperparameters_Cora_WithoutAttention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672a1dc-fcde-48ef-ac4b-f7aefc95f71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
